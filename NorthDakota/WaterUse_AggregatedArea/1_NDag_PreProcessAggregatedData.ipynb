{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Delaware Riber Basin Commission Aggregated Amounts data for WaDE upload.\n",
    "Date Updated: 08/29/2023\n",
    "Purpose:  To pre-process the ND data into one master file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import math\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/NorthDakota/AggregatedAmounts\"\n",
    "os.chdir(workingDir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries data, xlsx file\n",
    "dfA1 =\"RawInputData/WATER USE REPORT_Basin_use_20230829_All.zip\"\n",
    "df1 = pd.read_csv(dfA1, encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "# Drop duplicates\n",
    "dfIn = df1.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfIn:\n",
    "    dfIn['WaDEUUID'] = \"ndag\" + dfIn.index.astype(str)\n",
    "    dfIn.to_csv('WATER USE REPORT_Basin_use_20230829_All.zip', compression=dict(method='zip', archive_name='WATER USE REPORT_Basin_use_20230829_All.csv'), index=False)\n",
    "\n",
    "print(len(dfIn))\n",
    "dfIn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each column filling out the basin and use type fields that are missing\n",
    "\n",
    "def basinAdd(dfIn):\n",
    "    # Iterate through each column\n",
    "    for col in dfIn.columns:\n",
    "        prev_value = None\n",
    "\n",
    "        # Iterate through each row\n",
    "        for index, value in dfIn[col].items():\n",
    "            if value == \"\":\n",
    "                if prev_value is not None:\n",
    "                    dfIn.at[index, col] = prev_value\n",
    "            else:\n",
    "                prev_value = value\n",
    "\n",
    "    return dfIn\n",
    "\n",
    "dfIn = basinAdd(dfIn.copy())\n",
    "print(len(dfIn))\n",
    "dfIn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the rows that have the column names\n",
    "dfIn = dfIn[dfIn['Acres'] != 'Acres']\n",
    "print(len(dfIn))\n",
    "dfIn.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefile info\n",
    "gdf_drb147 = gpd.read_file('RawInputData/shapefile/NDGISHUB_HUC8_Subbasin.zip', crs=\"EPSG:4326\")\n",
    "print(len(gdf_drb147))\n",
    "gdf_drb147.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# left merge timeseries info with shapefile info.\n",
    "dfIn2 = pd.DataFrame()\n",
    "dfIn2 = pd.merge(dfIn, gdf_drb147, left_on='Ã¯Â»Â¿Basin', right_on = 'NAME')\n",
    "dfIn2 = dfIn2.drop_duplicates().replace(np.nan, \"\").replace(\"nan,nan\", \"\").reset_index(drop=True)\n",
    "print(len(dfIn2))\n",
    "dfIn2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to WaDE Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIn2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Withdrawal dataframe\n",
    "# --------------------------\n",
    "\n",
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfIn2['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"NDag_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"\" # determine below\n",
    "df['in_AggregationIntervalUnitCV'] = \"Annual\"\n",
    "df['in_VariableCV'] = \"Withdrawal\"\n",
    "df['in_VariableSpecificCV'] = \"\" # determine below\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"NDag_O1\"\n",
    "\n",
    "# Water Source\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df[\"in_WaterSourceName\"] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df[\"in_WaterSourceTypeCV\"] = \"Surface and Groundwater\"\n",
    "\n",
    "# ReportingUnits Info\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_ReportingUnitName'] = dfIn2['Ã¯Â»Â¿Basin']\n",
    "df['in_ReportingUnitNativeID'] = \"nd\" +dfIn2['HUC8'].replace(\"\", 0).fillna(0).astype(str).str.strip()\n",
    "df['in_ReportingUnitProductVersion'] = \"\"\n",
    "df['in_ReportingUnitTypeCV'] = \"HUC8\"\n",
    "df['in_ReportingUnitUpdateDate'] = \"\"\n",
    "df['in_StateCV'] = \"ND\"\n",
    "\n",
    "# AggregatedAmounts Info\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_Amount'] = dfIn2['Acre Feet']\n",
    "df['in_BeneficialUseCategory'] = dfIn2['Use Type']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_InterbasinTransferFromID'] = \"\"\n",
    "df['in_InterbasinTransferToID'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfIn2['Acres']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerGeneratedGWh'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryUseCategoryCV'] = \"\"\n",
    "df['in_ReportYearCV'] = dfIn2['Year']\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_TimeframeEnd'] = \"12/31/\" + dfIn2['Year'] # determine below\n",
    "df['in_TimeframeStart'] = \"01/01/\" + dfIn2['Year']  # determine below\n",
    "\n",
    "outdf = df.copy()\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdf))\n",
    "outdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing sate info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean owner name up\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).title().replace(\" \", \"\").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_ReportingUnitName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_ReportingUnitName']), axis=1)\n",
    "outdf['in_ReportingUnitName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_ReportingUnitName'] = outdf.apply(lambda row: ensureEmptyString(row['in_ReportingUnitName']), axis=1)\n",
    "outdf['in_ReportingUnitName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_ReportingUnitTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_ReportingUnitTypeCV']), axis=1)\n",
    "outdf['in_ReportingUnitTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "for x in outdf['in_BeneficialUseCategory'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing n_Amount datatype\n",
    "outdf['in_Amount'] = pd.to_numeric(outdf['in_Amount'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str).str.strip() + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str).str.strip()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine in_VariableSpecificCV\n",
    "outdf['in_VariableSpecificCV'] = outdf['in_VariableCV'].astype(str) + \"_\" + outdf['in_AggregationIntervalUnitCV'].astype(str) + \"_\" + outdf['in_BeneficialUseCategory'].astype(str) + \"_\" + outdf['in_WaterSourceTypeCV'].astype(str)\n",
    "outdf['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creating WaDE VariableSpecificUUID for easy VariableSpecificCV identification \n",
    "# use these inputs: VariableCV_AggregationIntervalUnitCV_BeneficalUse_WaterSourceTypeCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp VariableSpecificUUID dataframe of unique water source.\n",
    "def assignVariableSpecificUUID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"NDag_V\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfVariableSpecificUUID = pd.DataFrame()\n",
    "dfVariableSpecificUUID['in_VariableCV'] = outdf['in_VariableCV']\n",
    "dfVariableSpecificUUID['in_AggregationIntervalUnitCV'] = outdf['in_AggregationIntervalUnitCV']\n",
    "dfVariableSpecificUUID['in_BeneficialUseCategory'] = outdf['in_BeneficialUseCategory']\n",
    "dfVariableSpecificUUID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfVariableSpecificUUID = dfVariableSpecificUUID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfVariableSpecificUUID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfVariableSpecificUUID['in_VariableSpecificUUID'] = dftemp.apply(lambda row: assignVariableSpecificUUID(row['Count']), axis=1)\n",
    "dfVariableSpecificUUID['linkKey'] = dfVariableSpecificUUID['in_VariableCV'].astype(str) + dfVariableSpecificUUID['in_AggregationIntervalUnitCV'].astype(str) + dfVariableSpecificUUID['in_BeneficialUseCategory'].astype(str) + dfVariableSpecificUUID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "VariableSpecificUUIDdict = pd.Series(dfVariableSpecificUUID.in_VariableSpecificUUID.values, index=dfVariableSpecificUUID.linkKey.astype(str)).to_dict()\n",
    "def retrieveVariableSpecificUUID(A, B, C, D):\n",
    "    if (A == '' and B == '' and C == '' and D == '') or (pd.isnull(A) and pd.isnull(B) and pd.isnull(C) and pd.isnull(D)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip() + str(C).strip() + str(D).strip()\n",
    "        try:\n",
    "            outList = VariableSpecificUUIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_VariableSpecificUUID'] = outdf.apply(lambda row: retrieveVariableSpecificUUID(row['in_VariableCV'], row['in_AggregationIntervalUnitCV'], row['in_BeneficialUseCategory'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_VariableSpecificUUID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "#dfshapetemp = gpd.read_file('shapefile//NDGISHUB_HUC8_Subbasin.zip', crs=\"EPSG:4326\")\n",
    "dfshapetemp = gdf_drb147.copy()\n",
    "print(len(dfshapetemp))\n",
    "dfshapetemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_ReportingUnitNativeID', 'geometry']\n",
    "outshape = pd.DataFrame(columns=columnsList)\n",
    "outshape['in_ReportingUnitNativeID'] = \"nd\" + dfshapetemp['HUC8'].replace(\"\", 0).fillna(0).astype(str).str.strip()\n",
    "outshape['geometry'] = dfshapetemp['geometry']\n",
    "outshape = outshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "outshape.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('RawInputData/Pag_ndMain.zip', compression=dict(method='zip', archive_name='Pag_ndMain.csv'), index=False)   # The output, save as a zip\n",
    "outshape.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
