{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing North Dakota Specific data for WaDEQA upload.\n",
    "- Date Updated: 05/25/2022\n",
    "\n",
    "Notes:\n",
    "- Water Use Data POD data.\n",
    "- Available data...\n",
    "    - Permit_Header.csv\n",
    "    - POD.csv\n",
    "    - Water_Use.csv\n",
    "- Match ts water use data -> POD data via POD_Index -> Permit data via Permit_Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd # the library that lets us read in shapefiles\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "\n",
    "# Cleanup\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory and Input File\n",
    "workingDir = \"G:/Shared drives/WaDE Data/NorthDakota/SiteSpecificAmounts/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Dataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries water use data\n",
    "fileInput = \"Water_Use.xlsx\"\n",
    "df_wu = pd.read_excel(fileInput)\n",
    "df_wu['Permit_Index'] = df_wu['Permit_Index'].astype('Int64').astype('str')\n",
    "df_wu['Use_Year'] = df_wu['Use_Year'].astype('Int64').astype('str')\n",
    "print(len(df_wu))\n",
    "df_wu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD data\n",
    "fileInput = \"POD.xlsx\"\n",
    "df_pod = pd.read_excel(fileInput)\n",
    "print(len(df_pod))\n",
    "df_pod.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permit_Header data\n",
    "fileInput = \"Permit_Header.xlsx\"\n",
    "df_ph = pd.read_excel(fileInput)\n",
    "print(len(df_ph))\n",
    "df_ph.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left-Join data\n",
    "df = pd.merge(df_wu, df_pod, on='POD_Index', how='left')\n",
    "df = df.merge(df_ph, left_on='Permit_Index_x', right_on='Permit_Index', how='left')\n",
    "df = df.replace(np.nan, \"\").reset_index(drop=True)\n",
    "\n",
    "print(len(df))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data\n",
    "- Exporting Monthly timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Return Data\n",
    "# Create temporary main dataframe\n",
    "dfout = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Variable Info\n",
    "dfout['in_VariableCV'] = \"Withdrawal\"\n",
    "dfout['in_VariableSpecificCV'] = \"\" # Timeseries specific.\n",
    "\n",
    "# Water Source Info\n",
    "dfout['in_WaterSourceTypeCV'] = df['Source']\n",
    "\n",
    "# Site Info\n",
    "dfout['in_County'] = df['County']\n",
    "dfout['in_Latitude'] = df['Latitude']\n",
    "dfout['in_Longitude'] = df['Longitude']\n",
    "dfout['in_SiteNativeID'] = df['POD'].astype('str')\n",
    "\n",
    "# Site Variable Amount Info\n",
    "dfout['in_Amount'] = df['Reported_AcFt'] # will convert from AcFt to MG\n",
    "dfout['in_AssociatedNativeAllocationIDs'] = df['Permit_Number'].astype(str)\n",
    "dfout['in_BeneficialUseCategory'] = df['Use_Type_x']\n",
    "dfout['in_CommunityWaterSupplySystem'] =  df['Civil_Township']\n",
    "# dfout['in_CropTypeCV'] = df['Crop_type1']\n",
    "# dfout['in_IrrigatedAcreage'] = df['Reported_Acres']\n",
    "# dfout['in_IrrigationMethodCV'] = df['Irrigation_Type']\n",
    "# dfout['in_PowerGeneratedGWh'] = df['KWHrs']\n",
    "dfout['in_ReportYearCV'] =  df['Use_Year']\n",
    "dfout['in_TimeframeStart'] = df['Use_Year'] + \"/01/01\"\n",
    "dfout['in_TimeframeEnd'] = df['Use_Year']  + \"/12/31\"\n",
    "\n",
    "print(len(dfout))\n",
    "dfout.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating in_WaterSourceTypeCV to be more machine readable / WaDE specific\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "def createWaterSourceTypeCV(inWST):\n",
    "    inWST = str(inWST).strip()\n",
    "    \n",
    "    if inWST == \"\":\n",
    "        outString = \"Unspecified\"\n",
    "    elif inWST == \"Ground Water\":\n",
    "        outString = \"Groundwater\"\n",
    "    else:\n",
    "        outString =  inWST\n",
    "      \n",
    "    return outString\n",
    "\n",
    "dfout['in_WaterSourceTypeCV'] = dfout.apply(lambda row: createWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDEND_WS\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = dfout['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    if (A == '') or (pd.isnull(A)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceTypeCV'] == A), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfout['in_WaterSourceNativeID'] = dfout.apply(lambda row: retrieveWaterSourceNativeID(row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title format for beneficial use\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "def formatTitle(valA):\n",
    "    valA = str(valA).strip().title()\n",
    "    if (valA == \"\") or (pd.isnull(valA)):\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        outString = valA\n",
    "      \n",
    "    return outString\n",
    "\n",
    "dfout['in_BeneficialUseCategory'] = dfout.apply(lambda row: formatTitle(row['in_BeneficialUseCategory']), axis=1)\n",
    "dfout['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom VariableSpecificCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "def createVariableSpecificCV(inV, inBU, inWST):\n",
    "    inV = str(inV).strip()\n",
    "    inBU = str(inBU).strip().title()\n",
    "    inWST = str(inWST).strip()\n",
    "    \n",
    "    outString = inV + \"_Annual_\" +  inBU + \"_\" + inWST\n",
    "    \n",
    "    return outString\n",
    "\n",
    "dfout['in_VariableSpecificCV'] = dfout.apply(lambda row: createVariableSpecificCV(row['in_VariableCV'], \n",
    "                                                                                     row['in_BeneficialUseCategory'],\n",
    "                                                                                     row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby and Sum\n",
    "- Issue of multiple withdrawl values from same sites by permit.  Will cheat for now and aggregate all values at the single site using our WaDE ss aggregation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout2 = dfout.copy()\n",
    "print(len(dfout2))\n",
    "dfout2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupbyList = ['in_SiteNativeID', 'in_VariableSpecificCV', 'in_TimeframeStart', 'in_TimeframeEnd']\n",
    "dfout2 = dfout2.groupby(groupbyList).agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem!=''])).replace(np.nan, \"\").reset_index()\n",
    "print(len(dfout2))\n",
    "dfout2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Output\n",
    "- checking & changing data type & format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert History Year to YYYY-MM-DD format.\n",
    "\n",
    "dfout2['in_TimeframeEnd'] = pd.to_datetime(dfout2['in_TimeframeEnd'], errors = 'coerce')\n",
    "dfout2['in_TimeframeEnd'] = pd.to_datetime(dfout2[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout2['in_TimeframeStart'] = pd.to_datetime(dfout2['in_TimeframeStart'], errors = 'coerce')\n",
    "dfout2['in_TimeframeStart'] = pd.to_datetime(dfout2[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summing up the comma separated list of Amounts to one value.\n",
    "def sumAmountsFunc(valA):\n",
    "    valAList = valA.split(\",\")\n",
    "    for x in valAList:\n",
    "        if x == \"\" or \",\" in x:\n",
    "            outString = x\n",
    "        else:\n",
    "            try:\n",
    "                x = float(x)\n",
    "                outString += x\n",
    "            except:\n",
    "                outString = x\n",
    "                    \n",
    "    return outString\n",
    "\n",
    "dfout2['in_Amount'] = dfout2.apply(lambda row: sumAmountsFunc(row['in_Amount']), axis=1)\n",
    "dfout2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting numbers that are in string to float.\n",
    "\n",
    "# in_Latitude & in_Longitude\n",
    "dfout2['in_Latitude'] = pd.to_numeric(dfout2['in_Latitude'], errors='coerce')\n",
    "dfout2['in_Longitude'] = pd.to_numeric(dfout2['in_Longitude'], errors='coerce')\n",
    "\n",
    "# in_Amount\n",
    "dfout2['in_Amount'] = pd.to_numeric(dfout2['in_Amount'], errors='coerce')\n",
    "\n",
    "# # in_PowerGeneratedGWh\n",
    "# dfout2['in_PowerGeneratedGWh'] = pd.to_numeric(dfout2['in_PowerGeneratedGWh'], errors='coerce')\n",
    "\n",
    "#in_ReportYearCV\n",
    "# having some issues converting this to an int\n",
    "dfout2['in_ReportYearCV'] = pd.to_numeric(dfout2['in_ReportYearCV'], errors='coerce')\n",
    "dfout2['in_ReportYearCV'] = dfout2['in_ReportYearCV'].fillna(0).astype('int64')\n",
    "\n",
    "dfout2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Amount AcFt to MG\n",
    "def convertAmountFunc(valA):\n",
    "    outVal = valA * 0.28002596920264\n",
    "    return outVal\n",
    "\n",
    "dfout2['in_Amount'] = dfout2.apply(lambda row: convertAmountFunc(row['in_Amount']), axis=1)\n",
    "dfout2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputfile(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting output files.\n",
    "dfout2.to_csv('P_ndSSMaster.csv', index=False)  # The master output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bonus:\n",
    "- checking processed sitespecificamounts.csv for duplicate and identifying why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dftest = pd.read_csv('G:/Shared drives/WaDE Data/NorthDakota/SiteSpecificAmounts/ProcessedInputData/sitespecificamounts.csv')\n",
    "# print(len(dftest))\n",
    "# dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dftest['VariableSpecificUUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfdp = dftest.copy()\n",
    "# duplicateCheckList = ['OrganizationUUID', 'SiteUUID', 'VariableSpecificUUID', 'BeneficialUseCategory', 'ReportYearCV', 'TimeframeEnd', 'TimeframeStart']\n",
    "# dfdp = dfdp.drop_duplicates(subset=duplicateCheckList)\n",
    "# print(len(dfdp))\n",
    "# dfdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #duplicate groupby test\n",
    "# dfgbt = dftest.copy()\n",
    "# groupbyList = ['OrganizationUUID', 'SiteUUID', 'VariableSpecificUUID', 'BeneficialUseCategory', 'ReportYearCV', 'TimeframeEnd', 'TimeframeStart']\n",
    "# dfgbt = dfgbt.groupby(groupbyList).agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem!=''])).replace(np.nan, \"\").reset_index()\n",
    "# print(len(dfgbt))\n",
    "# dfgbt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfgbt.to_excel('duplicate groupby test.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = dfout2.copy()\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom VariableSpecificCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "def createTestColumn(inV):\n",
    "    inV = str(inV).strip()\n",
    "    \n",
    "    outString = inV + \"_test Yo\"\n",
    "    \n",
    "    return outString\n",
    "\n",
    "dftest['testColumn'] = dftest.apply(lambda row: createTestColumn(row['in_VariableCV']), axis=1)\n",
    "dftest['testColumn']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
