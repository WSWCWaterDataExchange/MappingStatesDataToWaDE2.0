{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Nevada Allocation data for WaDEQA upload.\n",
    "Date Updated: 08/03/2020\n",
    "Purpose:  To pre-process the Nevada data into one master file for simple DataFrame creation and extraction\n",
    "\n",
    "### Notes:\n",
    "To incldue owners, made a temporary Permit_Owners_5temp.csv file by removing previous onwers from list.  Plan on left-join to POD AllApps_2.csv by 'app' field.\n",
    "\n",
    "\n",
    "https://ndwr.maps.arcgis.com/home/item.html?id=0d050f7b79724404b80bf29589f67363\n",
    "https://arcgis.shpo.nv.gov/arcgis/rest/services/Water_Resources_Public_Data/WaterRights_POD_POU/FeatureServer\n",
    "https://arcgis.shpo.nv.gov/arcgis/rest/services/Water_Resources_Public_Data/SE_HydrographicBasins/FeatureServer\n",
    "http://water.nv.gov/CodeDefinitions.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import geopandas as gpd # the library that lets us read in shapefiles\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Nevada/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POD Sites Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD Data\n",
    "PoDAAInput = \"POD AllApps_2_input.csv\"\n",
    "dfPoD = pd.read_csv(PoDAAInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfPoD:\n",
    "    dfPoD['WaDEUUID'] = \"nvD\" + dfPoD.index.astype(str)\n",
    "    dfPoD.to_csv('POD AllApps_2_input.csv', index=False)\n",
    "    \n",
    "dfPoD['in_PODorPOUSite'] = \"POD\"\n",
    "dfPoD['in_SiteNativeID'] = \"POD\" + dfPoD.index.astype(str) # creating custom site Native iD for POD\n",
    "\n",
    "print(len(dfPoD))\n",
    "dfPoD.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoU Sites Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Data\n",
    "PoUAAInput = \"PoU AllApps_3_input.csv\"\n",
    "dfPoU = pd.read_csv(PoUAAInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfPoU:\n",
    "    dfPoU['WaDEUUID'] = \"nvU\" + dfPoU.index.astype(str)\n",
    "    dfPoU.to_csv('PoU AllApps_3_input.csv.csv', index=False)\n",
    "    \n",
    "dfPoU['in_PODorPOUSite'] = \"POU\"\n",
    "dfPoU['in_SiteNativeID'] = \"POU\" + dfPoU.index.astype(str) # creating custom site Native iD for POU\n",
    "\n",
    "print(len(dfPoU))\n",
    "dfPoU.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD & PoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat POD and POU data\n",
    "df = pd.concat([dfPoD, dfPoU], ignore_index=True)\n",
    "df = df.drop_duplicates().reset_index()\n",
    "print(len(df))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner Data\n",
    "- add to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Owner Data\n",
    "OwnTemp = \"Permit_Owners_5temp.csv\"\n",
    "dfown = pd.read_csv(OwnTemp)\n",
    "print(len(dfown))\n",
    "dfown.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Owner info. Remove special characters\n",
    "import re\n",
    "\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).strip()\n",
    "    return Val\n",
    "\n",
    "dfown['owner_name'] = dfown.apply(lambda row: cleanOwnerDataFunc(row['owner_name']), axis=1)\n",
    "dfown['owner_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With owner sort and merge columns by 'app' field.\n",
    "dfown = dfown.groupby('app', sort=False).agg(lambda x: ', '.join([str(elem) for elem in (list(set(x)))]))\n",
    "dfown = dfown.drop_duplicates().reset_index()\n",
    "print(len(dfown))\n",
    "dfown.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data with Owner by app field\n",
    "df = pd.merge(df, dfown, left_on='app', right_on='app', how='left') # Joinning PoD data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating WaterSourceTypeCV\n",
    "UnknownWSCVDict = {\n",
    "\"EFF\" : \"Reuse\",\n",
    "\"GEO\" : \"Groundwater\",\n",
    "\"LAK\" : \"Surface Water\",\n",
    "\"OGW\" : \"Groundwater\",\n",
    "\"OSW\" : \"Surface Water\",\n",
    "\"RES\" : \"Reservoir\",\n",
    "\"SPR\" : \"Surface Water\",\n",
    "\"STO\" : \"Storage\",\n",
    "\"STR\" : \"Surface Water\",\n",
    "\"UG\" : \"Groundwater\",\n",
    "\"UKN\" : \"Unknown\"}\n",
    "def assignWaterSourceTypeCV(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outList = \"Unspecified\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()  # remove whitespace chars\n",
    "        try:\n",
    "            outList = UnknownWSCVDict[String1]\n",
    "        except:\n",
    "            outList = \"Unspecified\"\n",
    "    return outList\n",
    "\n",
    "df['in_WaterSourceTypeCV'] = df.apply(lambda row: assignWaterSourceTypeCV(row['source']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating SiteName\n",
    "def assignSiteName(colrowValue):\n",
    "    colrowValuestr = str(colrowValue)\n",
    "    colrowValuestr = colrowValuestr.strip()\n",
    "    if ((colrowValuestr == \"\") or pd.isnull(colrowValuestr) or colrowValuestr == 'nan'):\n",
    "        outList = \"Unspecified\"\n",
    "    else:\n",
    "        outList = colrowValuestr\n",
    "    return outList\n",
    "\n",
    "df['in_SiteName'] = df.apply(lambda row: assignSiteName(row['site_name']), axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating SiteTypeCV\n",
    "UnknownSTCVDict = {\n",
    "    \"EFF\":\"Effluent\",\n",
    "    \"GEO\":\"Geothermal\",\n",
    "    \"LAK\":\"lake\",\n",
    "    \"OGW\":\"Other Ground Water\",\n",
    "    \"OSW\":\"Other Surface Water\",\n",
    "    \"RES\":\"Reservoir\",\n",
    "    \"SPR\":\"Spring\",\n",
    "    \"STO\":\"Storage\",\n",
    "    \"STR\":\"stream\",\n",
    "    \"UG\":\"Underground\",\n",
    "    \"UKN\":\"Unknown\"}\n",
    "def assignSiteTypeCV(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = ''\n",
    "    else:\n",
    "        String1 = colrowValue.strip()  # remove whitespace chars\n",
    "        try:\n",
    "            outList = UnknownSTCVDict[String1]\n",
    "        except:\n",
    "            outList = \"Unspecified\"\n",
    "    return outList\n",
    "\n",
    "df['in_SiteTypeCV'] = df.apply(lambda row: assignSiteTypeCV(row['source']), axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing state site info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDENV_WS\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = df['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    if (A == '') or (pd.isnull(A)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceTypeCV'] == A), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "df['in_WaterSourceNativeID'] = df.apply(lambda row: retrieveWaterSourceNativeID(row['in_WaterSourceTypeCV']), axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing datatype of used date fields. \n",
    "df['prior_dt'] = pd.to_datetime(df['prior_dt'], errors = 'coerce')\n",
    "df['prior_dt'] = pd.to_datetime(df[\"prior_dt\"].dt.strftime('%m/%d/%Y'))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching gemetry to csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data, Shapefile input\n",
    "dfPoUshapetemp = gpd.read_file('shapefile/NVwr_POU.shp')\n",
    "#dfPoUshapetemp = pd.DataFrame(dfPoUshapetemp)\n",
    "dfPoUshapetemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp.index.astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to Finished File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "df.to_csv('P_MastersNV.csv', index=False)\n",
    "dfPoUshape.to_csv('P_nvGeometry.csv', index=False) # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
