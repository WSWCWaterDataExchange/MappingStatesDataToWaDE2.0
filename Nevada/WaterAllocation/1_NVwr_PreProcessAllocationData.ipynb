{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing (state / organization Name) Allocation data for WaDE upload.\n",
    "- Purpose:  To pre-process the data into one master file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Nevada/WaterAllocation\" # file location\n",
    "os.chdir(workingDir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point of Diversion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "FI_PoD = \"RawInputData/PointsofDiversion.zip\"\n",
    "dfinPOD = pd.read_csv(FI_PoD).replace(np.nan, \"\")\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOD:\n",
    "    dfinPOD['WaDEUUID'] = \"utD\" + dfinPOD.index.astype(str)\n",
    "    dfinPOD.to_csv('RawInputData/PointsofDiversion.zip', compression=dict(method='zip', archive_name='PointsofDiversion.csv'), index=False)\n",
    "\n",
    "FI_POwner=\"RawInputData/PermitOwners.zip\"\n",
    "dfinPOwner = pd.read_csv(FI_POwner).replace(np.nan, \"\")\n",
    "dfinPOwner['app'] = dfinPOwner['app'].str.replace('\\s+','')\n",
    "dfinPOwner= dfinPOwner.groupby('app').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem != \"\"])).replace(np.nan, \"\").reset_index()   \n",
    "# WaDE UUID tracker for data assessment\n",
    "# if 'WaDEUUID' not in dfinPOwner:\n",
    "#     dfinPOwner['WaDEUUID'] = \"utD\" + dfinPOwner.index.astype(str)\n",
    "#     dfinPOwner.to_csv('RawInputData/MergedPodPo.zip', compression=dict(method='zip', archive_name='MergedPodPo.csv'), index=False)\n",
    "\n",
    "mergedData = pd.merge(dfinPOD, dfinPOwner, left_on='app', right_on='app',how='left' )#merging pod and permit owner tables\n",
    "\n",
    "#pd.reset_option('max_columns')\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(len(dfinPOwner))\n",
    "#dfinPOD.head()\n",
    "mergedData.head()\n",
    "#dfinPOwner.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = mergedData['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"NVwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"NVwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"NVwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "df['in_WaterSourceTypeCV'] = mergedData['source']\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"Digitized\"\n",
    "df['in_County'] = mergedData['county_x']\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = mergedData['latitude']\n",
    "df['in_Longitude'] = mergedData['longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = mergedData['site_name']\n",
    "df['in_SiteNativeID'] = \"SitePODwadeID\" + mergedData['ï»¿OID_'].astype(str) ##########################\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = mergedData['source_desc']\n",
    "df['in_StateCV'] = \"NV\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = mergedData['diversion_rate']\n",
    "df['in_AllocationLegalStatusCV'] = mergedData['app_status']\n",
    "df['in_AllocationNativeID'] =  mergedData['app'].replace(\"\", 0).fillna(0).astype(str).str.lower().str.strip()\n",
    "df['in_AllocationOwner'] = mergedData['owner_name']\n",
    "df['in_AllocationPriorityDate'] = mergedData['priority_date']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = mergedData['duty_balance']\n",
    "df['in_BeneficialUseCategory'] = mergedData['mou']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0 # either a 1 or 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = mergedData['pou_acre_total']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = mergedData['permit_record']\n",
    "\n",
    "outPOD = df.copy()\n",
    "outPOD = outPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOD))\n",
    "outPOD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place of Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - place of use data\n",
    "FI_POU = \"RawInputData/shapefile/POU_Permits_All.zip\"\n",
    "dfinPOU = gpd.read_file(FI_POU).replace(np.nan, \"\") \n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOU:\n",
    "    dfinPOU['WaDEUUID'] = \"utU\" + dfinPOU.index.astype(str)\n",
    "    dfinPOU.to_csv('RawInputData/POU_Permits_All.zip', compression=dict(method='zip', archive_name='POU_Permits_All.csv'), index=False)\n",
    "\n",
    "dfinPOwner = pd.read_csv(FI_POwner, encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "dfinPOwner['app'] = dfinPOwner['app'].str.replace('\\s+','')\n",
    "dfinPOwner= dfinPOwner.groupby('app').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem != \"\"])).replace(np.nan, \"\").reset_index()   \n",
    "PouMergedData = pd.merge(dfinPOU, dfinPOwner, left_on='app', right_on='app',how='left' )\n",
    "\n",
    "print(len(PouMergedData))\n",
    "dfinPOU.head() \n",
    "#PouMergedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = PouMergedData['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"NVwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"NVwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"NVwr_O1\"\n",
    "\n",
    "#dfinPOU['']\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = PouMergedData['source']\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"Digitized\"\n",
    "df['in_County'] = PouMergedData['county_x']\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = PouMergedData['latitude']\n",
    "df['in_Longitude'] = PouMergedData['longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POU\"  # \"Place of Use\"\n",
    "df['in_SiteName'] = PouMergedData['site_name']\n",
    "df['in_SiteNativeID'] = \"SitePOUwadeID\" + PouMergedData['OBJECTID'].astype(str) ###################\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = PouMergedData['source_des']\n",
    "df['in_StateCV'] = \"NV\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = PouMergedData['diversio_1']\n",
    "df['in_AllocationLegalStatusCV'] =PouMergedData['app_status']\n",
    "df['in_AllocationNativeID'] =  PouMergedData['app'].replace(\"\", 0).fillna(0).astype(str).str.lower().str.strip()\n",
    "df['in_AllocationOwner'] = PouMergedData['owner_name']\n",
    "df['in_AllocationPriorityDate'] = PouMergedData['priority_d']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = PouMergedData['duty_balan']\n",
    "df['in_BeneficialUseCategory'] = PouMergedData['mou']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0 # either a 1 or 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = PouMergedData['pou_acre_t']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = PouMergedData['permit_rec']\n",
    "\n",
    "outPOU = df.copy()\n",
    "outPOU = outPOU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOU))\n",
    "outPOU.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU Data.  Make needed changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outPOD, outPOU]\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating County\n",
    "CountyDict = {\n",
    "    \"HU\" : \"Humboldt\",\n",
    "    \"CC\" : \"Carson City\",\n",
    "    \"CH\" : \"Churchill\",\n",
    "    \"CL\" : \"Clark\",\n",
    "    \"DO\" : \"Douglas\",\n",
    "    \"EL\" : \"Elko\",\n",
    "    \"ES\" : \"Esmerelda\",\n",
    "    \"EU\" : \"Eureka\",\n",
    "    \"LA\" : \"Lander\",\n",
    "    \"LI\" : \"Lincoln\",\n",
    "    \"LY\": \"Lyon\",\n",
    "    \"MI\": \"Mineral\",\n",
    "    \"NY\": \"Nye\",\n",
    "    \"PE\": \"Pershing\",\n",
    "    \"ST\": \"Storey\",\n",
    "     \"\": \"Unknown\",\n",
    "    \"WA\": \"Washoe\",\n",
    "    \"WP\": \"White Pine\",\n",
    "    \"UK\": \"Unknown\"}\n",
    "def assignCounty(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()\n",
    "        try:\n",
    "            outList = CountyDict[String1]\n",
    "        except:\n",
    "            outList = \"\"\n",
    "    return outList\n",
    "\n",
    "outdf['in_County'] = outdf.apply(lambda row: assignCounty(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating AllocationLegalStatusCV\n",
    "LegalDict = {\n",
    "\"ABN\" : \"Abandoned\",\n",
    "\"ABR\" : \"Abrogated\",\n",
    "\"APP\" : \"Application\",\n",
    "\"CAN\" : \"Canceled\",\n",
    "\"CER\" : \"Certificate\",\n",
    "\"CUR\" : \"Curtailed\",\n",
    "\"DEC\" : \"Decreed\",\n",
    "\"DEN\": \"Denied\",\n",
    "\"EXP\": \"Expired\",\n",
    "\"FOR\": \"Forfeited\",\n",
    "\"PER\": \"Permit\",\n",
    "\"REJ\": \"Rejected\",\n",
    "\"REL\": \"Relinquished\",\n",
    "\"RES\": \"Reserved\",\n",
    "\"RFA\": \"Ready For Action\",\n",
    "\"RFP\": \"Ready for Action (Protested)\",\n",
    "\"RLP\": \"Relinquish a Portion\",\n",
    "\"RSC\": \"Rescinded\",\n",
    "\"RVK\": \"Revoked\",\n",
    "\"RVP\": \"Revocable Permit\",\n",
    "\"SUP\": \"Supersceded\",\n",
    "\"SUS\": \"Suspended\",\n",
    "\"VST\": \"Vested Rights\",\n",
    "\"WDR\": \"Withdrawn\"}\n",
    "def assignAllocationLegalStatusCV(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue) == True :\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()\n",
    "        try:\n",
    "            outList = LegalDict[String1]\n",
    "        except:\n",
    "            outList = \"\"\n",
    "    return outList\n",
    "outdf['in_AllocationLegalStatusCV'] = outdf.apply(lambda row: assignAllocationLegalStatusCV(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating BeneficialUse\n",
    "BeneficialUseDict = {\n",
    "\"COM\" : \"Commercial\",\n",
    "\"CON\" : \"Construction\",\n",
    "\"DEC\" : \"As Decreed\",\n",
    "\"DOM\" : \"Domestic\",\n",
    "\"DWR\" : \"Dewatering\",\n",
    "\"ENV\" : \"Environmental\",\n",
    "\"EVP\" : \"Evaporation\",\n",
    "\"IND\": \"Industrial\",\n",
    "\"IRC\": \"Irrigation-Carey Act\",\n",
    "\"IRD\": \"Irrigation-DLE\",\n",
    "\"IRR\": \"Irrigation\",\n",
    "\"MM\": \"Mining and Milling\",\n",
    "\"MMD\": \"Mining Milling and Dewatering\",\n",
    "\"MUN\": \"Municipal\",\n",
    "\"OTH\": \"Other\",\n",
    "\"PWR\": \"Power\",\n",
    "\"QM\": \"Quasi-Municipal\",\n",
    "\"REC\": \"Recreational\",\n",
    "\"STK\": \"Stockwatering\",\n",
    "\"STO\": \"Storage\",\n",
    "\"UKN\": \"Unknown\",\n",
    "\"WLD\": \"Wildlife\"}\n",
    "def assignBeneficialUse(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = ''\n",
    "    else:\n",
    "        String1 = colrowValue.strip()  # remove whitespace chars\n",
    "        try:\n",
    "            outList = BeneficialUseDict[String1]\n",
    "        except:\n",
    "            outList = \"\"\n",
    "\n",
    "    return outList\n",
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: assignBeneficialUse(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating WaterSourceTypeCV\n",
    "UnknownWSCVDict = {\n",
    "\"EFF\" : \"Reuse\",\n",
    "\"GEO\" : \"Groundwater\",\n",
    "\"LAK\" : \"Surface Water\",\n",
    "\"OGW\" : \"Groundwater\",\n",
    "\"OSW\" : \"Surface Water\",\n",
    "\"RES\" : \"Reservoir\",\n",
    "\"SPR\" : \"Surface Water\",\n",
    "\"STO\" : \"Storage\",\n",
    "\"STR\" : \"Surface Water\",\n",
    "\"UG\" : \"Groundwater\",\n",
    "\"UKN\" : \"Unknown\"}\n",
    "def assignWaterSourceTypeCV(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()  # remove whitespace chars\n",
    "        try:\n",
    "            outList = UnknownWSCVDict[String1]\n",
    "        except:\n",
    "            outList = \"\"\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: assignWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating SiteTypeCV\n",
    "UnknownSTCVDict = {\n",
    "    \"EFF\":\"Effluent\",\n",
    "    \"GEO\":\"Geothermal\",\n",
    "    \"LAK\":\"lake\",\n",
    "    \"OGW\":\"Other Ground Water\",\n",
    "    \"OSW\":\"Other Surface Water\",\n",
    "    \"RES\":\"Reservoir\",\n",
    "    \"SPR\":\"Spring\",\n",
    "    \"STO\":\"Storage\",\n",
    "    \"STR\":\"stream\",\n",
    "    \"UG\":\"Underground\",\n",
    "    \"UKN\":\"Unknown\"}\n",
    "def assignSiteTypeCV(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()  # remove whitespace chars\n",
    "        try:\n",
    "            outList = UnknownSTCVDict[String1]\n",
    "        except:\n",
    "            outList = \"\"\n",
    "    return outList\n",
    "\n",
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: assignSiteTypeCV(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean name entries of spcial characters\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Latitude entry is either numireic or blank, no 0 entries\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Longitude entry is either numireic or blank, no 0 entries\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype of Priority Date to date fields entry\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf[\"in_AllocationPriorityDate\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Flow entry is either numireic or blank, no 0 entries\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Volume entry is either numireic or blank, no 0 entries\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str) + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop non-Active AllocationLegalStatusCV Water Rights\n",
    "- For this {state name / organization}, we don't want water rights that are considered: {enter string entries here}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-active AllocationLegalStatusCV values specific to that state.\n",
    "\n",
    "# drop the list\n",
    "dropLegalStatusList = [\"Abandoned\", \"Abrogated\", \"Application\", \"Canceled\", \"Denied\", \"Expired\", \"Forfeited\", \"Ready For Action\", \"Ready for Action (Protested)\", \"Rejected\", \"Revoked\", \"Supersceded\", \"Withdrawn\"]\n",
    "\n",
    "# drop rows from above list\n",
    "outdf = outdf[outdf.in_AllocationLegalStatusCV.isin(dropLegalStatusList) == False].reset_index(drop=True)\n",
    "\n",
    "print(len(outdf))\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "shapefileInput = \"RawInputData/shapefile/POU_Permits_All.zip\" # ziped folder of the shp file\n",
    "dfPoUshapetemp = gpd.read_file(shapefileInput)\n",
    "print(len(dfPoUshapetemp))\n",
    "dfPoUshapetemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp dataframe to hold native ID and geometry from shapefile input\n",
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "\n",
    "# assing values to temp dataframe based on shapefile input\n",
    "# for in_SiteNativeID assure ID value is the same as that listed above for POU info.\n",
    "dfPoUshape['in_SiteNativeID'] = \"SitePOUwadeID\" + dfPoUshapetemp['OBJECTID'].astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "print(len(dfPoUshape))\n",
    "dfPoUshape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "# change output name / abbreviation to match native state provdier and wade data type \n",
    "outdf.to_csv('RawInputData/Pwr_nvMain.zip', compression=dict(method='zip', archive_name='Pwr_nvMain.csv'), index=False)  # The output, save as a zip\n",
    "dfPoUshape.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry.\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
