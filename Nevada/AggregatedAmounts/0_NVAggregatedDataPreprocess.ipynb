{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with NV Aggregated Data\n",
    "\n",
    "Pre-processing input data for a smoother upload experience of the state data to the WaDE 2.0 database.\n",
    "Using geopandas to read in shp file, and coverting to WKT for ReportingUnit geometry.\n",
    "\n",
    "#### Notes:\n",
    "- NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import geopandas as gpd # the library that lets us read in shapefiles\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "\n",
    "#Setting work directory, reading inputs, creating dataframe\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Nevada/AggregatedAmounts/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pumpage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV input file\n",
    "basin2015Input = \"StateInv_2015_BasinPumpage.csv\"\n",
    "basin2017Input = \"StateInv_2017_BasinPumpage.csv\"\n",
    "county2015Input = \"StateInv_2015_CountyPumpage.csv\"\n",
    "county2017Input = \"StateInv_2015_CountyPumpage.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin 2015\n",
    "dfb15 = pd.read_csv(basin2015Input)\n",
    "dfb15['Year'] = \"2015\"\n",
    "dfb15['in_ReportingUnitType'] = \"Basin\"\n",
    "print(len(dfb15))\n",
    "dfb15.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin 2017\n",
    "dfb17 = pd.read_csv(basin2017Input)\n",
    "dfb17['Year'] = \"2017\"\n",
    "dfb17['in_ReportingUnitType'] = \"Basin\"\n",
    "print(len(dfb17))\n",
    "dfb17.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coutny 2015\n",
    "dfc15 = pd.read_csv(county2015Input)\n",
    "dfc15['Year'] = \"2015\"\n",
    "dfc15['in_ReportingUnitType'] = \"County\"\n",
    "print(len(dfc15))\n",
    "dfc15.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coutny 2017\n",
    "dfc17 = pd.read_csv(county2017Input)\n",
    "dfc17['Year'] = \"2017\"\n",
    "dfc17['in_ReportingUnitType'] = \"County\"\n",
    "print(len(dfc17))\n",
    "dfc17.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate basin dataframes.\n",
    "frames = [dfb15, dfb17]\n",
    "dfbtemp = pd.concat(frames).reset_index(drop=True)\n",
    "dfbtemp['in_ReportingUnitNativeID'] = dfbtemp['BasinID']\n",
    "dfbtemp['in_ReportingUnitName'] = dfbtemp['BasinName']\n",
    "dfbtemp = dfbtemp.drop(['OID_', 'BasinID', 'BasinName'], axis=1)\n",
    "print(len(dfbtemp))\n",
    "dfbtemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to transpose the data.\n",
    "# create Temporary basin out dataframe\n",
    "columnsList = [\"Year\", \"in_ReportingUnitType\", \"in_ReportingUnitNativeID\", \"in_ReportingUnitName\"]\n",
    "dfbtemp2 = pd.DataFrame(columns=columnsList)\n",
    "dfbtemp2 = dfbtemp[columnsList]\n",
    "\n",
    "############################################\n",
    "\n",
    "dfbtemp2 = dfbtemp2.assign(NV_BenUse='')\n",
    "dfbtemp2 = dfbtemp2.assign(in_Amount='')\n",
    "dfbtemp2 = dfbtemp2.assign(in_ReportingUnitType='')\n",
    "dfBasinOut = pd.DataFrame() # dataframe to append to\n",
    "\n",
    "############################################\n",
    "columnsList = [\n",
    "    'COM',\n",
    "    'CON',\n",
    "    'DOM',\n",
    "    'ENV',\n",
    "    'IND',\n",
    "    'IRR',\n",
    "    'MM',\n",
    "    'MUN',\n",
    "    'OTH',\n",
    "    'PWR',\n",
    "    'QM',\n",
    "    'REC',\n",
    "    'STK',\n",
    "    'WLD']\n",
    "lenList = len(columnsList)\n",
    "\n",
    "\n",
    "############################################\n",
    "for i in range(lenList):\n",
    "    BenuseString = columnsList[i]\n",
    "    dfbtemp2['NV_BenUse'] = BenuseString\n",
    "    dfbtemp2['in_Amount'] = dfbtemp[columnsList[i]]\n",
    "    dfbtemp2['in_ReportingUnitType'] = \"Basin\"\n",
    "    dfBasinOut = dfBasinOut.append(dfbtemp2)\n",
    "    \n",
    "############################################\n",
    "\n",
    "print(len(dfBasinOut.index))\n",
    "dfBasinOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate county dataframes.\n",
    "frames = [dfc15, dfc17]\n",
    "dfctemp = pd.concat(frames).reset_index(drop=True)\n",
    "dfctemp['in_ReportingUnitNativeID'] = \"\"\n",
    "dfctemp['in_ReportingUnitName'] = dfctemp['County']\n",
    "dfctemp = dfctemp.drop(['OID_', 'County'], axis=1)\n",
    "print(len(dfctemp))\n",
    "dfctemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom reportingunit native ID for easy site identificaiion\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp ReportingUnitNativeID dataframe of unique reporting units.\n",
    "def assignReportingUnitNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDENV_RU\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfReportingUnitNativeID = pd.DataFrame()\n",
    "dfReportingUnitNativeID['in_ReportingUnitName'] = dfctemp['in_ReportingUnitName']\n",
    "dfReportingUnitNativeID['in_ReportingUnitType'] = dfctemp['in_ReportingUnitType']\n",
    "dfReportingUnitNativeID = dfReportingUnitNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfReportingUnitNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfReportingUnitNativeID['in_ReportingUnitNativeID'] = dftemp.apply(lambda row: assignReportingUnitNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom reportingunit native ID\n",
    "def retrieveReportingUnitNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfReportingUnitNativeID.loc[(dfReportingUnitNativeID['in_ReportingUnitName'] == A) & \n",
    "                                         (dfReportingUnitNativeID['in_ReportingUnitType'] == B), 'in_ReportingUnitNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfctemp['in_ReportingUnitNativeID'] = dfctemp.apply(lambda row: retrieveReportingUnitNativeID( row['in_ReportingUnitName'], row['in_ReportingUnitType']), axis=1)\n",
    "dfctemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need to transpose the data.\n",
    "# create Temporary county out dataframe\n",
    "columnsList = [\"Year\", \"in_ReportingUnitType\", \"in_ReportingUnitNativeID\", \"in_ReportingUnitName\"]\n",
    "dfctemp2 = pd.DataFrame(columns=columnsList)\n",
    "dfctemp2 = dfctemp[columnsList]\n",
    "\n",
    "############################################\n",
    "\n",
    "dfctemp2 = dfctemp2.assign(NV_BenUse='')\n",
    "dfctemp2 = dfctemp2.assign(in_Amount='')\n",
    "dfctemp2 = dfctemp2.assign(in_ReportingUnitType='')\n",
    "dfCountyOut = pd.DataFrame() # dataframe to append to\n",
    "\n",
    "############################################\n",
    "columnsList = [\n",
    "    'COM',\n",
    "    'CON',\n",
    "    'DOM',\n",
    "    'ENV',\n",
    "    'IND',\n",
    "    'IRR',\n",
    "    'MM',\n",
    "    'MUN',\n",
    "    'OTH',\n",
    "    'PWR',\n",
    "    'QM',\n",
    "    'REC',\n",
    "    'STK',\n",
    "    'WLD']\n",
    "lenList = len(columnsList)\n",
    "\n",
    "\n",
    "############################################\n",
    "for i in range(lenList):\n",
    "    BenuseString = columnsList[i]\n",
    "    dfctemp2['NV_BenUse'] = BenuseString\n",
    "    dfctemp2['in_Amount'] = dfctemp[columnsList[i]]\n",
    "    dfctemp2['in_ReportingUnitType'] = \"County\"\n",
    "    dfCountyOut = dfCountyOut.append(dfctemp2)\n",
    "    \n",
    "############################################\n",
    "\n",
    "print(len(dfCountyOut.index))\n",
    "dfCountyOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate temp basin and county dataframes.\n",
    "frames = [dfBasinOut, dfCountyOut]\n",
    "dfout = pd.concat(frames).reset_index(drop=True)\n",
    "print(len(dfout))\n",
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeframeStart & TimeframeEnd\n",
    "\n",
    "dfout['in_TimeframeStart'] = '01/01/' + dfout['Year'].astype(str)\n",
    "dfout['in_TimeframeEnd'] = '12/31/' + dfout['Year'].astype(str)\n",
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating BeneficialUse\n",
    "BeneficialUseDict = {\n",
    "    \"COM\" : \"Commercial\",\n",
    "    \"CON\" : \"Construction\",\n",
    "    \"DOM\" : \"Domestic\",\n",
    "    \"ENV\" : \"Environmental\",\n",
    "    \"IND\" : \"Industrial\",\n",
    "    \"IRR\" : \"Irrigation\",\n",
    "    \"MM\" : \"Mining and Milling\",\n",
    "    \"MUN\" : \"Municipal\",\n",
    "    \"PWR\" : \"Power\",\n",
    "    \"QM\" : \"Quasi-Municipal\",\n",
    "    \"REC\" : \"Recreational\",\n",
    "    \"STK\" : \"Stockwater\",\n",
    "    \"WLD\" : \"Wildlife\"}\n",
    "def assignBeneficialUse(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = \"Unspecified\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()\n",
    "        try:\n",
    "            outList = BeneficialUseDict[String1]\n",
    "        except:\n",
    "            outList = \"Unspecified\"\n",
    "\n",
    "    return outList\n",
    "\n",
    "dfout['in_BeneficialUseCategory'] = dfout.apply(lambda row: assignBeneficialUse(row['NV_BenUse']), axis=1)\n",
    "dfout['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_VariableSpecificCV Info\n",
    "dfout['in_VariableSpecificCV'] = \"Withdrawal_Annual_\" + dfout['in_BeneficialUseCategory'] + \"_Groundwater\"\n",
    "dfout['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapefile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basin Shapefile input\n",
    "basinShape = gpd.read_file('shapefile/NVBasinShapefile.shp')\n",
    "print(len(basinShape))\n",
    "basinShape.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columnsList = ['RU_Name', 'RU_Type', 'geometry']\n",
    "dfNVBshape = pd.DataFrame(columns=columnsList)\n",
    "dfNVBshape['RU_Name'] = basinShape['BasinName']\n",
    "dfNVBshape['RU_Type'] = \"Basin\"\n",
    "dfNVBshape['geometry'] = basinShape['geometry']\n",
    "dfNVBshape = dfNVBshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfNVBshape.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coutny Shapefile input\n",
    "countyShape = gpd.read_file('shapefile/NVCountyShapefile.shp')\n",
    "print(len(countyShape))\n",
    "countyShape.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['RU_Name', 'RU_Type', 'geometry']\n",
    "dfNVCshape = pd.DataFrame(columns=columnsList)\n",
    "dfNVCshape['RU_Name'] = countyShape['County']\n",
    "dfNVCshape['RU_Type'] = \"County\"\n",
    "dfNVCshape['geometry'] = countyShape['geometry']\n",
    "dfNVCshape = dfNVCshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfNVCshape.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate basin and county shape dataframes together.\n",
    "frames = [dfNVBshape, dfNVCshape]\n",
    "dfAllShape = pd.concat(frames).reset_index(drop=True)\n",
    "dfAllShape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Output Data & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dfout.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dfAllShape.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out to CSV.\n",
    "dfout.to_csv('P_nvAggMaster.csv', index=False) # The output.\n",
    "dfAllShape.to_csv('P_nvGeometry.csv', index=False) # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
