{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Idaho Allocation data for WaDEQA upload.\n",
    "- Purpose:  To pre-process the Idaho data into one master file for simple DataFrame creation and extraction.  Working Idaho data for WaDEQA 2.0 is mostly composed of point of diversion data.\n",
    "- Notes: working with POD and POU data.  Working with assumption that both POD and POU data share the same water right record information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Idaho/WaterAllocation\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POD Sites Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# POD Data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# read in shapefile data, then just export a zipped csv.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m FI_POD \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRawInputData/shapefiles/Water_Right_PODs.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m dfinPOD \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFI_POD\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m dfinPOD \u001b[38;5;241m=\u001b[39m dfinPOD\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# don't want geometry for POD sites.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# WaDE UUID tracker for data assessment\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\geopandas\\io\\file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_fiona(\n\u001b[0;32m    298\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    299\u001b[0m     )\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\geopandas\\io\\file.py:395\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[1;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m    392\u001b[0m         [record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m f_filt], columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    393\u001b[0m     )\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 395\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mGeoDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf_filt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m datetime_fields:\n\u001b[0;32m    399\u001b[0m     as_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[k], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:641\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[1;34m(cls, features, crs, columns)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__geo_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    639\u001b[0m     feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39m__geo_interface__\n\u001b[0;32m    640\u001b[0m row \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    642\u001b[0m }\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# load properties\u001b[39;00m\n\u001b[0;32m    644\u001b[0m properties \u001b[38;5;241m=\u001b[39m feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shapely\\geometry\\geo.py:96\u001b[0m, in \u001b[0;36mshape\u001b[1;34m(context)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _empty_shape_for_no_coordinates(geom_type)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m geom_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoordinates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m geom_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinestring\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LineString(ob[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shapely\\geometry\\point.py:78\u001b[0m, in \u001b[0;36mPoint.__new__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(coords\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mnumber):\n\u001b[0;32m     77\u001b[0m     coords \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m coords]\n\u001b[1;32m---> 78\u001b[0m geom \u001b[38;5;241m=\u001b[39m \u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(geom, Point):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid values passed to Point constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shapely\\decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[0;32m     76\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shapely\\creation.py:74\u001b[0m, in \u001b[0;36mpoints\u001b[1;34m(coords, y, z, indices, out, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m coords \u001b[38;5;241m=\u001b[39m _xyz_to_coords(coords, y, z)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mpoints(coords, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m simple_geometries_1d(coords, indices, GeometryType\u001b[38;5;241m.\u001b[39mPOINT, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# POD Data\n",
    "# read in shapefile data, then just export a zipped csv.\n",
    "FI_POD = \"RawInputData/shapefiles/Water_Right_PODs.zip\"\n",
    "dfinPOD = gpd.read_file(FI_POD).replace(np.nan, \"\")\n",
    "dfinPOD = dfinPOD.drop(['geometry'], axis=1) # don't want geometry for POD sites.\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOD:\n",
    "    dfinPOD['WaDEUUID'] = \"idD\" + dfinPOD.index.astype(str)\n",
    "    dfinPOD.to_csv('RawInputData/Water_Right_PODs.zip', compression=dict(method='zip', archive_name='Water_Right_PODs.csv'), index=False)\n",
    "\n",
    "print(len(dfinPOD))\n",
    "dfinPOD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOD['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"IDwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"IDwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"IDwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfinPOD['Source'].replace(np.nan, \"\").astype(str).astype(str).str.title()\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = \"\" # autfo fill in below\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = dfinPOD['DataSource']\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOD['Latitude']\n",
    "df['in_Longitude'] = dfinPOD['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = dfinPOD['DiversionN']\n",
    "df['in_SiteNativeID'] = \"POD\" + dfinPOD['PointOfDiv'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"ID\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = dfinPOD['Basis']\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfinPOD['OverallMax'].astype(float)\n",
    "df['in_AllocationLegalStatusCV'] = dfinPOD['Status']\n",
    "df['in_AllocationNativeID'] =  dfinPOD['WaterRight'].replace(\"\", 0).fillna(0).astype(str)\n",
    "df['in_AllocationOwner'] = dfinPOD['Owner']\n",
    "df['in_AllocationPriorityDate'] = dfinPOD['PriorityDa']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfinPOD['OverallM_1'].astype(float)\n",
    "df['in_BeneficialUseCategory'] = dfinPOD['Uses']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfinPOD['WRReport']\n",
    "\n",
    "outPOD = df.copy()\n",
    "outPOD = outPOD.drop_duplicates().reset_index(drop=True).replace(np.nan, '')\n",
    "print(len(outPOD))\n",
    "outPOD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POU Site Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POU - use shapefile\n",
    "# read in shapefile data, then just export a zipped csv.\n",
    "FI_POU = \"RawInputData/shapefiles/WaterRightPOUs.zip\"\n",
    "dfinPOU = gpd.read_file(FI_POU).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOU:\n",
    "    dfinPOU['WaDEUUID'] = \"idU\" + dfinPOU.index.astype(str)\n",
    "    dfinPOU.to_csv('RawInputData/WaterRightPOUs.zip', compression=dict(method='zip', archive_name='WaterRightPOUs.csv'), index=False)\n",
    "\n",
    "print(len(dfinPOU))\n",
    "dfinPOU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POU dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOU['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"IDwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"IDwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"IDwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfinPOU['Source'].replace(np.nan, \"\").astype(str).str.title()\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = \"\" # autfo fill in below\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"Centroid\"\n",
    "df['in_County'] = \"WaDE Unspecified\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOU['cent_Latit']\n",
    "df['in_Longitude'] = dfinPOU['cent_Longi']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POU\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"POU\" + dfinPOU['PlaceOfUse'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"ID\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = \"\"\n",
    "df['in_AllocationLegalStatusCV'] = dfinPOU['Status']\n",
    "df['in_AllocationNativeID'] =  dfinPOU['WaterRight'].replace(\"\", 0).fillna(0).astype(str)\n",
    "df['in_AllocationOwner'] = dfinPOU['Owner']\n",
    "df['in_AllocationPriorityDate'] = dfinPOU['PriorityDa']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = \"\"\n",
    "df['in_BeneficialUseCategory'] = dfinPOU['WaterUse']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfinPOU['AcreLimit']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfinPOU['WRReport']\n",
    "\n",
    "outPOU = df.copy()\n",
    "outPOU = outPOU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOU))\n",
    "outPOU.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outPOD, outPOU]\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix ID Owner Name\n",
    "# Given ID Owner is not full concatenated record. Use provided xlsx from Danielle Favreau to fix.\n",
    "\n",
    "fileInput = \"ownername_USactingThrough_WaDE_05112023.xlsx\"\n",
    "df_idown = pd.read_excel(fileInput)\n",
    "df_idown['WRNO'] = df_idown['WRNO'].replace(\" \", \"\").replace(\"\", 0).fillna(0).astype(str).str.strip()\n",
    "df_idown['OrgName2'] = df_idown['OrgName2'].replace(\"DIRECTOR PN CODE-\", \"\").astype(str).str.strip()\n",
    "IdahoOwnerNameFixdict = pd.Series(df_idown.OrgName2.values, index=df_idown.WRNO.astype(str)).to_dict()\n",
    "\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveOwnerName(valID, valOwn):\n",
    "    try:\n",
    "        outString = IdahoOwnerNameFixdict[valID]\n",
    "    except:\n",
    "        outString = valOwn\n",
    "    return outString\n",
    "\n",
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: retrieveOwnerName(row['in_AllocationNativeID'], row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean owner name up\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID POD source data has a few names that contain a ',' in them, but should still be okay\n",
    "outdf['in_SiteName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_CoordinateMethodCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_CoordinateMethodCV']), axis=1)\n",
    "outdf['in_CoordinateMethodCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationBasisCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationBasisCV']), axis=1)\n",
    "outdf['in_AllocationBasisCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationLegalStatusCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaterSourceType\n",
    "# searach water source name for keywords\n",
    "\n",
    "WaterSourceTypeDict = {\n",
    "\"sub\" : \"Groundwater\",\n",
    "\"ground water\" : \"Groundwater\",\n",
    "\"canal\" :  \"Surface Water\",\n",
    "\"channel\" : \"Surface Water\",\n",
    "\"creek\" : \"Surface Water\",\n",
    "\"ditch\" : \"Surface Water\",\n",
    "\"drain\" : \"Surface Water\",\n",
    "\"drains\" : \"Surface Water\",\n",
    "\"draw\" : \"Surface Water\",\n",
    "\"dry\" : \"Surface Water\",\n",
    "\"fork\" : \"Surface Water\",\n",
    "\"gluch\" : \"Surface Water\",\n",
    "\"gulch\": \"Surface Water\",\n",
    "\"hole\" : \"Surface Water\",\n",
    "\"holes\" : \"Surface Water\",\n",
    "\"hollow\"  : \"Surface Water\",\n",
    "\"lake\" :  \"Surface Water\",\n",
    "\"lakes\" :  \"Surface Water\",\n",
    "\"pond\" :  \"Surface Water\",\n",
    "\"reservoir\" : \"Surface Water\",\n",
    "\"river\" : \"Surface Water\",\n",
    "\"runoff\" : \"Surface Water\",\n",
    "\"seep\" : \"Surface Water\",\n",
    "\"slough\" : \"Surface Water\",\n",
    "\"spring\" :  \"Surface Water\",\n",
    "\"springs\" :  \"Surface Water\",\n",
    "\"spr\" :  \"Surface Water\",\n",
    "\"stream\" : \"Surface Water\",\n",
    "\"streams\" : \"Surface Water\",\n",
    "\"surface\" : \"Surface Water\",\n",
    "\"swamp\" : \"Surface Water\",\n",
    "\"swamps\" : \"Surface Water\",\n",
    "\"wash\" : \"Surface Water\",\n",
    "\"fargo wasteway\" : \"Surface Water\",\n",
    "\"frozen dog wasteway\" : \"Surface Water\",\n",
    "\"tunnel no 7 wasteway\" : \"Surface Water\",\n",
    "\"waste water\" : \"Reuse\",\n",
    "\"wastewater\" : \"Reuse\",\n",
    "\"treated municipal wastewater\" : \"Reuse\"}\n",
    "\n",
    "def assignWaterSourceType(val):\n",
    "    val = val.lower().strip()\n",
    "    if val == \"\" or pd.isnull(val):\n",
    "        outList = \"\"\n",
    "    elif val == \"ground water\": \n",
    "        outList = \"Groundwater\"\n",
    "    else:\n",
    "        for i in WaterSourceTypeDict.keys():\n",
    "            if i in val:\n",
    "                outList = WaterSourceTypeDict[i]\n",
    "                break\n",
    "            else:\n",
    "                outList = \"\"\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: assignWaterSourceType(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude & in_Longitude\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').fillna(\"\")\n",
    "outdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_IrrigatedAcreage datatype\n",
    "outdf['in_IrrigatedAcreage'] = pd.to_numeric(outdf['in_IrrigatedAcreage'], errors='coerce').fillna(\"\")\n",
    "outdf['in_IrrigatedAcreage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str) + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching gemetry to csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefile input\n",
    "# use same as input above\n",
    "\n",
    "dfPoUshapetemp = dfinPOD.copy()\n",
    "print(len(dfPoUshapetemp))\n",
    "dfPoUshapetemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp['PlaceOfUse'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('RawInputData/Pwr_idMain.zip', compression=dict(method='zip', archive_name='Pwr_idMain.csv'), index=False) # The output, save as a zip\n",
    "dfPoUshape.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
