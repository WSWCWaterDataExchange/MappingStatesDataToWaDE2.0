{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f571be",
   "metadata": {},
   "source": [
    "# Data Assessment & Analytics for Reservoir and Observation Site Time Series Water Use\n",
    "Notes:\n",
    "- change os directory location\n",
    "- be aware of the number of provdied native source data files\n",
    "- beware of of what data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import geoplot as gplt  # for plotting maps and geo-data\n",
    "import geoplot.crs as gcrs  #used to pull in webdata related to maps and geo-data\n",
    "import missingno as msno # creates a matrix chart to show missing values\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go  # for subplot creation\n",
    "from plotly.subplots import make_subplots  # for subplot creation\n",
    "import matplotlib.pyplot as mplt  # use with gplt to save fig to pdf\n",
    "\n",
    "# ---- cleanup ----\n",
    "import re # string regular expression manipulation\n",
    "from datetime import datetime # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24dccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = os.getcwd() # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- where to find input files ----\n",
    "InputFolderString = #\"G:/Shared drives/WaDE Data/Texas/SS_ReservoirsObservationSites\" # set this to where input files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Native Input Data\n",
    "# #################################################################\n",
    "# # ---- This needs to be custom per state ----\n",
    "\n",
    "# # Data Set 1: -\n",
    "# dfin1 = pd.read_csv(InputFolderString + '/RawinputData/-.zip')\n",
    "\n",
    "# # # Data Set 2: --\n",
    "# # dfin2 = pd.read_csv(InputFolderString + '/RawinputData/--.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaDE Processed Input Data\n",
    "#################################################################\n",
    "\n",
    "dfm = pd.read_csv(InputFolderString + \"/ProcessedInputData/methods.csv\", encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "dfv = pd.read_csv(InputFolderString + \"/ProcessedInputData/variables.csv\", encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "dfo = pd.read_csv(InputFolderString + \"/ProcessedInputData/organizations.csv\", encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "dfws = pd.read_csv(InputFolderString + \"/ProcessedInputData/watersources.csv\").replace(np.nan, \"\")\n",
    "dfwspurge = pd.read_csv(InputFolderString + \"/ProcessedInputData/watersources_missing.csv\").replace(np.nan, \"\")\n",
    "\n",
    "dfs = pd.read_csv(InputFolderString + \"/ProcessedInputData/sites.csv\").replace(np.nan, \"\")\n",
    "dfspurge = pd.read_csv(InputFolderString + \"/ProcessedInputData/sites_missing.csv\").replace(np.nan, \"\")\n",
    "\n",
    "dfsa = pd.read_csv(InputFolderString + \"/ProcessedInputData/sitespecificamounts.csv\").replace(np.nan, \"\")\n",
    "dfsapurge = pd.read_csv(InputFolderString + \"/ProcessedInputData/sitespecificamounts_missing.csv\").replace(np.nan, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff4e59",
   "metadata": {},
   "source": [
    "# Water Source Info (watersources.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a506fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(dfws))\n",
    "dfws.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.bar(dfws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'WaterSourceTypeCV'\n",
    "for x in dfws['WaterSourceTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6701f3",
   "metadata": {},
   "source": [
    "# Site Info (sites.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0995e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(dfs))\n",
    "dfs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ba2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.bar(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'CoordinateMethodCV'\n",
    "for x in dfs['CoordinateMethodCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c269f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'SiteTypeCV'\n",
    "for x in dfs['SiteTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7fb8ad-b6a8-4cba-896f-288ad074ebee",
   "metadata": {},
   "source": [
    "# Site-Specific Amount Info (sitespecificamounts.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71945f5-b979-42fc-ab2a-6c116d086896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfsa))\n",
    "dfsa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51025c04-4ca2-4cd0-8718-b0375bc9f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.bar(dfsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c3370-02e9-42dd-b4e3-2c6bf1fcd653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'BeneficialUseCategory'\n",
    "uniqueList = list(set([i.strip() for i in ','.join(dfsa['BeneficialUseCategory'].astype(str)).split(',')]))\n",
    "uniqueList.sort()\n",
    "uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddd8f3-bd5c-4578-9a56-cb120dc3f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_CropTypeCV'\n",
    "for x in dfsa['CropTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42f827-2905-4ee2-9583-d414d35f9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_CustomerTypeCV'\n",
    "for x in dfsa['CustomerTypeCV'].astype(str).sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bac778-6639-438c-8920-e098fa158714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_PopulationServed'\n",
    "for x in dfsa['PopulationServed'].astype(str).sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12f5a3-b50f-4c76-88c2-03a7f9fc6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_ReportYearCV'\n",
    "for x in dfsa['ReportYearCV'].astype(str).sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6a04e-1daf-4a8e-a096-947ec241dda1",
   "metadata": {},
   "source": [
    "## Markdown Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eef5d9-8bbd-44a5-b176-3392de8f84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method.csv\n",
    "try:\n",
    "  dftmp = dfm.loc[[0]].drop(['MethodDescription'], axis=1).copy().to_markdown()\n",
    "except:\n",
    "  dftmp = dfm.drop(['MethodDescription'], axis=1).copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f97bf-9e96-427d-9f37-a695132708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable.csv\n",
    "try:\n",
    "  dftmp = dfv.loc[[0]].copy().to_markdown()\n",
    "except:\n",
    "  dftmp = dfv.copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae894a-8562-49b8-8c31-c0fe98e1ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizations.csv\n",
    "try:\n",
    "  dftmp = dfo.loc[[0]].copy().to_markdown()\n",
    "except:\n",
    "  dftmp = dfo.copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a7493-14c5-4ec1-8372-6a848a3d1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watersources.csv\n",
    "try:\n",
    "  dftmp = dfws.loc[[0]].copy().to_markdown()\n",
    "except:\n",
    "  dftmp = dfws.copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d7b0b-8168-4e20-91bf-997f8b34ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites.csv\n",
    "try:\n",
    "  dftmp = dfs.loc[[0]].drop(['Geometry'], axis=1).copy().to_markdown()\n",
    "except:\n",
    "  dftmp = dfs.drop(['Geometry'], axis=1).copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791c4d6-0c96-4ffc-9d7a-0b82eb7d065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sitespecificamounts.csv\n",
    "try:\n",
    "  dftmp = dfsa.loc[[0]].copy().to_markdown()\n",
    "except:\n",
    "  dftmp = dfsa.copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd1cc8-df83-4dae-83fc-05aa9ba05aef",
   "metadata": {},
   "source": [
    "## Num of Record Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ebd77-c7e8-4b43-82fd-35c143db610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of entries of source data\n",
    "print(f\"Num of Source #1 Entries (rows): \", \"|\", len(dfin1))\n",
    "# print(f\"Num of Source #2 Entries (rows): \", \"|\", len(dfin2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec2965-5482-4803-a30e-3e211fdd3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of entries compiled into WaDE\n",
    "podString =  len(dfs[dfs['PODorPOUSite'] == 'POD'])\n",
    "pouString=  len(dfs[dfs['PODorPOUSite'] == 'POU'])\n",
    "saString = len(dfsa)\n",
    "print(\"Dataset  | Num of Identified PODs | Num of Identified POUs | Num of Identified Time Series Records\")\n",
    "print(\"**Compiled WaDE Data** |\", podString, \"|\", pouString, \"|\", saString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce8fa67",
   "metadata": {},
   "source": [
    "## Why Removed Records Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70010938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Reasons why records were removed from water source info ----\")\n",
    "if len(dfwspurge) != 0:\n",
    "    print(dfwspurge['ReasonRemoved'].value_counts().astype(str) + \" | removed from watersources.csv input\")\n",
    "else:\n",
    "    print(\"...nothing removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18752994",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ---- Reasons why records were removed from site info ---- \")\n",
    "if len(dfspurge) != 0:\n",
    "    print(dfspurge['ReasonRemoved'].value_counts().astype(str) + \" | removed from sites.csv input\")\n",
    "else:\n",
    "    print(\"...nothing removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88495a-6e23-4abf-bcbc-38445ae511be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ---- Reasons why records were removed from site specific amounts  info ---- \")\n",
    "if len(dfsapurge) != 0:\n",
    "    print(dfsapurge['ReasonRemoved'].value_counts().astype(str) + \" | removed from sitespecificamounts.csv input\")\n",
    "else:\n",
    "    print(\"...nothing removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee4707",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- merge watersource.csv to sites.csv ----\n",
    "\n",
    "# explode site.csv on WaterSourceUUIDs\n",
    "dfstemp = dfs.copy()\n",
    "dfstemp = dfstemp.assign(WaterSourceUUIDs=dfstemp['WaterSourceUUIDs'].str.split(',')).explode('WaterSourceUUIDs').reset_index(drop=True)\n",
    "\n",
    "# merge\n",
    "dfstemp_ws = pd.merge(dfstemp, dfws[['WaterSourceUUID', 'WaterSourceTypeCV']], left_on='WaterSourceUUIDs', right_on='WaterSourceUUID', how='left')\n",
    "\n",
    "# groupby site-watersource.csv via SiteUUID\n",
    "dfstemp_ws = dfstemp_ws.groupby('SiteUUID').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem != \"\"])).replace(np.nan, \"\").reset_index()\n",
    "\n",
    "print(len(dfstemp_ws))\n",
    "dfstemp_ws.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a939e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Num of POD sites vs POU sites ----\n",
    "print(dfstemp_ws.PODorPOUSite.value_counts())\n",
    "\n",
    "fig = px.histogram(dfstemp_ws, x=\"PODorPOUSite\", text_auto=True)\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of PODorPOUSite Entries in sites.csv\",\n",
    "                  xaxis_title=\"PODorPOUSite Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/PODorPOUSite.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cf685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Num of sites via WatersourceTypeCV ----\n",
    "print(dfstemp_ws.WaterSourceTypeCV.value_counts())\n",
    "\n",
    "fig = px.histogram(dfstemp_ws, x=\"WaterSourceTypeCV\", text_auto=True)\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of WaterSourceTypeCV Entries in sites.csv\",\n",
    "                  xaxis_title=\"WaterSourceTypeCV Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/WaterSourceTypeCV.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51679d23-9677-47d3-be98-72c6fff3e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryUseCategory: histogram distribution of WaDE values\n",
    "print(dfsa.PrimaryUseCategory.value_counts())\n",
    "\n",
    "fig = px.histogram(dfsa, x=\"PrimaryUseCategory\", text_auto=True)\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of PrimaryUseCategory Entries in sitespecificamounts.csv\",\n",
    "                  xaxis_title=\"PrimaryUseCategory Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/PrimaryUseCategory.pdf', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519c683-21ac-4143-a115-4028466dd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Amount: Boxplot distribution of WaDE values ----\n",
    "\n",
    "try: \n",
    "    trace1 = go.Violin(x=dfsa['Amount'], points='outliers', name='Violin Plot')\n",
    "    trace2 = go.Histogram(x=dfsa['Amount'], name='Historgram')\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    fig.add_trace(trace1, row=1, col=1)\n",
    "    fig.add_trace(trace2, row=2, col=1)\n",
    "\n",
    "    fig.update_layout(showlegend=False, bargap=0.2, title=\"Amount Distribution in sitespecificamounts.csv\", font=dict(family=\"Arial Bold\", size=12,color=\"Black\"))\n",
    "    fig.update_xaxes(title_text=\"Amount Value\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Amount Value\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Num. of Records (log)\", row=2, col=1, type=\"log\")\n",
    "    fig.show(renderer=\"png\")\n",
    "    fig.write_image('figures/Amount.png', engine=\"kaleido\")\n",
    "\n",
    "except: print('Could not plot Amount value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c27f1-a506-4027-9d8a-ed9a2d2f2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Map of Points sites ----\n",
    "\n",
    "dfstemp = dfstemp_ws.copy()\n",
    "dfstemp = dfstemp[dfstemp['Geometry'] == ''].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "    ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "    gdfstemp = gpd.GeoDataFrame(dfstemp, geometry=gpd.points_from_xy(dfstemp.Longitude.astype(float), dfstemp.Latitude.astype(float)), crs=\"EPSG:4326\")\n",
    "    gplt.pointplot(gdfstemp, hue='WaterSourceTypeCV', edgecolor='lightgray', linewidth=0.5, legend=True, legend_var='hue', ax=ax)\n",
    "    mplt.savefig(format=\"png\", fname='figures/PointMap.png') \n",
    "except:\n",
    "    print('No point data to plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc755d8",
   "metadata": {},
   "source": [
    "# Removed Records compared to Source Data\n",
    "- this is working just fine, just want to comment out temporarily for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79220931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explode purge.xlsx files by WaDEUUID, concat together\n",
    "# #################################################################\n",
    "\n",
    "# # Explode watersources_missing.xlsx records by WaDEUUID\n",
    "# dfwspurgeCopy = dfwspurge.assign(WaDEUUID=dfwspurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "# dfwspurgeCopy = dfwspurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# # Explode sites_missing.xlsx records by WaDEUUID\n",
    "# dfspurgeCopy = dfspurge.assign(WaDEUUID=dfspurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "# dfspurgeCopy = dfspurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# # Explode waterallocations_missing.xlsx records by WaDEUUID\n",
    "# dfaapurgeCopy = dfaapurge.assign(WaDEUUID=dfaapurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "# dfaapurgeCopy = dfaapurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# # concat purge dataframes togehter\n",
    "# frames = [dfwspurgeCopy, dfspurgeCopy, dfaapurgeCopy] \n",
    "# dfWaDEUUID = pd.concat(frames)\n",
    "# dfWaDEUUID = dfWaDEUUID.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "# print(len(dfWaDEUUID))\n",
    "# dfWaDEUUID.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c080897",
   "metadata": {},
   "source": [
    "# Custom Queries and Analysis for this Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N/A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
