{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Washington Allocation data for WaDE upload.\n",
    "- Purpose:  To preprocess the Washington data into one master file for simple DataFrame creation and extraction\n",
    "\n",
    "Useful Links to Data:\n",
    "- The Data - Geographic Water Information System (GWIS)Data from the WA stat: https://fortress.wa.gov/ecy/gispublic/DataDownload/wr/GWIS_Data/\n",
    "- Data dictionary - https://fortress.wa.gov/ecy/gispublic/DataDownload/wr/GWIS_Data/GWIS_Data_Dictionary/\n",
    "- Public website   - https://ecology.wa.gov/Water-Shorelines/Water-supply/Water-rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Needed Libraries\n",
    "\n",
    "# working with data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Washington/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File, contains PoD info\n",
    "d_pointFile = \"shapefiles/D_Point.zip\"\n",
    "#df_1 = gpd.read_file(d_pointFile, encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "df_1 = gpd.read_file(d_pointFile)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in df_1:\n",
    "    df_1['WaDEUUID'] = \"waD\" + df_1.index.astype(str)\n",
    "    df_1.to_csv('D_Point.zip', compression=dict(method='zip', archive_name='D_Point.csv'), index=False)\n",
    "\n",
    "df_1['D_Point_ID'] = df_1['D_Point_ID'].astype(int)\n",
    "print(len(df_1))\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File, Bridge table\n",
    "D_Point_WR_DocFile = \"D_Point_WR_Doc.zip\"\n",
    "df_2 = pd.read_csv(D_Point_WR_DocFile, encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "df_2['D_Point_ID'] = df_2['D_Point_ID'].replace(\"\", 0).fillna(0).astype(float).astype(int)\n",
    "print(len(df_2))\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File, Contains water use and owner info\n",
    "Person_Plus_EXTRACT_FromWRTSnotGWISFile = \"Person_Plus_EXTRACT_FromWRTSnotGWIS.zip\"\n",
    "df_3 = pd.read_csv(Person_Plus_EXTRACT_FromWRTSnotGWISFile, encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "print(len(df_3))\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes into one, using left-join.\n",
    "dfinPOD = pd.DataFrame()\n",
    "dfinPOD = pd.merge(df_1, df_2, left_on='D_Point_ID', right_on='D_Point_ID', how='left') # Joinning PoD data\n",
    "dfinPOD = pd.merge(dfinPOD, df_3, left_on=dfinPOD.WR_Doc_ID.replace(\"\", 0).fillna(0).astype(int).astype(str).str.strip(), right_on=df_3.WR_Doc_ID.replace(\"\", 0).fillna(0).astype(int).astype(str).str.strip(), how='left') # Joinning PoD data\n",
    "\n",
    "dfinPOD = dfinPOD.drop_duplicates().replace(np.nan, \"\").replace(\"nan,nan\", \"\").reset_index(drop=True)\n",
    "print(len(dfinPOD))\n",
    "dfinPOD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix owner name\n",
    "\n",
    "def assignOwner(valueFirst, valueMid, valueLast):\n",
    "    #--- First Name ---\n",
    "    if valueFirst == \"\" or pd.isnull(valueFirst):\n",
    "        FirstName = \"\"\n",
    "    else:\n",
    "        FirstName = str(valueFirst).strip()\n",
    "        \n",
    "    #--- Midile Initial ---\n",
    "    if valueMid == \"\" or pd.isnull(valueMid):\n",
    "        MidName = \"\"\n",
    "    else:\n",
    "        MidName = str(valueMid).strip()\n",
    "    \n",
    "    #--- Last Name ---\n",
    "    if valueLast == \"\" or pd.isnull(valueLast):\n",
    "        LastName = \"\"\n",
    "    else:\n",
    "        LastName = str(valueLast).strip()\n",
    "\n",
    "    if LastName == \"\":\n",
    "        outlist = LastName + FirstName + MidName\n",
    "    else:\n",
    "        outlist = LastName + \", \" + FirstName + \" \"+ MidName\n",
    "        \n",
    "    outlist = re.sub(\"[$@&.;,/\\)(-]\", \"\", outlist).title().replace(\"  \", \" \").strip()\n",
    "    \n",
    "    return outlist\n",
    "\n",
    "\n",
    "dfinPOD['Owner'] = dfinPOD.apply(lambda row: assignOwner(row['PersonFirstNM'],\n",
    "                                               row['PersonMINM'],\n",
    "                                               row['PersonLastOrOrganizationNM']), axis=1)\n",
    "dfinPOD['Owner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating AllocationAmount\n",
    "def assignAllocationAmount(colrowValueIQ, colrowValueUC):\n",
    "    if colrowValueIQ == '' or pd.isnull(colrowValueIQ):\n",
    "        outVal = \"\"\n",
    "    elif colrowValueIQ <= 0 or pd.isnull(colrowValueIQ):\n",
    "        outVal = 0\n",
    "    else:\n",
    "        MultiFactor = 1.0\n",
    "        gpmcfsUnit = colrowValueUC.strip()\n",
    "        if gpmcfsUnit == 'GPM':\n",
    "            MultiFactor = 0.00222800926\n",
    "        elif gpmcfsUnit == 'GPD':\n",
    "            MultiFactor = 1.0 / 646317.0\n",
    "        try:\n",
    "            outVal = MultiFactor * colrowValueIQ\n",
    "        except:\n",
    "            outVal = colrowValueIQ\n",
    "    return outVal\n",
    "\n",
    "dfinPOD['in_AllocationFlow_CFS'] = dfinPOD.apply(lambda row: assignAllocationAmount(row['InstantaneousQuantity'], row['InstantaneousUnitCode']), axis=1)\n",
    "dfinPOD['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Sites where ASSOC_FL != 'Y'\n",
    "# remove Polygons where WR_Doc_ID_x == \"\"\n",
    "dfinPOD = dfinPOD[dfinPOD['Assoc_FL'] == 'Y'].reset_index(drop=True)\n",
    "dfinPOD = dfinPOD[dfinPOD['WR_Doc_ID_x'] != \"\"].reset_index(drop=True)\n",
    "print(len(dfinPOD))\n",
    "dfinPOD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOD['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"WAwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"WAwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"WAwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = dfinPOD['WaRecRCWClassTypeCode'].str.title().str.strip()\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = dfinPOD['Location_C']\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOD['Latitude']\n",
    "df['in_Longitude'] = dfinPOD['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"POD\" + dfinPOD['D_Point_ID'].replace(\"\", 0).fillna(0).astype(float).astype(int).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = dfinPOD['D_Point_Ty']\n",
    "df['in_StateCV'] = \"WA\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfinPOD['in_AllocationFlow_CFS']\n",
    "df['in_AllocationLegalStatusCV'] = dfinPOD['WaRecProcessStatusTypeCode']\n",
    "df['in_AllocationNativeID'] =  \"wa\" + dfinPOD['WR_Doc_ID_x'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_AllocationOwner'] = dfinPOD['Owner']\n",
    "df['in_AllocationPriorityDate'] = dfinPOD['PriorityDate']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = dfinPOD['WaRecPhaseTypeCode']\n",
    "df['in_AllocationVolume_AF'] = dfinPOD['AnnualVolumeQuantity']\n",
    "df['in_BeneficialUseCategory'] = dfinPOD['PurposeOfUseTypeCodes'].astype(str)\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfinPOD['IrrigatedAreaQuantity']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = \"https://appswr.ecology.wa.gov/waterrighttrackingsystem/WaterRights/WaterRightRecord.aspx?waRecId=\" + dfinPOD['WaRecId'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "\n",
    "outPOD = df.copy()\n",
    "outPOD = outPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOD))\n",
    "outPOD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - PoU Shapefile Data\n",
    "# export dataframe as zipped csv\n",
    "pouInput = 'shapefiles/WR_Doc_POU1.zip'\n",
    "df_1u = gpd.read_file(pouInput)\n",
    "#df_1u = df_1u.drop(['Field', 'geometry'], axis=1) # want to create a csv without the geometry in it, for visual inspection reasons.\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in df_1u:\n",
    "    df_1u['WaDEUUID'] = \"waU\" + df_1u.index.astype(str)\n",
    "    df_1u.to_csv('smWR_Doc_POU1.zip', compression=dict(method='zip', archive_name='smWR_Doc_POU1.csv'), index=False)\n",
    "\n",
    "df_1u = df_1u.drop_duplicates().reset_index(drop=True)\n",
    "print(len(df_1u))\n",
    "df_1u.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WaDE Specific SiteNativeID\n",
    "# temp fix for lack of site id value\n",
    "\n",
    "df_1u['in_SiteNativeID'] = \"wadeID\" + df_1u.index.astype(str)\n",
    "df_1u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes into one, using left-join.\n",
    "# df_u1 and df3\n",
    "dfinPOU = pd.DataFrame()\n",
    "dfinPOU = pd.merge(df_1u, df_3, left_on=df_1u.WR_DOC_ID.replace(\"\", 0).fillna(0).astype(float).astype(int).astype(str), \n",
    "                   right_on=df_3.WR_Doc_ID.replace(\"\", 0).fillna(0).astype(float).astype(int).astype(str), how='left')\n",
    "\n",
    "dfinPOU = dfinPOU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfinPOU))\n",
    "dfinPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignOwner(valueFirst, valueMid, valueLast):\n",
    "    #--- First Name ---\n",
    "    if valueFirst == \"\" or pd.isnull(valueFirst):\n",
    "        FirstName = \"\"\n",
    "    else:\n",
    "        FirstName = str(valueFirst).strip()\n",
    "        \n",
    "    #--- Midile Initial ---\n",
    "    if valueMid == \"\" or pd.isnull(valueMid):\n",
    "        MidName = \"\"\n",
    "    else:\n",
    "        MidName = str(valueMid).strip()\n",
    "    \n",
    "    #--- Last Name ---\n",
    "    if valueLast == \"\" or pd.isnull(valueLast):\n",
    "        LastName = \"\"\n",
    "    else:\n",
    "        LastName = str(valueLast).strip()\n",
    "\n",
    "    if LastName == \"\":\n",
    "        outlist = LastName + FirstName + MidName\n",
    "    else:\n",
    "        outlist = LastName + \", \" + FirstName + \" \"+ MidName\n",
    "        \n",
    "    outlist = re.sub(\"[$@&.;,/\\)(-]\", \"\", outlist).title().replace(\"  \", \" \").strip()\n",
    "    \n",
    "    return outlist\n",
    "\n",
    "\n",
    "dfinPOU['Owner'] = dfinPOU.apply(lambda row: assignOwner(row['PersonFirstNM'], row['PersonMINM'], row['PersonLastOrOrganizationNM']), axis=1)\n",
    "dfinPOU['Owner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating AllocationAmount\n",
    "def assignAllocationAmount(colrowValueIQ, colrowValueUC):\n",
    "    if colrowValueIQ == '' or pd.isnull(colrowValueIQ):\n",
    "        outVal = \"\"\n",
    "    elif colrowValueIQ <= 0 or pd.isnull(colrowValueIQ):\n",
    "        outVal = 0\n",
    "    else:\n",
    "        MultiFactor = 1.0\n",
    "        gpmcfsUnit = colrowValueUC.strip()\n",
    "        if gpmcfsUnit == 'GPM':\n",
    "            MultiFactor = 0.00222800926\n",
    "        elif gpmcfsUnit == 'GPD':\n",
    "            MultiFactor = 1.0 / 646317.0\n",
    "        try:\n",
    "            outVal = MultiFactor * colrowValueIQ\n",
    "        except:\n",
    "            outVal = colrowValueIQ\n",
    "    return outVal\n",
    "\n",
    "dfinPOU['in_AllocationFlow_CFS'] =  dfinPOU.apply(lambda row: assignAllocationAmount(row['InstantaneousQuantity'], row['InstantaneousUnitCode']), axis=1)\n",
    "dfinPOU['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfinPOU))\n",
    "dfinPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Polygons where WR_Doc_NR != '' (meaning their id field is blank)\n",
    "# remove Polygons where WR_DOC_ID == 99999 (99999 is their 'blank' value field)\n",
    "dfinPOU = dfinPOU[dfinPOU['WR_Doc_NR'] != \"\"].reset_index(drop=True)\n",
    "dfinPOU = dfinPOU[dfinPOU['WR_DOC_ID'] != 99999].reset_index(drop=True)\n",
    "print(len(dfinPOU))\n",
    "dfinPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOU['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"WAwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"WAwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"WAwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = dfinPOU['WaRecRCWClassTypeCode'].str.title().str.strip()\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOU['Latitude']\n",
    "df['in_Longitude'] = dfinPOU['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POU\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = dfinPOU['in_SiteNativeID']\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"WA\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfinPOU['in_AllocationFlow_CFS']\n",
    "df['in_AllocationLegalStatusCV'] = dfinPOU['WaRecProcessStatusTypeCode']\n",
    "df['in_AllocationNativeID'] = \"wa\" + dfinPOU['WR_Doc_ID'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_AllocationOwner'] = dfinPOU['Owner']\n",
    "df['in_AllocationPriorityDate'] = dfinPOU['PriorityDate']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = dfinPOU['WaRecPhaseTypeCode']\n",
    "df['in_AllocationVolume_AF'] = dfinPOU['AnnualVolumeQuantity']\n",
    "df['in_BeneficialUseCategory'] = dfinPOU['PurposeOfUseTypeCodes'].astype(str)\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfinPOU['IrrigatedAreaQuantity']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = \"https://appswr.ecology.wa.gov/waterrighttrackingsystem/WaterRights/WaterRightRecord.aspx?waRecId=\" + dfinPOU['WaRecId'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "\n",
    "outPOU = df.copy()\n",
    "outPOU = outPOU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOU))\n",
    "outPOU.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD & POU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outPOD, outPOU]\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating WaterSourceTypeCV\n",
    "wsTypeDict = {\n",
    "    \"Unspecified\" : \"Unspecified\",\n",
    "    \"Groundwater\" : \"Groundwater\",\n",
    "    \"Surfacewater\" : \"Surface Water\",\n",
    "    \"Reservoir\" : \"Reservoir\"}\n",
    "def assignWaterSourceTypeCV(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outList = \"WaDE Unspecified\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()\n",
    "        try:\n",
    "            outList = wsTypeDict[String1]\n",
    "        except:\n",
    "            outList = String1\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: assignWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Creating CoordinateAccuracy\n",
    "coordinateAccuracyDictWA = {\n",
    "    \"C\":\"field checked (without GPS)\",\n",
    "    \"G\":\"field checked with GPS\",\n",
    "    \"P\":\"proposed (does not exist in real world)\",\n",
    "    \"PA\":\"proposed and All-right (does not exist in real world)\",\n",
    "    \"PD\":\"proposed and Dubious (does not exist in real world)\",\n",
    "    \"PM\":\"proposed and Multiple Dubious (does not exist in real world)\",\n",
    "    \"PX\":\"proposed and Centroid Dubious (does not exist in real world)\",\n",
    "    \"U\":\"unchecked\",\n",
    "    \"UA\":\"unchecked and All-right\",\n",
    "    \"UD\":\"unchecked and Dubious\",\n",
    "    \"UM\":\"unchecked and Multiple Dubious\",\n",
    "    \"UX\":\"unchecked and Centroid Dubious\",\n",
    "    \"W\":\"from well log unchecked\",\n",
    "    \"WA\":\"from well log unchecked and All-right\",\n",
    "    \"WD\":\"from well log unchecked and Dubious\",\n",
    "    \"WX\":\"from well log unchecked and Centroid Dubious\"}\n",
    "def assignCoordinateAccuracy(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()\n",
    "        try:\n",
    "            outList = coordinateAccuracyDictWA[String1]\n",
    "        except:\n",
    "            outList = String1\n",
    "    return outList\n",
    "\n",
    "outdf['in_CoordinateAccuracy'] = outdf.apply(lambda row: assignCoordinateAccuracy(row['in_CoordinateAccuracy']), axis=1)\n",
    "outdf['in_CoordinateAccuracy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating SiteTypeCV\n",
    "UnknownSTCVDict = {\n",
    "    \"GC\":\"Ground Water Collector\",\n",
    "    \"HW\":\"Headworks Gravity Flow (or surface water device unknown)\",\n",
    "    \"ID\":\"Irrigation Dam\",\n",
    "    \"MW\":\"Monitoring Well\",\n",
    "    \"PM\":\"Surface Water Pump\",\n",
    "    \"RD\":\"Reservoir Dam\",\n",
    "    \"WL\":\"Well (or ground water device unknown)\"}\n",
    "def assignSiteTypeCV(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()  # remove whitespace chars\n",
    "        try:\n",
    "            outList = UnknownSTCVDict[String1]\n",
    "        except:\n",
    "            outList = String1\n",
    "\n",
    "    return outList\n",
    "\n",
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: assignSiteTypeCV(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating BeneficialUseCategory\n",
    "benUseDict = {\n",
    "    \"508-14\":\"508-14\",\n",
    "    \"AI\":\"Agricultural Irrigation\",\n",
    "    \"CI\":\"Commercial & indust\",\n",
    "    \"CM\":\"Commercial\",\n",
    "    \"CO\":\"Cooling for indust proces\",\n",
    "    \"DC\":\"Dust Control\",\n",
    "    \"DG\":\"Domestic general\",\n",
    "    \"DM\":\"Domestic multiple\",\n",
    "    \"DS\":\"Domestic single\",\n",
    "    \"DY\":\"Dairy\",\n",
    "    \"EN\":\"Environmental quality\",\n",
    "    \"FP\":\"Frost protection\",\n",
    "    \"FR\":\"Fire protection\",\n",
    "    \"FS\":\"Fish propagation\",\n",
    "    \"GP\":\"Groundwater Preservation\",\n",
    "    \"HE\":\"Heat Exchange\",\n",
    "    \"HP\":\"Heat protection for crops\",\n",
    "    \"HW\":\"Highway\",\n",
    "    \"IFlow\":\"Instream Flow\",\n",
    "    \"II\":\"Individual Irrigation\",\n",
    "    \"IR\":\"Irrigation\",\n",
    "    \"IT\":\"Municipal inter-tie system\",\n",
    "    \"IU\":\"Irrigation Unknown\",\n",
    "    \"MI\":\"Mining\",\n",
    "    \"MT\":\"Mitigation\",\n",
    "    \"MU\":\"Municipal\",\n",
    "    \"NR\":\"No Purpose Identified\",\n",
    "    \"OT\":\"Other\",\n",
    "    \"PO\":\"Power\",\n",
    "    \"PR\":\"Parks and Recreation\",\n",
    "    \"RE\":\"Recreation - beautification\",\n",
    "    \"RW\":\"Railway\",\n",
    "    \"SA\":\"Stream augmentation\",\n",
    "    \"SR\":\"Storage\",\n",
    "    \"ST\":\"Stock water\",\n",
    "    \"TS\":\"Test Well\",\n",
    "    \"TW-P\":\"Trust water Permanent\",\n",
    "    \"TW-T\":\"Trust water Temporary\",\n",
    "    \"WL\":\"Wildlife refuge\"}\n",
    "def assignBenUseCategory(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        keyStr = colrowValue.strip()\n",
    "        try:\n",
    "            benUseListStr = keyStr.split()  # Need to split WA csv data\n",
    "            outList = \", \".join(benUseDict[inx] for inx in benUseListStr)\n",
    "        except:\n",
    "            outList = \"\"\n",
    "    return outList\n",
    "\n",
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: assignBenUseCategory(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationTypeCV']), axis=1)\n",
    "outdf['in_AllocationTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationLegalStatusCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Longitude\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_IrrigatedAcreage datatype\n",
    "outdf['in_IrrigatedAcreage'] = pd.to_numeric(outdf['in_IrrigatedAcreage'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_IrrigatedAcreage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str) + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop non-Active AllocationLegalStatusCV Water Rights\n",
    "- For WA, we don't want water rights that are considered: Inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-active AllocationLegalStatusCV values specific to that state.\n",
    "\n",
    "# drop list\n",
    "dropLegalStatusList = [\"Inactive\"]\n",
    "\n",
    "# drop rows from above list\n",
    "outdf = outdf[outdf.in_AllocationLegalStatusCV.isin(dropLegalStatusList) == False].reset_index(drop=True)\n",
    "\n",
    "print(len(outdf))\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching gemetry to csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "# dfPoUshapetemp = gpd.read_file('shapefiles/smWR_Doc_POU1.zip')\n",
    "\n",
    "# # remove Polygons where WR_Doc_NR != '' (meaning their id field is blank)\n",
    "# # remove Polygons where WR_DOC_ID == 99999 (99999 is their 'blank' value field)\n",
    "# dfPoUshapetemp = dfPoUshapetemp[dfPoUshapetemp['WR_Doc_NR'] != \"\"].reset_index(drop=True)\n",
    "# dfPoUshapetemp = dfPoUshapetemp[dfPoUshapetemp['WR_DOC_ID'] != 99999].reset_index(drop=True)\n",
    "\n",
    "dfPoUshapetemp = dfinPOU.copy()\n",
    "\n",
    "print(len(dfPoUshapetemp))\n",
    "dfPoUshapetemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = dfPoUshapetemp['in_SiteNativeID'].replace(\"\", 0).fillna(0).astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('Pwr_waMain.zip', compression=dict(method='zip', archive_name='Pwr_waMain.csv'), index=False)  # The output, save as a zip\n",
    "dfPoUshape.to_csv('P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
