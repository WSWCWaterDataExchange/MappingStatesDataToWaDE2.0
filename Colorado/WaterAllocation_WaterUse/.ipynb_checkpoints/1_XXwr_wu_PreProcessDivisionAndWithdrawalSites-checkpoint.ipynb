{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing \"XX\" Water Right and Time Series Water Use data for WaDE Upload\n",
    "- Purpose:  To pre-process the data into one main file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"G:/Shared drives/WaDE Data/Colorado/WaterAllocation_WaterUse\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input 1 - DWR_Water_Right_-_Net_Amounts.zip\n",
    "- water right and site info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input File - asdf\n",
    "fileInput = \"RawInputData/DWR_Water_Right_-_Net_Amounts.zip\"\n",
    "dfin1 = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin1:\n",
    "    dfin1['WaDEUUID'] = \"in1\" + dfin1.index.astype(str)\n",
    "    dfin1.to_csv(\"RawInputData/DWR_Water_Right_-_Net_Amounts.zip\", compression=dict(method='zip', archive_name=\"DWR_Water_Right_-_Net_Amounts.csv\"), index=False)\n",
    "\n",
    "print(len(dfin1))\n",
    "dfin1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Beneficial Use.\n",
    "#Need to split CO abbreviatoin strings to a workable format.\n",
    "\n",
    "BenUseDict = {\n",
    "\"0\" : \"Storage\",\n",
    "\"1\" : \"Irrigation\",\n",
    "\"2\" : \"Municipal\",\n",
    "\"3\" : \"Commercial\",\n",
    "\"4\" : \"Industrial\",\n",
    "\"5\" : \"Recreation\",\n",
    "\"6\" : \"Fishery\",\n",
    "\"7\" : \"Fire\",\n",
    "\"8\" : \"Domestic\",\n",
    "\"9\" : \"Stock\",\n",
    "\"A\" : \"Augmentation\",\n",
    "\"B\" : \"Export from Basin\",\n",
    "\"C\" : \"Cumulative Accretion to River\",\n",
    "\"D\" : \"Cumulative Depletion from River\",\n",
    "\"E\" : \"Evaporative\",\n",
    "\"F\" : \"Federal Reserved\",\n",
    "\"G\" : \"Geothermal\",\n",
    "\"H\" : \"Household Use Only\",\n",
    "\"K\" : \"Snow Making\",\n",
    "\"M\" : \"Minimum Streamflow\",\n",
    "\"N\" : \"Net Effect on River\",\n",
    "\"P\" : \"Power Generation\",\n",
    "\"Q\" : \"Other\",\n",
    "\"R\" : \"Recharge\",\n",
    "\"S\" : \"Export from State\",\n",
    "\"T\" : \"Transmountain Export\",\n",
    "\"W\" : \"Wildlife\",\n",
    "\"X\" : \"All Beneficial Uses\"}\n",
    "\n",
    "def retrieveBenUse(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        String1 = str(colrowValue).strip()\n",
    "        x=[]\n",
    "        x[:] = String1\n",
    "        try:\n",
    "            outList = []\n",
    "            for i in range(len(x)):\n",
    "                y = x[i].strip()\n",
    "                y = BenUseDict[y]\n",
    "                outList.append(y)\n",
    "            outString = \",\".join(str(e) for e in outList)\n",
    "        except:\n",
    "            outString = \"\"\n",
    "    return outString\n",
    "\n",
    "dfin1['in_BeneficialUseCategory'] = dfin1.apply(lambda row: retrieveBenUse(row['Decreed Uses']), axis=1)\n",
    "dfin1['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining WaterSourceTypeCV\n",
    "\n",
    "WSTypeDict = {\n",
    "\"Aquifer NNT/NT Reservation\" : \"Surface Water\",\n",
    "\"Ditch\" : \"Surface Water\",\n",
    "\"Ditch System\" : \"Surface Water\",\n",
    "\"Exchange Plan\" : \"Surface Water\",\n",
    "\"Measuring Point\" : \"Surface Water\",\n",
    "\"Mine\" : \"Surface Water\",\n",
    "\"Minimum Flow\" : \"Surface Water\",\n",
    "\"Other\" : \"Surface Water\",\n",
    "\"Pipeline\" : \"Surface Water\",\n",
    "\"Power Plant\" : \"Surface Water\",\n",
    "\"Pump\" : \"Surface Water\",\n",
    "\"Reach\" : \"Surface Water\",\n",
    "\"Reach (Aggregating)\" : \"Surface Water\",\n",
    "\"Recharge Area\" : \"Surface Water\",\n",
    "\"Recharge Area Group\" : \"Surface Water\",\n",
    "\"Reservoir\" : \"Surface Water\",\n",
    "\"Reservoir System\" : \"Surface Water\",\n",
    "\"Seep\" : \"Surface Water\",\n",
    "\"Spring\" : \"Surface Water\",\n",
    "\"Stream Gage\" : \"Surface Water\",\n",
    "\"Well\" : \"Groundwater\",\n",
    "\"Well Field\" : \"Groundwater\",\n",
    "\"Well Group\" : \"Groundwater\",\n",
    "\"Augmentation/Replacement Plan\" : \"Groundwater\"}\n",
    "\n",
    "def retrieveWaterSourceTypeCV(colrowValue):\n",
    "    if (colrowValue == \"\") or (pd.isnull(colrowValue)):\n",
    "        outString = \"WaDE Blank\"\n",
    "    else:\n",
    "        colrowValue = str(colrowValue).strip()\n",
    "        try:\n",
    "            outString = WSTypeDict[colrowValue]\n",
    "        except:\n",
    "            outString = \"WaDE Blank\"\n",
    "    return outString\n",
    "\n",
    "dfin1['in_WaterSourceTypeCV'] = dfin1.apply(lambda row: retrieveWaterSourceTypeCV(row['Structure Type']), axis=1)\n",
    "dfin1['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation_CFS\n",
    "# If Decreed Units = \"C\" and Net Absolute != 0, then return Net Absolute\n",
    "# Elif Decreed Units = \"C\" and Net Conditional != 0, then return Net Conditional\n",
    "# Else return blank\n",
    "\n",
    "# For creating Allocation_CFS\n",
    "def assignAllocation_CFS(valA, valB, valC):\n",
    "    valA = str(valA).strip()\n",
    "    if (valB != 0) and (valC != 0):\n",
    "        outString = 0\n",
    "    else:\n",
    "        if (valA == \"C\") and (valB != 0):\n",
    "            outString = valB\n",
    "        elif (valA  == \"C\") and (valC != 0):\n",
    "            outString = valC\n",
    "        else:\n",
    "            outString = 0\n",
    "    return outString\n",
    "\n",
    "dfin1['in_AllocationFlow_CFS'] = dfin1.apply(lambda row: assignAllocation_CFS(row[\"Decreed Units\"], row[\"Net Absolute\"], row[\"Net Conditional\"]), axis=1)\n",
    "dfin1['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationVolume_AF\n",
    "# If Decreed Units = \"A\" and Net Absolute != 0, then return Net Absolute\n",
    "# Elif Decreed Units = \"A\" and Net Conditional != 0, then return Net Conditional\n",
    "# Else return blank\n",
    "\n",
    "# For creating AllocationVolume_AF\n",
    "def assignAllocationVolume_AF(valA, valB, valC):\n",
    "    valA = str(valA).strip()\n",
    "    if (valB != 0) and (valC != 0):\n",
    "        outString = 0\n",
    "    else:\n",
    "        if (valA == \"A\") and (valB != 0):\n",
    "            outString = valB\n",
    "        elif (valA  == \"A\") and (valC != 0):\n",
    "            outString = valC\n",
    "        else:\n",
    "            outString = 0\n",
    "    return outString\n",
    "\n",
    "dfin1['in_AllocationVolume_AF'] = dfin1.apply(lambda row: assignAllocationVolume_AF(row[\"Decreed Units\"], row[\"Net Absolute\"], row[\"Net Conditional\"]), axis=1)\n",
    "dfin1['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating AllocationLegalStatusCV\n",
    "# If Net Absolute = 0 and Net Condontial = 0, then Condtional Aboslute\n",
    "# Elif Net Absolute = 0 and Net Condontial != 0, then Condtional\n",
    "# Else, Aboslute\n",
    "\n",
    "def assignAllocationLegalStatusCV(valA, valB):\n",
    "    if (valA == 0) and (valB == 0):\n",
    "        outString = \"Conditional Absolute\"\n",
    "    elif (valA == 0) and (valB != 0):\n",
    "        outString = \"Conditional\"\n",
    "    else:\n",
    "        outString = \"Absolute\"\n",
    "    return outString\n",
    "\n",
    "dfin1['in_AllocationLegalStatusCV'] = dfin1.apply(lambda row: assignAllocationLegalStatusCV(row['Net Absolute'], row['Net Conditional']), axis=1)\n",
    "dfin1['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a unique identifier for WaDE AllocationNativeID.  Combine combine **Admin No**, **Order No**, **Decreed Units**, & **WDID** into single string entry.\n",
    "\n",
    "# For creating AllocationAmount\n",
    "def assignAllocationNativeID(colrowValueA, colrowValueB, colrowValueC, colrowValueD):\n",
    "    colrowValueA = str(colrowValueA).strip()\n",
    "    colrowValueB = str(colrowValueB).strip()\n",
    "    colrowValueD = str(colrowValueD).strip()\n",
    "    outString = \"-\".join(map(str, [colrowValueA, colrowValueB, colrowValueC, colrowValueD]))\n",
    "    return outString\n",
    "\n",
    "dfin1['in_AllocationNativeID'] = dfin1.apply(lambda row: assignAllocationNativeID(row['Admin No'], row['Order No'], row['Decreed Units'], row['WDID']), axis=1)\n",
    "dfin1['in_AllocationNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list of WDIDs (from Division data) as inputs, retreive time series data.\n",
    "# Split list into catagories that are 100 long. Issue with CO API timing out after too long.\n",
    "dfin1_s = dfin1.drop_duplicates(subset=[\"WDID\"], keep=False).reset_index()\n",
    "wdidList = dfin1_s['WDID'].tolist()\n",
    "wdidListB = [wdidList[i:i + 100] for i in range(0, len(wdidList), 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input 2 - time series water use info.zip\r\n",
    "-retrieved via api, saved to local zip for easy future acces\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done\n",
    "# %%time\n",
    "# # Time Series Dataframe\n",
    "# dfts = pd.DataFrame()\n",
    "\n",
    "# str2 = \"https://dwr.state.co.us/Rest/GET/api/v2/structures/divrec/divrecmonth/?format=csv&wdid=\"\n",
    "# str3 = \"%2C&apiKey=wAC6ZmzcPJ30dyy6nYu6jQmG7BBedcem\"\n",
    "\n",
    "# for i in range(len(wdidListB)):\n",
    "#     lstC = wdidListB[i]\n",
    "#     lstCa = '%2C'.join([str(n) for n in lstC]) \n",
    "#     urlInput = str2 + lstCa + str3\n",
    "#     print(urlInput)\n",
    "#     try:\n",
    "#         tempdf = pd.read_csv(urlInput, skiprows=2).replace(np.nan, \"\")\n",
    "#         dfts = pd.concat([dfts, tempdf])\n",
    "#     except:\n",
    "#         print(\"bad reponse\")\n",
    "\n",
    "# print(len(dfts))\n",
    "# dfts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done\n",
    "# dfts.to_csv('RawInputData/TimeSeriesInfo.zip', compression=dict(method='zip', archive_name='TimeSeriesInfo.csv'), index=False)  # The output, save as a zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - TimeSeriesInfo.zip\n",
    "fileInput = \"RawInputData/TimeSeriesInfo.zip\"\n",
    "dfin2 = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin2:\n",
    "    dfin2['WaDEUUID'] = \"in2\" + dfin2.index.astype(str)\n",
    "    dfin2.to_csv(\"RawInputData/TimeSeriesInfo.zip\", compression=dict(method='zip', archive_name=\"TimeSeriesInfo.csv\"), index=False)\n",
    "\n",
    "print(len(dfin2))\n",
    "dfin2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left merge sites to water use\n",
    "dfin1 = dfin1.merge(dfin2, left_on='WDID', right_on='wdid', how='left')\n",
    "print(len(dfin1))\n",
    "dfin1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfin1['WaDEUUID_x']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"COwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"COwr_V1\" # for wr records portion only, will create sa portion below\n",
    "df['in_AggregationIntervalUnitCV'] = \"Monthly\"\n",
    "df['in_VariableCV'] = \"Discharge Flow\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"COwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"Fresh\"\n",
    "df['in_WaterSourceName'] = dfin1['Water Source']\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "df['in_WaterSourceTypeCV'] = dfin1['in_WaterSourceTypeCV']\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = dfin1['Location Accuracy']\n",
    "df['in_County'] = dfin1['County']\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfin1['Latitude']\n",
    "df['in_Longitude'] = dfin1['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = dfin1['Structure Name']\n",
    "df['in_SiteNativeID'] = dfin1['WDID'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = dfin1['Structure Type'].astype(str)\n",
    "df['in_StateCV'] = \"CO\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfin1['in_AllocationFlow_CFS'].astype(float) # see above for conversion\n",
    "df['in_AllocationLegalStatusCV'] = dfin1['in_AllocationLegalStatusCV']\n",
    "df['in_AllocationNativeID'] =  dfin1['in_AllocationNativeID'].astype(str)\n",
    "df['in_AllocationOwner'] = \"\"\n",
    "df['in_AllocationPriorityDate'] = dfin1['Appropriation Date']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"12/31\"\n",
    "df['in_AllocationTimeframeStart'] = \"01/01\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfin1['in_AllocationVolume_AF'].astype(float) # see above for conversion\n",
    "df['in_BeneficialUseCategory'] = dfin1['in_BeneficialUseCategory']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0 # 1 or 0, if we want this data excempt\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfin1['More Information']\n",
    "\n",
    "# Site VariableAmounts Info\n",
    "df['in_Amount'] = dfin1['dataValue']\n",
    "df['in_AssociatedNativeAllocationIDs'] = dfin1['in_AllocationNativeID'].astype(str)\n",
    "df['in_PowerGeneratedGWh'] = \"\"\n",
    "df['in_PrimaryUseCategory'] = \"\"\n",
    "df['in_ReportYearCV'] = dfin1['dataMeasDate']\n",
    "df['in_SDWISIdentifier'] = \"\"\n",
    "df['in_TimeframeEnd'] = dfin1['dataMeasDate']\n",
    "df['in_TimeframeStart'] = dfin1['dataMeasDate']\n",
    "# df['in_AllocationCropDutyAmount'] = \"\" see above AllocationAmount Info\n",
    "# df['in_BeneficialUseCategory'] = \"\" see above AllocationAmount Info\n",
    "# df['in_CommunityWaterSupplySystem'] = \"\" see above AllocationAmount Info\n",
    "# df['in_CropTypeCV'] = \"\" see above AllocationAmount Info\n",
    "# df['in_CustomerTypeCV'] = \"\" see above AllocationAmount Info\n",
    "# df['in_DataPublicationDate'] = \"\" see above AllocationAmount Info\n",
    "# df['in_DataPublicationDOI'] = \"\" see above AllocationAmount Info\n",
    "# df['in_Geometry'] = \"\" see above Site Info\n",
    "# df['in_IrrigatedAcreage'] = \"\" see above AllocationAmount Info\n",
    "# df['in_IrrigationMethodCV'] = \"\" see above AllocationAmount Info\n",
    "# df['in_PopulationServed'] = \"\" see above AllocationAmount Info\n",
    "# df['in_PowerType'] = \"\" see above AllocationAmount Info\n",
    "# df['in_SDWISIdentifier'] = \"\" see above AllocationAmount Info\n",
    "\n",
    "outdf1 = df.copy()\n",
    "outdf1 = outdf1.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdf1))\n",
    "outdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU Data.  Make needed changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc etc,\n",
    "# outdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate DataFrames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outdf1]  # list all out dataframes here\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean name entries of spcial characters\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: ensureEmptyString(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "uniqueList = list(set([i.strip() for i in ','.join(outdf['in_BeneficialUseCategory'].astype(str)).split(',')]))\n",
    "uniqueList.sort()\n",
    "uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Latitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Longitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Amount entry is either numireic or blank, no 0 entries\n",
    "outdf['in_Amount'] = pd.to_numeric(outdf['in_Amount'], errors='coerce').round(2).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure PopulationServed entry is numireic WITH 0 entries (no blank strings)\n",
    "outdf['in_PopulationServed'] = pd.to_numeric(outdf['in_PopulationServed'], errors='coerce').round().replace(\"\",0).fillna(0).astype(int).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_PopulationServed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'])\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeEnd to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf['in_TimeframeEnd'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeEnd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeStart to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf['in_TimeframeStart'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeStart'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year out\n",
    "outdf['in_ReportYearCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Primary Use Category\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/rjame/Documents/WSWC Documents/MappingStatesDataToWaDE2.0/5_CustomFunctions/AssignPrimaryUseCategory\")\n",
    "import AssignPrimaryUseCategoryFile # Use Custom import file\n",
    "\n",
    "outdf['in_PrimaryUseCategory'] = outdf.apply(lambda row: AssignPrimaryUseCategoryFile.retrievePrimaryUseCategory(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_PrimaryUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom VariableSpecificCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "def createVariableSpecificCV(inV, inAIU, inPU, inWST):\n",
    "    inV = str(inV).strip()\n",
    "    inAIU = str(inAIU).strip()\n",
    "    inPU = str(inPU).strip().title()\n",
    "    inWST = str(inWST).strip()\n",
    "    outString = inV + \"_\" + inAIU + \"_\" + inPU + \"_\" + inWST\n",
    "    return outString\n",
    "\n",
    "outdf['in_VariableSpecificCV'] = outdf.apply(lambda row: createVariableSpecificCV(row['in_VariableCV'], \n",
    "                                                                                  row['in_AggregationIntervalUnitCV'],\n",
    "                                                                                  row['in_PrimaryUseCategory'],\n",
    "                                                                                  row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# use unique WaterSourceName and WaterSourceType values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_WaterSourceNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_WaterSourceName'] = outdf['in_WaterSourceName'].astype(str).str.strip()\n",
    "dfTempID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_WaterSourceNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_WaterSourceName'].astype(str) + dfTempID['in_WaterSourceTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_WaterSourceNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_WaterSourceNativeID'], \n",
    "                                                                              row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom site native ID for easy site identification\n",
    "# use Unique Latitude, Longitude, SiteName and SiteTypeCV values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_SiteNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_Latitude'] = outdf['in_Latitude'].astype(str).str.strip()\n",
    "dfTempID['in_Longitude'] = outdf['in_Longitude'].astype(str).str.strip()\n",
    "dfTempID['in_SiteName'] = outdf['in_SiteName'].astype(str).str.strip()\n",
    "dfTempID['in_SiteTypeCV'] = outdf['in_SiteTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_SiteNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_Latitude'].astype(str) + dfTempID['in_Longitude'].astype(str) + dfTempID['in_SiteName'].astype(str)+ dfTempID['in_SiteTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_SiteNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB, valC, valD):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip() + str(valC).strip() + str(valD).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_SiteNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_SiteNativeID'], \n",
    "                                                                       row['in_Latitude'], row['in_Longitude'],\n",
    "                                                                       row['in_SiteName'], row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop non-Active AllocationLegalStatusCV Water Rights\n",
    "- For this {state name / organization}, we don't want water rights that are considered: Conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-active AllocationLegalStatusCV values specific to that state.\n",
    "\n",
    "# drop the list\n",
    "dropLegalStatusList = [\"Conditional\"] # enter string entries here\n",
    "\n",
    "# drop rows from above list\n",
    "outdf = outdf[outdf.in_AllocationLegalStatusCV.isin(dropLegalStatusList) == False].reset_index(drop=True)\n",
    "\n",
    "print(len(outdf))\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PoU Shapefile Data\n",
    "# shapefileInput = \"RawInputData/shapefiles/{enter file name here}.zip\" # ziped folder of the shp file\n",
    "\n",
    "# dfPoUshapetemp = gpd.read_file(shapefileInput)\n",
    "# dfPoUshapetemp['geometry'] = dfPoUshapetemp['geometry'].to_crs(epsg=4326) # Realign Geometry Projection\n",
    "# print(len(dfPoUshapetemp))\n",
    "# dfPoUshapetemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create temp dataframe to hold native ID and geometry from shapefile input\n",
    "# columnsList = ['in_SiteNativeID', 'geometry']\n",
    "# dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "\n",
    "# # assing values to temp dataframe based on shapefile input\n",
    "# # for in_SiteNativeID assure ID value is the same as that listed above for POU info.\n",
    "# dfPoUshape['in_SiteNativeID'] = \"POU\" + \"\"\n",
    "# dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "# dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "# print(len(dfPoUshape))\n",
    "# dfPoUshape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('RawInputData/Pwr_wu_Main.zip', compression=dict(method='zip', archive_name='Pwr_wu_Main.csv'), index=False)  # The output, save as a zip\n",
    "#dfPoUshape.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
