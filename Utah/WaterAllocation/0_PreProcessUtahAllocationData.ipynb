{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Utah Allocation data for WaDEQA upload.\n",
    "- Purpose:  To pre-process the Utah data into one master file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "\n",
    "# Working Directory\n",
    "workingDir = \"C:/Users/rjame/Documents/WSWC Documents/MappingStatesDataToWaDE2.0/Utah/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)\n",
    "\n",
    "from pyproj import Transformer, transform\n",
    "transformer = Transformer.from_proj(26912, 4326)  # A trick to drastically optimize the Transformer of pyproj.\n",
    "# Utah projection = EPSG:26912.  WGS84 projection used by WaDE 2.0 = epsg:4326."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point of Diversion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "FI_PoD = \"Point of Diversion/PointsOfDiversion_input.csv\"\n",
    "FI_WMs = \"Point of Diversion/WRCHEX_WATER_MASTER.csv\"\n",
    "FI_Irr = \"Point of Diversion/IRRIGATION_MASTER.csv\"\n",
    "FI_Mun = \"Point of Diversion/WTRUSE_MUNICIPAL.csv\"\n",
    "FI_Pow = \"Point of Diversion/WTRUSE_POWER.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe creation\n",
    "dfPODin = pd.read_csv(FI_PoD, encoding = \"ISO-8859-1\") # Point of Diversion Input\n",
    "dfWMain = pd.read_csv(FI_WMs, encoding = \"ISO-8859-1\") # Irrigation Input\n",
    "dfIrrin = pd.read_csv(FI_Irr, encoding = \"ISO-8859-1\") # Irrigation Input\n",
    "dfMunin = pd.read_csv(FI_Mun, encoding = \"ISO-8859-1\") # Municiplal Input\n",
    "dfPowin = pd.read_csv(FI_Pow, encoding = \"ISO-8859-1\") # Power Inpu\n",
    "dfPOD = pd.DataFrame() # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes into one, using left-join.\n",
    "dfPOD = pd.merge(dfPODin, dfWMain[['WRNUM', 'DATE_FILED', 'DATE_TERMINATED', 'IRRIGATION_DEPLETION']], on='WRNUM', how='left')\n",
    "dfPOD = pd.merge(dfPOD, dfIrrin[['WRNUM', 'USE_END_DATE', 'USE_BEG_DATE']], on='WRNUM', how='left')\n",
    "dfPOD = pd.merge(dfPOD, dfMunin[['WRNUM', 'MUNICIPALITY']], on='WRNUM', how='left')\n",
    "dfPOD = pd.merge(dfPOD, dfPowin[['WRNUM', 'POWER_CAPACITY']], on='WRNUM', how='left')\n",
    "print(len(dfPOD))\n",
    "dfPOD.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign PODorPOUSite value\n",
    "dfPOD['in_PODorPOUSite'] = \"POD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place of Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "FI_POU = \"Place of Use/Utah_Place_of_Use_input.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataframe creation\n",
    "dfPOU = pd.DataFrame() # Output\n",
    "dfPOUin = pd.read_csv(FI_POU, encoding = \"ISO-8859-1\") # Place of Use Input\n",
    "print(len(dfPOUin))\n",
    "dfPOUin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty WRNUMS rows, can't match those to anything.\n",
    "def emptyWRNUMS(val):\n",
    "    val = str(val).strip()\n",
    "    val = val.rstrip(\",\")  # strip trailing commas\n",
    "    return val\n",
    "\n",
    "dfPOUin['WRNUMS'] = dfPOUin.apply(lambda row: emptyWRNUMS(row['WRNUMS']), axis=1)\n",
    "dfPOUin = dfPOUin[dfPOUin['WRNUMS'] != '']\n",
    "dfPOUin = dfPOUin.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to split out WRNUMS into their own row\n",
    "# The explode() method explodes lists into separate rows.\n",
    "dfPOUin = dfPOUin.assign(WRNUMS=dfPOUin['WRNUMS'].str.split(',')).explode('WRNUMS')\n",
    "dfPOUin = dfPOUin.rename({'WRNUMS': 'WRNUM'}, axis=1)\n",
    "dfPOUin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes into one, using left-join.\n",
    "dfPOU = pd.merge(dfPOUin, dfWMain[['WRNUM', 'DATE_FILED', 'DATE_TERMINATED', 'IRRIGATION_DEPLETION']], on='WRNUM', how='left')\n",
    "dfPOU = pd.merge(dfPOU, dfIrrin[['WRNUM', 'USE_END_DATE', 'USE_BEG_DATE']], on='WRNUM', how='left')\n",
    "dfPOU = pd.merge(dfPOU, dfMunin[['WRNUM', 'MUNICIPALITY']], on='WRNUM', how='left')\n",
    "dfPOU = pd.merge(dfPOU, dfPowin[['WRNUM', 'POWER_CAPACITY']], on='WRNUM', how='left')\n",
    "print(len(dfPOU))\n",
    "dfPOU.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign PODorPOUSite value\n",
    "dfPOU['in_PODorPOUSite'] = \"POU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "frames = [dfPOD, dfPOU]\n",
    "dfout = pd.concat(frames)\n",
    "\n",
    "#Removing all NaN Values and replacing with blank\n",
    "dfout = dfout.replace(np.nan, \"\", regex=True)\n",
    "\n",
    "print(len(dfout))\n",
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Sure datatype of Long, Lat, Wrex, Irrigation are Float\n",
    "dfout['CFS'] = pd.to_numeric(dfout['CFS'], errors='coerce')\n",
    "dfout['ACFT'] = pd.to_numeric(dfout['ACFT'], errors='coerce')\n",
    "dfout['IRRIGATION_DEPLETION'] = pd.to_numeric(dfout['IRRIGATION_DEPLETION'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype of used date fields. \n",
    "dfout['PRIORITY'] = pd.to_datetime(dfout['PRIORITY'], errors = 'coerce')\n",
    "dfout['PRIORITY'] = pd.to_datetime(dfout[\"PRIORITY\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout['DATE_FILED'] = pd.to_datetime(dfout['DATE_FILED'], errors = 'coerce')\n",
    "dfout['DATE_FILED'] = pd.to_datetime(dfout[\"DATE_FILED\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout['DATE_TERMINATED'] = pd.to_datetime(dfout['DATE_TERMINATED'], errors = 'coerce')\n",
    "dfout['DATE_TERMINATED'] = pd.to_datetime(dfout[\"DATE_TERMINATED\"].dt.strftime('%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaterSourceTypeCV\n",
    "\n",
    "WaterSourceTypeCVDictionary={\n",
    "\"Underground\" : \"Groundwater\",\n",
    "\"Abandonded Well\" : \"Groundwater\",\n",
    "\"Point to Point\" : \"Surface Water\",\n",
    "\"Surface\" : \"Surface Water\",\n",
    "\"Return\" : \"Surface Water\",\n",
    "\"Drain\" : \"Surface Water\",\n",
    "\"Spring\" : \"Surface Water\",\n",
    "\"Rediversion\" : \"Surface Water\"}\n",
    "def CreateWaterSourceTypeCV(val):\n",
    "    if val == '' or pd.isnull(val):\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        val = val.strip()\n",
    "        try:\n",
    "            outString = WaterSourceTypeCVDictionary[val]\n",
    "        except:\n",
    "            outString = \"Unspecified\"\n",
    "    return outString\n",
    "\n",
    "dfout['in_WaterSourceTypeCV'] = dfout.apply(lambda row: CreateWaterSourceTypeCV(row['TYPE']), axis=1)\n",
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling 'AllocationTimeframeStart' & 'AllocationTimeframeEnd'\n",
    "#Both can have a string format for WaDE 2.0.\n",
    "    \n",
    "def assignTime(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outlist = \"\"\n",
    "    else:\n",
    "        colrowValue = str(colrowValue)\n",
    "        colrowValue = colrowValue.strip()\n",
    "        if len(colrowValue) == 4:\n",
    "            startmonth = colrowValue[0:1]\n",
    "            startday = colrowValue[1:2]\n",
    "            outlist = \"0\" + startmonth + \"/\" + \"0\" + startday\n",
    "        elif len(colrowValue) == 5:\n",
    "            startmonth = colrowValue[0:1]\n",
    "            startday = colrowValue[1:3]\n",
    "            outlist = \"0\" + startmonth + \"/\" + startday\n",
    "        elif len(colrowValue) == 6:\n",
    "            startmonth = colrowValue[0:2]\n",
    "            startday = colrowValue[2:4]\n",
    "            outlist = startmonth + \"/\" + startday\n",
    "        else:\n",
    "            outlist = \"\"\n",
    "  \n",
    "    return outlist\n",
    "\n",
    "\n",
    "dfout['in_AllocationTimeframeStart'] = dfout.apply(lambda row: assignTime(row['USE_BEG_DATE']), axis=1)\n",
    "dfout['in_AllocationTimeframeEnd'] = dfout.apply(lambda row: assignTime(row['USE_END_DATE']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign SiteTypeCV value.\n",
    "# Uses the re library, but requires for loop.\n",
    "# Order that the lists are inputed into dictoinary is important, want to overide generic search with a more specific search.\n",
    "\n",
    "# Create the Lists\n",
    "canalList = [\"canal\", \"canals\"]\n",
    "creekList = [\"creek\"]\n",
    "ditchList = [\"ditch\"]\n",
    "drainList = [\"drain\", \"drains\"]\n",
    "lakeList = [\"lake\"]\n",
    "pondList = [\"pond\"]\n",
    "reservoirList = [\"reservoir\"]\n",
    "riverList = [\"river\", \"fork\", \"surface\"]\n",
    "sloughList = [\"slough\"]\n",
    "springList = [\"spring\", \"springs\", \"gulch\", \"seep\"]\n",
    "tunnelList = [\"tunnel\", \"tunnels\"]\n",
    "washList = [\"wash\"]\n",
    "wellList = [\"well\", \"wells\", \"well:\", \"draw\", \"hollow\"]\n",
    "\n",
    "# Making the dictionary\n",
    "listDictionary = {}\n",
    "listDictionary[\"Canal\"] = canalList\n",
    "listDictionary[\"Creek\"] = creekList\n",
    "listDictionary[\"Ditch\"] = ditchList\n",
    "listDictionary[\"Drain\"] = drainList\n",
    "listDictionary[\"Lake\"] = lakeList\n",
    "listDictionary[\"Pond\"] = pondList\n",
    "listDictionary[\"Reservoir\"] = reservoirList\n",
    "listDictionary[\"River\"] = riverList\n",
    "listDictionary[\"Slough\"] = sloughList\n",
    "listDictionary[\"Spring\"] = springList\n",
    "listDictionary[\"Tunnel\"] = tunnelList\n",
    "listDictionary[\"Wash\"] = washList\n",
    "listDictionary[\"Well\"] = wellList\n",
    "\n",
    "def CreateSiteTypeCV(val):\n",
    "    if val == '' or pd.isnull(val):\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        outString = \"Unspecified\" # Default\n",
    "        \n",
    "        # Cleaning text / simple search format\n",
    "        val = val.replace(\",\", \" \")\n",
    "        val = val.replace(\".\", \" \")\n",
    "        val = val.replace(\";\", \" \")\n",
    "        val = val.replace(\"-\", \" \")\n",
    "        val = val.replace(\"/\", \" \")\n",
    "        val = val.replace(\"(\", \" \")\n",
    "        val = val.replace(\")\", \" \")\n",
    "        val = val.lower().strip()\n",
    "        val = \" \"+val+\" \"\n",
    "        \n",
    "        for x in listDictionary:\n",
    "            labelString = x\n",
    "            valueList = listDictionary[x]\n",
    "            for words in valueList:\n",
    "                if re.search(\" \"+words+ \" \", val): outString = x\n",
    "            \n",
    "    return outString\n",
    "\n",
    "dfout['in_SiteTypeCV'] = dfout.apply(lambda row: CreateSiteTypeCV( row['SOURCE']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign LegalStatusCV value.\n",
    "# Uses the re library, but requires for loop.\n",
    "# Order that the lists are inputed into dictoinary is important, want to overide generic search with a more specific search.\n",
    "\n",
    "# Create the Lists\n",
    "ADECList = [\"ADEC\"]\n",
    "ADVList = [\"ADV\"]\n",
    "APPList = [\"APP\"]\n",
    "CERTList = [\"CERT\"]\n",
    "DECList = [\"DEC\"]\n",
    "DILList = [\"DIL\"]\n",
    "DISList = [\"DIS\"]\n",
    "EXPList = [\"EXP\"]\n",
    "FORFList = [\"FORF\"]\n",
    "LAPList = [\"LAP\"]\n",
    "NPRList = [\"NPR\"]\n",
    "NUSEList = [\"NUSE\"]\n",
    "PERFList = [\"PERF\"]\n",
    "REJList = [\"REJ\"]\n",
    "RNUMList = [\"RNUM\"]\n",
    "STATUSList = [\"STATUS\"]\n",
    "TEMPList = [\"TEMP\"]\n",
    "TERMList = [\"TERM\"]\n",
    "UGWCList = [\"UGWC\"]\n",
    "UNAPList = [\"UNAP\"]\n",
    "WDList = [\"WD\"]\n",
    "WUCList = [\"WUC\"]\n",
    "\n",
    "\n",
    "# Making the dictionary\n",
    "listDictionary = {}\n",
    "\n",
    "listDictionary[\"Lapsed\"] = LAPList\n",
    "\n",
    "listDictionary[\"Adjudication Decree\"] = ADECList\n",
    "listDictionary[\"Adverse Use Claim\"] = ADVList\n",
    "listDictionary[\"Approved\"] = APPList\n",
    "listDictionary[\"Certificated\"] = CERTList\n",
    "listDictionary[\"Decree\"] = DECList\n",
    "listDictionary[\"Diligence Claim\"] = DILList\n",
    "listDictionary[\"Disallowed\"] = DISList\n",
    "listDictionary[\"Expired\"] = EXPList\n",
    "listDictionary[\"Forfeited\"] = FORFList\n",
    "listDictionary[\"No Proof Required\"] = NPRList\n",
    "listDictionary[\"Nonuse\"] = NUSEList\n",
    "listDictionary[\"Perfected\"] = PERFList\n",
    "listDictionary[\"Rejected\"] = REJList\n",
    "listDictionary[\"Renumbered\"] = RNUMList\n",
    "listDictionary[\"Deff\"] = STATUSList\n",
    "listDictionary[\"Temp Applications\"] = TEMPList\n",
    "listDictionary[\"Terminated\"] = TERMList\n",
    "listDictionary[\"Underground Water Claim\"] = UGWCList\n",
    "listDictionary[\"Unapproved\"] = UNAPList\n",
    "listDictionary[\"Withdrawn\"] = WDList\n",
    "listDictionary[\"Water User`s Claim\"] = WUCList\n",
    "\n",
    "\n",
    "def CreateLegalStatus(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = \"\"\n",
    "        for x in listDictionary:\n",
    "            valueList = listDictionary[x]\n",
    "            for words in valueList:\n",
    "                if words in val: outString = x\n",
    "\n",
    "    return outString\n",
    "\n",
    "dfout['in_LegalStatus'] = dfout.apply(lambda row: CreateLegalStatus( row['STATUS']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing state site info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDEUT_WS\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = dfout['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    if (A == '') or (pd.isnull(A)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceTypeCV'] == A), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfout['in_WaterSourceNativeID'] = dfout.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceTypeCV']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all NaN Values and replacing with blank\n",
    "dfout = dfout.replace(np.nan, \"\", regex=True)\n",
    "\n",
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to Finished File\n",
    "dfout.to_csv('P_UtahMaster.csv', index=False)  # The output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
