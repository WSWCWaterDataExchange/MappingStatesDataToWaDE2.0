{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Utah Allocation data for WaDEQA upload.\n",
    "- Purpose:  To pre-process the Utah data into one master file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd # the library that lets us read in shapefiles\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebooki\n",
    "\n",
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Utah/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)\n",
    "\n",
    "from pyproj import Transformer, transform\n",
    "transformer = Transformer.from_proj(26912, 4326)  # A trick to drastically optimize the Transformer of pyproj.\n",
    "# Utah projection = EPSG:26912.  WGS84 projection used by WaDE 2.0 = epsg:4326."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point of Diversion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "FI_PoD = \"Point of Diversion/PointsOfDiversion_input.csv\"\n",
    "FI_WMs = \"Point of Diversion/WRCHEX_WATER_MASTER.csv\"\n",
    "FI_Irr = \"Point of Diversion/IRRIGATION_MASTER.csv\"\n",
    "FI_Mun = \"Point of Diversion/WTRUSE_MUNICIPAL.csv\"\n",
    "FI_Pow = \"Point of Diversion/WTRUSE_POWER.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe creation\n",
    "dfPODin = pd.read_csv(FI_PoD, encoding = \"ISO-8859-1\") # Point of Diversion Input\n",
    "dfWMain = pd.read_csv(FI_WMs, encoding = \"ISO-8859-1\") # Irrigation Input\n",
    "dfIrrin = pd.read_csv(FI_Irr, encoding = \"ISO-8859-1\") # Irrigation Input\n",
    "dfMunin = pd.read_csv(FI_Mun, encoding = \"ISO-8859-1\") # Municiplal Input\n",
    "dfPowin = pd.read_csv(FI_Pow, encoding = \"ISO-8859-1\") # Power Inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes into one, using left-join.\n",
    "dfPODin = pd.merge(dfPODin, dfWMain[['WRNUM', 'DATE_FILED', 'DATE_TERMINATED', 'IRRIGATION_DEPLETION']], on='WRNUM', how='left')\n",
    "dfPODin = pd.merge(dfPODin, dfIrrin[['WRNUM', 'USE_END_DATE', 'USE_BEG_DATE']], on='WRNUM', how='left')\n",
    "dfPODin = pd.merge(dfPODin, dfMunin[['WRNUM', 'MUNICIPALITY']], on='WRNUM', how='left')\n",
    "dfPODin = pd.merge(dfPODin, dfPowin[['WRNUM', 'POWER_CAPACITY']], on='WRNUM', how='left')\n",
    "dfPODin = dfPODin.replace(np.nan, \"\").reset_index()\n",
    "print(len(dfPODin))\n",
    "dfPODin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating BeneficialUseCategory\n",
    "benUseDict = {\n",
    "    \"I\" : \"Irrigation\",\n",
    "    \"S\" : \"Stockwatering\",\n",
    "    \"D\" : \"Domestic\",\n",
    "    \"M\" : \"Municipal\",\n",
    "    \"X\" : \"Mining\",\n",
    "    \"P\" : \"Power\",\n",
    "    \"O\" : \"Other\"}\n",
    "def assignBenUseCategory(colrowValue):\n",
    "    colrowValue = str(colrowValue).strip()\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outList = \"Unspecified\"\n",
    "    else:\n",
    "        outList = \",\".join(benUseDict[inx] for inx in list(str(colrowValue)))\n",
    "    return outList\n",
    "\n",
    "\n",
    "dfPODin['in_BeneficialUseCategory'] = dfPODin.apply(lambda row: assignBenUseCategory(row['USES']), axis=1)\n",
    "dfPODin['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Owner info. Remove special characters\n",
    "import re\n",
    "\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).strip()\n",
    "    return Val\n",
    "\n",
    "dfPODin['OWNER'] = dfPODin.apply(lambda row: cleanOwnerDataFunc(row['OWNER']), axis=1)\n",
    "dfPODin['OWNER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixNativeID(valA):\n",
    "    outString = str(valA).strip()\n",
    "    return outString\n",
    "\n",
    "dfPODin['WRNUM'] = dfPODin.apply(lambda row: fixNativeID(row['WRNUM']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the output Dataframe for PODs.\n",
    "\n",
    "dfPOD = pd.DataFrame(index=dfPODin.index)\n",
    "\n",
    "# Water Source\n",
    "dfPOD[\"in_WaterSourceTypeCV\"] = dfPODin['TYPE']\n",
    "\n",
    "# Site\n",
    "dfPOD[\"in_Latitude\"] = dfPODin['Latitude']\n",
    "dfPOD[\"in_Longitude\"] = dfPODin['Longitude']\n",
    "dfPOD[\"in_PODorPOUSite\"] = \"POD\"\n",
    "dfPOD[\"in_SiteName\"] = dfPODin['SOURCE']\n",
    "dfPOD[\"in_SiteNativeID\"] = \"POD\" + dfPODin['OBJECTID'].astype(str)\n",
    "dfPOD[\"in_SiteTypeCV\"] = dfPODin['SOURCE']\n",
    "\n",
    "# Allocation\n",
    "dfPOD['in_AllocationApplicationDate'] = dfPODin['DATE_FILED']\n",
    "dfPOD['in_AllocationCommunityWaterSupplySystem'] = dfPODin['MUNICIPALITY']\n",
    "dfPOD[\"in_AllocationCropDutyAmount\"] = dfPODin['IRRIGATION_DEPLETION']\n",
    "dfPOD[\"in_AllocationExpirationDate\"] = dfPODin['DATE_TERMINATED']\n",
    "dfPOD[\"in_AllocationFlow_CFS\"] = dfPODin['CFS'].astype(float)\n",
    "dfPOD['in_AllocationLegalStatusCV'] = dfPODin['STATUS']\n",
    "dfPOD[\"in_AllocationNativeID\"] = dfPODin['WRNUM']\n",
    "dfPOD['in_AllocationOwner'] = dfPODin['OWNER']\n",
    "dfPOD['in_AllocationPriorityDate'] = dfPODin['PRIORITY']\n",
    "dfPOD[\"in_AllocationVolume_AF\"] = dfPODin['ACFT'].astype(float)\n",
    "dfPOD[\"in_BeneficialUseCategory\"] = dfPODin['in_BeneficialUseCategory']  #see above\n",
    "dfPOD['USE_BEG_DATE'] = dfPODin['USE_BEG_DATE']\n",
    "dfPOD['USE_END_DATE'] = dfPODin['USE_END_DATE']\n",
    "\n",
    "dfPOD = dfPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfPOD))\n",
    "dfPOD.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place of Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "FI_POU = \"Place of Use/PlaceOfUseService_input.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataframe creation\n",
    "dfPOUin = pd.read_csv(FI_POU, encoding = \"ISO-8859-1\") # Place of Use Input\n",
    "print(len(dfPOUin))\n",
    "dfPOUin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to split out WRNUMS into their own row\n",
    "# The explode() method explodes lists into separate rows.\n",
    "dfPOUin = dfPOUin.assign(WRNUMS=dfPOUin['WRNUMS'].str.split(',')).explode('WRNUMS').reset_index()\n",
    "dfPOUin = dfPOUin.rename({'WRNUMS': 'WRNUM'}, axis=1)\n",
    "dfPOUin = dfPOUin.replace(np.nan, \"\").reset_index()\n",
    "print(len(dfPOUin))\n",
    "dfPOUin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes into one, using left-join.\n",
    "dfPOUin = pd.merge(dfPOUin, dfWMain[['WRNUM', 'DATE_FILED', 'DATE_TERMINATED', 'IRRIGATION_DEPLETION']], on='WRNUM', how='left')\n",
    "dfPOUin = pd.merge(dfPOUin, dfIrrin[['WRNUM', 'USE_END_DATE', 'USE_BEG_DATE']], on='WRNUM', how='left')\n",
    "dfPOUin = pd.merge(dfPOUin, dfMunin[['WRNUM', 'MUNICIPALITY']], on='WRNUM', how='left')\n",
    "dfPOUin = pd.merge(dfPOUin, dfPowin[['WRNUM', 'POWER_CAPACITY']], on='WRNUM', how='left')\n",
    "print(len(dfPOUin))\n",
    "dfPOUin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixNativeID(valA):\n",
    "    outString = str(valA).strip()\n",
    "    return outString\n",
    "\n",
    "dfPOUin['WRNUM'] = dfPOUin.apply(lambda row: fixNativeID(row['WRNUM']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFS and AF not provided for POU data.  Will instead assume they share values.\n",
    "# merging dfPOD data to ensure that the POUs are using the same CFS and AF as the PODS.\n",
    "dfPOUin = pd.merge(dfPOUin, dfPOD, left_on='WRNUM', right_on='in_AllocationNativeID', how='left')\n",
    "print(len(dfPOUin))\n",
    "dfPOUin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the output Dataframe for POUs.\n",
    "\n",
    "dfPOU = pd.DataFrame(index=dfPOUin.index)\n",
    "\n",
    "# Water Source\n",
    "dfPOU[\"in_WaterSourceTypeCV\"] = \"\"\n",
    "\n",
    "# Site\n",
    "dfPOU[\"in_Latitude\"] = dfPOUin['Latitude']\n",
    "dfPOU[\"in_Longitude\"] = dfPOUin['Longitude']\n",
    "dfPOU[\"in_PODorPOUSite\"] = \"POU\"\n",
    "dfPOU[\"in_SiteName\"] = \"Unspecified\"\n",
    "dfPOU[\"in_SiteNativeID\"] = \"POU\" + dfPOUin['RECORD_ID'].astype(str)\n",
    "dfPOU[\"in_SiteTypeCV\"] = \"\"\n",
    "\n",
    "# Allocation\n",
    "dfPOU['in_AllocationApplicationDate'] = \"\"\n",
    "dfPOU['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "dfPOU[\"in_AllocationCropDutyAmount\"] = \"\"\n",
    "dfPOU[\"in_AllocationExpirationDate\"] = \"\"\n",
    "dfPOU[\"in_AllocationFlow_CFS\"] = dfPOUin['in_AllocationFlow_CFS'].astype(float)  # from POD data\n",
    "dfPOU['in_AllocationLegalStatusCV'] = \"\"\n",
    "dfPOU[\"in_AllocationNativeID\"] = dfPOUin['WRNUM']\n",
    "dfPOU['in_AllocationOwner'] = dfPOUin['in_AllocationOwner']  # from POD data\n",
    "dfPOU['in_AllocationPriorityDate'] = dfPOUin['in_AllocationPriorityDate']  # from POD data\n",
    "dfPOU[\"in_AllocationVolume_AF\"] = dfPOUin['in_AllocationVolume_AF'].astype(float)  # from POD data\n",
    "dfPOU[\"in_BeneficialUseCategory\"] = dfPOUin['in_BeneficialUseCategory']  # from POD data\n",
    "dfPOU['USE_BEG_DATE'] = \"\"\n",
    "dfPOU['USE_END_DATE'] = \"\"\n",
    "\n",
    "dfPOU = dfPOU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfPOUin))\n",
    "dfPOU.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "frames = [dfPOD, dfPOU]\n",
    "dfout = pd.concat(frames)\n",
    "\n",
    "#Removing all NaN Values and replacing with blank\n",
    "dfout = dfout.replace(np.nan, \"\", regex=True).reset_index()\n",
    "\n",
    "print(len(dfout))\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Sure datatype of Long, Lat, Wrex, Irrigation are Float\n",
    "dfout['in_AllocationFlow_CFS'] = pd.to_numeric(dfout['in_AllocationFlow_CFS'], errors='coerce')\n",
    "dfout['in_AllocationVolume_AF'] = pd.to_numeric(dfout['in_AllocationVolume_AF'], errors='coerce')\n",
    "dfout['in_AllocationCropDutyAmount'] = pd.to_numeric(dfout['in_AllocationCropDutyAmount'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype of used date fields. \n",
    "dfout['in_AllocationPriorityDate'] = pd.to_datetime(dfout['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "dfout['in_AllocationPriorityDate'] = pd.to_datetime(dfout[\"in_AllocationPriorityDate\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout['in_AllocationApplicationDate'] = pd.to_datetime(dfout['in_AllocationApplicationDate'], errors = 'coerce')\n",
    "dfout['in_AllocationApplicationDate'] = pd.to_datetime(dfout[\"in_AllocationApplicationDate\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout['in_AllocationExpirationDate'] = pd.to_datetime(dfout['in_AllocationExpirationDate'], errors = 'coerce')\n",
    "dfout['in_AllocationExpirationDate'] = pd.to_datetime(dfout[\"in_AllocationExpirationDate\"].dt.strftime('%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaterSourceTypeCV\n",
    "\n",
    "WaterSourceTypeCVDictionary={\n",
    "\"Underground\" : \"Groundwater\",\n",
    "\"Abandonded Well\" : \"Groundwater\",\n",
    "\"Point to Point\" : \"Surface Water\",\n",
    "\"Surface\" : \"Surface Water\",\n",
    "\"Return\" : \"Surface Water\",\n",
    "\"Drain\" : \"Surface Water\",\n",
    "\"Spring\" : \"Surface Water\",\n",
    "\"Rediversion\" : \"Surface Water\"}\n",
    "def CreateWaterSourceTypeCV(val):\n",
    "    if val == \"\" or pd.isnull(val):\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        val = val.strip()\n",
    "        try:\n",
    "            outString = WaterSourceTypeCVDictionary[val]\n",
    "        except:\n",
    "            outString = \"Unspecified\"\n",
    "    return outString\n",
    "\n",
    "dfout['in_WaterSourceTypeCV'] = dfout.apply(lambda row: CreateWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling 'AllocationTimeframeStart' & 'AllocationTimeframeEnd'\n",
    "#Both can have a string format for WaDE 2.0.\n",
    "    \n",
    "def assignTime(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outlist = \"\"\n",
    "    else:\n",
    "        colrowValue = str(colrowValue)\n",
    "        colrowValue = colrowValue.strip()\n",
    "        if len(colrowValue) == 4:\n",
    "            startmonth = colrowValue[0:1]\n",
    "            startday = colrowValue[1:2]\n",
    "            outlist = \"0\" + startmonth + \"/\" + \"0\" + startday\n",
    "        elif len(colrowValue) == 5:\n",
    "            startmonth = colrowValue[0:1]\n",
    "            startday = colrowValue[1:3]\n",
    "            outlist = \"0\" + startmonth + \"/\" + startday\n",
    "        elif len(colrowValue) == 6:\n",
    "            startmonth = colrowValue[0:2]\n",
    "            startday = colrowValue[2:4]\n",
    "            outlist = startmonth + \"/\" + startday\n",
    "        else:\n",
    "            outlist = \"\"\n",
    "  \n",
    "    return outlist\n",
    "\n",
    "\n",
    "dfout['in_AllocationTimeframeStart'] = dfout.apply(lambda row: assignTime(row['USE_BEG_DATE']), axis=1)\n",
    "dfout['in_AllocationTimeframeEnd'] = dfout.apply(lambda row: assignTime(row['USE_END_DATE']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign SiteTypeCV value.\n",
    "# Uses the re library, but requires for loop.\n",
    "# Order that the lists are inputed into dictoinary is important, want to overide generic search with a more specific search.\n",
    "\n",
    "# Create the Lists\n",
    "canalList = [\"canal\", \"canals\"]\n",
    "creekList = [\"creek\"]\n",
    "ditchList = [\"ditch\"]\n",
    "drainList = [\"drain\", \"drains\"]\n",
    "lakeList = [\"lake\"]\n",
    "pondList = [\"pond\"]\n",
    "reservoirList = [\"reservoir\"]\n",
    "riverList = [\"river\", \"fork\", \"surface\"]\n",
    "sloughList = [\"slough\"]\n",
    "springList = [\"spring\", \"springs\", \"gulch\", \"seep\"]\n",
    "tunnelList = [\"tunnel\", \"tunnels\"]\n",
    "washList = [\"wash\"]\n",
    "wellList = [\"well\", \"wells\", \"well:\", \"draw\", \"hollow\"]\n",
    "\n",
    "# Making the dictionary\n",
    "listDictionary = {}\n",
    "listDictionary[\"Canal\"] = canalList\n",
    "listDictionary[\"Creek\"] = creekList\n",
    "listDictionary[\"Ditch\"] = ditchList\n",
    "listDictionary[\"Drain\"] = drainList\n",
    "listDictionary[\"Lake\"] = lakeList\n",
    "listDictionary[\"Pond\"] = pondList\n",
    "listDictionary[\"Reservoir\"] = reservoirList\n",
    "listDictionary[\"River\"] = riverList\n",
    "listDictionary[\"Slough\"] = sloughList\n",
    "listDictionary[\"Spring\"] = springList\n",
    "listDictionary[\"Tunnel\"] = tunnelList\n",
    "listDictionary[\"Wash\"] = washList\n",
    "listDictionary[\"Well\"] = wellList\n",
    "\n",
    "def CreateSiteTypeCV(val):\n",
    "    if val == \"\" or pd.isnull(val):\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        outString = \"Unspecified\" # Default\n",
    "        \n",
    "        # Cleaning text / simple search format\n",
    "        val = val.replace(\",\", \" \")\n",
    "        val = val.replace(\".\", \" \")\n",
    "        val = val.replace(\";\", \" \")\n",
    "        val = val.replace(\"-\", \" \")\n",
    "        val = val.replace(\"/\", \" \")\n",
    "        val = val.replace(\"(\", \" \")\n",
    "        val = val.replace(\")\", \" \")\n",
    "        val = val.lower().strip()\n",
    "        val = \" \"+val+\" \"\n",
    "        \n",
    "        for x in listDictionary:\n",
    "            labelString = x\n",
    "            valueList = listDictionary[x]\n",
    "            for words in valueList:\n",
    "                if re.search(\" \"+words+ \" \", val): outString = x\n",
    "            \n",
    "    return outString\n",
    "\n",
    "dfout['in_SiteTypeCV'] = dfout.apply(lambda row: CreateSiteTypeCV( row['in_SiteTypeCV']), axis=1)\n",
    "dfout['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign LegalStatusCV value.\n",
    "# Uses the re library, but requires for loop.\n",
    "# Order that the lists are inputed into dictoinary is important, want to overide generic search with a more specific search.\n",
    "\n",
    "# Create the Lists\n",
    "ADECList = [\"ADEC\"]\n",
    "ADVList = [\"ADV\"]\n",
    "APPList = [\"APP\"]\n",
    "CERTList = [\"CERT\"]\n",
    "DECList = [\"DEC\"]\n",
    "DILList = [\"DIL\"]\n",
    "DISList = [\"DIS\"]\n",
    "EXPList = [\"EXP\"]\n",
    "FORFList = [\"FORF\"]\n",
    "LAPList = [\"LAP\"]\n",
    "NPRList = [\"NPR\"]\n",
    "NUSEList = [\"NUSE\"]\n",
    "PERFList = [\"PERF\"]\n",
    "REJList = [\"REJ\"]\n",
    "RNUMList = [\"RNUM\"]\n",
    "STATUSList = [\"STATUS\"]\n",
    "TEMPList = [\"TEMP\"]\n",
    "TERMList = [\"TERM\"]\n",
    "UGWCList = [\"UGWC\"]\n",
    "UNAPList = [\"UNAP\"]\n",
    "WDList = [\"WD\"]\n",
    "WUCList = [\"WUC\"]\n",
    "\n",
    "\n",
    "# Making the dictionary\n",
    "listDictionary = {}\n",
    "\n",
    "listDictionary[\"Lapsed\"] = LAPList\n",
    "\n",
    "listDictionary[\"Adjudication Decree\"] = ADECList\n",
    "listDictionary[\"Adverse Use Claim\"] = ADVList\n",
    "listDictionary[\"Approved\"] = APPList\n",
    "listDictionary[\"Certificated\"] = CERTList\n",
    "listDictionary[\"Decree\"] = DECList\n",
    "listDictionary[\"Diligence Claim\"] = DILList\n",
    "listDictionary[\"Disallowed\"] = DISList\n",
    "listDictionary[\"Expired\"] = EXPList\n",
    "listDictionary[\"Forfeited\"] = FORFList\n",
    "listDictionary[\"No Proof Required\"] = NPRList\n",
    "listDictionary[\"Nonuse\"] = NUSEList\n",
    "listDictionary[\"Perfected\"] = PERFList\n",
    "listDictionary[\"Rejected\"] = REJList\n",
    "listDictionary[\"Renumbered\"] = RNUMList\n",
    "listDictionary[\"Deff\"] = STATUSList\n",
    "listDictionary[\"Temp Applications\"] = TEMPList\n",
    "listDictionary[\"Terminated\"] = TERMList\n",
    "listDictionary[\"Underground Water Claim\"] = UGWCList\n",
    "listDictionary[\"Unapproved\"] = UNAPList\n",
    "listDictionary[\"Withdrawn\"] = WDList\n",
    "listDictionary[\"Water User`s Claim\"] = WUCList\n",
    "\n",
    "\n",
    "def CreateLegalStatus(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = \"\"\n",
    "        for x in listDictionary:\n",
    "            valueList = listDictionary[x]\n",
    "            for words in valueList:\n",
    "                if words in val: outString = x\n",
    "\n",
    "    return outString\n",
    "\n",
    "dfout['in_AllocationLegalStatusCV'] = dfout.apply(lambda row: CreateLegalStatus( row['in_AllocationLegalStatusCV']), axis=1)\n",
    "dfout['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing state site info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDEUT_WS\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = dfout['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    if (A == '') or (pd.isnull(A)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceTypeCV'] == A), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfout['in_WaterSourceNativeID'] = dfout.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "dfPoUshapetemp = gpd.read_file('Place of Use/PlaceOfUseService/PlaceOfUseService2.shp')\n",
    "dfPoUshapetemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp['RECORD_ID'].astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all NaN Values and replacing with blank\n",
    "dfout = dfout.replace(np.nan, \"\", regex=True)\n",
    "print(len(dfout))\n",
    "dfout.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to Finished File\n",
    "dfout.to_csv('P_UtahMaster.csv', index=False)  # The output\n",
    "dfPoUshape.to_csv('P_utGeometry.csv', index=False) # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
