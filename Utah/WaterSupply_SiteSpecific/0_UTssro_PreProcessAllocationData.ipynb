{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f178c7c",
   "metadata": {},
   "source": [
    "# Preprocessing Utah Reservoir and Gage data for WaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b11961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Utah/SS_ReservoirsObservationSites/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794dd299",
   "metadata": {},
   "source": [
    "## Data: \"Distribution Stations\" site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileInput = \"Distribution_Stations.csv\"\n",
    "dfds = pd.read_csv(fileInput)\n",
    "dfds['STATION_ID'] = dfds['STATION_ID'].astype(int)\n",
    "print(len(dfds))\n",
    "dfds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a86b4",
   "metadata": {},
   "source": [
    "## Data: get timeseries data via API service per site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03665236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done already. Run time = 35min 30s.\n",
    "\n",
    "# %%time\n",
    "\n",
    "# # Get list of STATION_ID\n",
    "# stationIDList = dfds['STATION_ID'].astype(int).astype(str).tolist()   \n",
    "\n",
    "# # issue with SSL verification for this data. Use this to ignore\n",
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# # create empty url dataframe for timeseries data\n",
    "# dfurl = pd.DataFrame()\n",
    "\n",
    "# slength = len(stationIDList)\n",
    "# for i in range(slength):\n",
    "#     fileInputURL = \"https://www.waterrights.utah.gov/dvrtdb/DailyCommaData.asp?BYEAR=1900&EYEAR=2023&StationId=\" + str(stationIDList[i])\n",
    "#     print(fileInputURL)\n",
    "#     try:\n",
    "#         # get metadata\n",
    "#         dfmetadata = pd.read_csv(fileInputURL, nrows=5) # read in file\n",
    "#         dfmetadata_T = dfmetadata.transpose() # tranpose the dataframe\n",
    "#         new_header = dfmetadata_T.iloc[0] #grab the first row for the header\n",
    "#         dfmetadata_T = dfmetadata_T[1:] #take the data less the header row\n",
    "#         dfmetadata_T.columns = new_header #set the header row as the df header\n",
    "#         unitsString = dfmetadata_T['Units'].astype(str).to_string() # convert value to string\n",
    "        \n",
    "#         # get timeseries\n",
    "#         dftemp = pd.read_csv(fileInputURL, skiprows=5)\n",
    "#         dftemp['Units'] = unitsString\n",
    "#         dftemp['timeseriesID'] =  str(stationIDList[i])\n",
    "#         dftemp['url'] = fileInputURL\n",
    "#         dfurl = pd.concat([dfurl, dftemp])\n",
    "#     except:\n",
    "#         dftemp = pd.DataFrame()\n",
    "#         dftemp['Units'] = \"\"\n",
    "#         dftemp['timeseriesID'] =  str(stationIDList[i])\n",
    "#         dftemp['url'] = fileInputURL\n",
    "#         dfurl = pd.concat([dfurl, dftemp])\n",
    "#         print(\"Error, issue with API return.\")\n",
    "\n",
    "        \n",
    "# dfurl.to_csv('url_timeseries.zip', compression=dict(method='zip', archive_name='url_timeseries.csv'), index=False)\n",
    "# print(len(dfurl))\n",
    "# dfurl.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78898727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - dataframeTimeSeries.zip\n",
    "df_timeseries = pd.read_csv('url_timeseries.zip', compression='zip')\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in df_timeseries:\n",
    "    df_timeseries['WaDEUUID'] = \"utssro\" + df_timeseries.index.astype(str)\n",
    "    df_timeseries.to_csv('url_timeseries.zip', compression=dict(method='zip', archive_name='url_timeseries.csv'), index=False)\n",
    "\n",
    "print(len(df_timeseries))\n",
    "df_timeseries.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b606e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries_ds = pd.merge(df_timeseries, dfds, left_on='timeseriesID', right_on='STATION_ID', how='left')\n",
    "print(len(df_timeseries_ds))\n",
    "df_timeseries_ds.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f874c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just checking units\n",
    "\n",
    "# # Assign Units\n",
    "\n",
    "# def checkUnitsFunc(valA):\n",
    "#     valA = str(valA).strip().lower()\n",
    "#     if 'cfs' in valA:\n",
    "#         outString = \"CFS\"\n",
    "#     if 'acft' in valA:\n",
    "#         outString = \"AF\"\n",
    "#     if 'feet' in valA:\n",
    "#         outString = \"FT\"\n",
    "#     return outString\n",
    "\n",
    "# df_timeseries_ds['timeseriesUnits'] = df_timeseries_ds.apply(lambda row: checkUnitsFunc(row['Units']), axis=1)\n",
    "# df_timeseries_ds['timeseriesUnits'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ad708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign VariableCV\n",
    "\n",
    "def checkVariableCVFunc(valA):\n",
    "    valA = str(valA).strip().lower()\n",
    "    \n",
    "    if 'cfs' in valA:\n",
    "        outString = \"Discharge\"\n",
    "    if 'discharge in cfs' in valA:\n",
    "        outString = \"Discharge\"\n",
    "    if 'height in feet' in valA:\n",
    "        outString = \"Stage\"\n",
    "    if 'storage in acft' in valA:\n",
    "        outString = \"Storage\"\n",
    "    if 'discharge in acft' in valA:\n",
    "        outString = \"Discharge AF\"\n",
    "    if 'diversion in acft' in valA:\n",
    "        outString = \"Diversion\"\n",
    "    if 'evaporation in cfs' in valA:\n",
    "        outString = \"Evaporation\"\n",
    "    \n",
    "    return outString\n",
    "\n",
    "df_timeseries_ds['in_VariableCV'] = df_timeseries_ds.apply(lambda row: checkVariableCVFunc(row['Units']), axis=1)\n",
    "df_timeseries_ds['in_VariableCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df020289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign SiteTypeCV\n",
    "\n",
    "def checkSiteTypeCVFunc(valA):\n",
    "    valA = str(valA).strip().lower()\n",
    "    if 'cfs' in valA:\n",
    "        outString = \"Stream Gage\"\n",
    "    if 'discharge in cfs' in valA:\n",
    "        outString = \"Stream Gage\"\n",
    "    if 'height in feet' in valA:\n",
    "        outString = \"Stream Gage\"\n",
    "    if 'storage in acft' in valA:\n",
    "        outString = \"Reservoir\"\n",
    "    if 'discharge in acft' in valA:\n",
    "        outString = \"Stream Gage\"\n",
    "    if 'diversion in acft' in valA:\n",
    "        outString = \"Stream Gage\"\n",
    "    if 'evaporation in cfs' in valA:\n",
    "        outString = \"Stream Gage\"\n",
    "    \n",
    "    return outString\n",
    "\n",
    "df_timeseries_ds['in_SiteTypeCV'] = df_timeseries_ds.apply(lambda row: checkSiteTypeCVFunc(row['Units']), axis=1)\n",
    "df_timeseries_ds['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf616ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign BeneficialUseCategory\n",
    "\n",
    "def checkBeneficialUseCategoryFunc(valA):\n",
    "    valA = str(valA).strip().lower()\n",
    "    if 'cfs' in valA:\n",
    "        outString = \"Discharge\"\n",
    "    if 'discharge in cfs' in valA:\n",
    "        outString = \"Discharge\"\n",
    "    if 'height in feet' in valA:\n",
    "        outString = \"Stage\"\n",
    "    if 'storage in acft' in valA:\n",
    "        outString = \"Storage\"\n",
    "    if 'discharge in acft' in valA:\n",
    "        outString = \"Discharge\"\n",
    "    if 'diversion in acft' in valA:\n",
    "        outString = \"Diversion\"\n",
    "    if 'evaporation in cfs' in valA:\n",
    "        outString = \"Evaporation\"\n",
    "    \n",
    "    return outString\n",
    "\n",
    "df_timeseries_ds['in_BeneficialUseCategory'] = df_timeseries_ds.apply(lambda row: checkBeneficialUseCategoryFunc(row['Units']), axis=1)\n",
    "df_timeseries_ds['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaDE Fields\n",
    "\n",
    "# output dataframe\n",
    "df1 = pd.DataFrame(index=df_timeseries_ds.index)\n",
    "\n",
    "# data assessment\n",
    "df1['WaDEUUID'] = df_timeseries_ds['WaDEUUID']\n",
    "\n",
    "# variable info\n",
    "df1['in_VariableCV'] = df_timeseries_ds['in_VariableCV']\n",
    "\n",
    "# water source info\n",
    "df1['in_WaterSourceName'] = df_timeseries_ds['SYSTEM']\n",
    "df1['in_WaterSourceNativeID'] = \"\" # fill out below\n",
    "df1['in_WaterSourceTypeCV'] = \"Surface Water\"\n",
    "\n",
    "# Site Info\n",
    "df1['in_CoordinateAccuracy'] = \"WaDE Unspecified\"\n",
    "df1['in_CoordinateMethodCV'] = \"WaDE Unspecified\"\n",
    "df1['in_County'] = \"WaDE Unspecified\"\n",
    "df1['in_HUC12'] = \"WaDE Unspecified\"\n",
    "df1['in_HUC8'] = \"WaDE Unspecified\"\n",
    "df1['in_Latitude'] = df_timeseries_ds['Latitude']\n",
    "df1['in_Longitude'] = df_timeseries_ds['Longitude']\n",
    "df1['in_PODorPOUSite'] = df_timeseries_ds['in_SiteTypeCV'] # samething here\n",
    "df1['in_SiteNativeID'] = df_timeseries_ds['STATION_ID']\n",
    "df1['in_SiteName'] = df_timeseries_ds['NAME']\n",
    "df1['in_SiteTypeCV'] = df_timeseries_ds['in_SiteTypeCV']\n",
    "df1['in_StateCV'] = 'UT'\n",
    "\n",
    "# Site VariableAmounts Info\n",
    "df1['in_Amount'] = df_timeseries_ds['Flow'] # change here\n",
    "df1['in_BeneficialUseCategory'] = df_timeseries_ds['in_BeneficialUseCategory']\n",
    "df1['in_ReportYearCV'] = \"\" # will fill in below\n",
    "df1['in_TimeframeEnd'] = df_timeseries_ds['Date']\n",
    "df1['in_TimeframeStart'] = df_timeseries_ds['Date']\n",
    "\n",
    "df1 = df1.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(len(df1))\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425554d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = df1.copy()\n",
    "print(len(dfout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea89a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e485f862",
   "metadata": {},
   "source": [
    "## Fixing a few errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create VariableSpecificCV field\n",
    "\n",
    "dfout['in_VariableSpecificCV'] = dfout['in_VariableCV'].astype(str) + \"_Daily_\" + dfout['in_BeneficialUseCategory'].astype(str) + \"_\" + dfout['in_WaterSourceTypeCV'].astype(str)\n",
    "dfout['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82766db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from string to datetime64[ns]\n",
    "# extracting year component of datetime64[ns]\n",
    "dfout['in_TimeframeEnd'] = pd.to_datetime(dfout['in_TimeframeEnd'])\n",
    "dfout['in_TimeframeStart'] = pd.to_datetime(dfout['in_TimeframeStart'])\n",
    "dfout['in_ReportYearCV'] = dfout['in_TimeframeStart'].dt.to_period('Y')\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude \n",
    "dfout['in_Latitude'] = pd.to_numeric(dfout['in_Latitude'], errors='coerce').fillna(0)\n",
    "dfout['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Longitude\n",
    "dfout['in_Longitude'] = pd.to_numeric(dfout['in_Longitude'], errors='coerce').fillna(0)\n",
    "dfout['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Water Amount datatype\n",
    "dfout['in_Amount'] = pd.to_numeric(dfout['in_Amount'], errors='coerce').fillna(0)\n",
    "dfout['in_Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDEUT_WS\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = dfout['in_WaterSourceName']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    if (A == '') or (pd.isnull(A)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceName'] == A), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfout['in_WaterSourceNativeID'] = dfout.apply(lambda row: retrieveWaterSourceNativeID(row['in_WaterSourceName']), axis=1)\n",
    "dfout['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89691d7e",
   "metadata": {},
   "source": [
    "## Review and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to Finished File\n",
    "dfout.to_csv('P_utSSROMain.zip', index=False, compression=\"zip\")  # The output, save as a zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60b8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
