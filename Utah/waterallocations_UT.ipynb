{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from waterallocationsFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "working_dir = \"C:/tseg/jupyterWaDE\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs \n",
    "fileInput=\"WRCHEX_WATER_MASTER.csv\" #\"Water_Master.csv\"\n",
    "FileInput2=\"OWNERS.csv\"     #\"UtahOwners.csv\"\n",
    "FileInput3= \"IRRIGATION_MASTER.csv\"    #\"Irrigation_Master.csv\"\n",
    "# municipal and power capacity\n",
    "FielInput4 = 'WTRUSE_Municipal.csv' # WRNUM MUNICIPALITY AllocationCommunityWaterSupplySystem \t\n",
    "FileInput5 = 'WTRUSE_Power.csv '# WRNUM POWER_CAPACITY/PowerGeneratedGWh, POWER_UNITS/div by M\n",
    "\n",
    "# water sources look up\n",
    "inp_wtrsrs=\"watersources.csv\"\n",
    "# sites look up\n",
    "inpt_sitdim = 'sites.csv'\n",
    "\n",
    "#output: water allocation\n",
    "allocCSV=\"waterallocations.csv\" #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## WaDE columns\n",
    "\n",
    "#the followwing fields have difference between the table here (edited by DPL) and that on the schema website\n",
    "#http://schema.westernstateswater.org/tables/Input_AllocationAmounts_fact.html\n",
    "\"\"\"\n",
    "BeneficialUseCategory, PrimaryUseCategory, AllocationTimeframeStart, AllocationTimeframeEnd, \" \"\n",
    "BeneficialUseCategoryCV, PrimaryUseCategoryCV, TimeframeStartDate,\tTimeframeEndDate,\tGeometry\t\n",
    "\"\"\"\n",
    "# UUIDs: Add UUIDs for all dim tables\n",
    "# OrganizationUUID, SiteUUID, VariableSpecificUUID, WaterSourceUUID, MethodUUID\n",
    "columns = [\"OrganizationUUID\", \"SiteUUID\", \"VariableSpecificUUID\", \"WaterSourceUUID\", \"MethodUUID\", \"PrimaryUseCategory\",\n",
    "           \"BeneficialUseCategory\", \"AllocationNativeID\", \"AllocationTypeCV\", \"AllocationOwner\",\n",
    "           \"AllocationApplicationDate\", \"AllocationPriorityDate\", \"AllocationLegalStatusCV\", \"AllocationCropDutyAmount\",\n",
    "           \"AllocationExpirationDate\",\n",
    "           \"AllocationChangeApplicationIndicator\", \"LegacyAllocationIDs\", \"AllocationBasisCV\", \"AllocationTimeframeStart\",\n",
    "           \"AllocationTimeframeEnd\", \"AllocationAmount\", \"AllocationMaximum\", \"PopulationServed\", \"PowerGeneratedGWh\",\n",
    "           \"IrrigatedAcreage\", \"AllocationCommunityWaterSupplySystem\", \"AllocationSDWISIdentifierCV\",\n",
    "           \"AllocationAssociatedWithdrawalSiteIDs\", \"AllocationAssociatedConsumptiveUseSiteIDs\", \"WaterAllocationNativeURL\",\n",
    "           \"CustomerTypeCV\", \"IrrigationMethodCV\", \"CropTypeCV\", \"CommunityWaterSupplySystem\", \"DataPublicationDate\",\n",
    "           \"DataPublicationDOI\"]\n",
    "\n",
    "dtypesx = [''] #here we could theoretically specify data types for each column name, but we didn't need to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### target dataFrame\n",
    "\n",
    "# TODO: assumes dtypes inferred from CO file\n",
    "outdf100=pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####%%timeit\n",
    "\n",
    "####### Read Inputs and merge tables\n",
    "# We are joining 'on-left': keep all rows of mater table (check if need to be refined)\n",
    "\n",
    "print(\"Reading inputs...\")\n",
    "# water_master\n",
    "input_columns = ['RECORD_ID', 'WREX_SOURCE', 'WATER_USES', 'WRNUM', 'TYPE_OF_RIGHT', 'DATE_FILED',\n",
    "               'DATE_PRIORITY', 'WREX_STATUS', 'IRRIGATION_DEPLETION','DATE_TERMINATED',\n",
    "               'WREX_CFS', 'WREX_ACFT']\n",
    "df100_l = pd.read_csv(fileInput,encoding = \"ISO-8859-1\", usecols = input_columns) #, or alternatively encoding = \"utf-8\"\n",
    "#df100\n",
    "#print(len(df100_l.index))\n",
    "df100_l.drop_duplicates(inplace=True)\n",
    "#print (len(df100_l.index))\n",
    "\n",
    "###### Join tables\n",
    "\n",
    "# Allocation owner\n",
    "input_owner_cols = ['WRCHEX', 'OWNER_LAST_NAME', 'OWNER_FIRST_NAME']\n",
    "df200 = pd.read_csv(FileInput2,encoding = \"ISO-8859-1\", usecols =input_owner_cols)  #UtahOwners\n",
    "#print(len(df200))\n",
    "df200.drop_duplicates(inplace=True)\n",
    "#print(len(df200))\n",
    "df100_ll=pd.merge(df100_l, df200, left_on='WRNUM', right_on='WRCHEX', how='left') #joined Utahowners table into Master_Table\n",
    "#df100_ll\n",
    "#print (len(df100_ll.index))\n",
    "\n",
    "# Irrigation master\n",
    "input_irr_cols = ['WRNUM', 'IRRIGATION_ACREAGE', 'USE_BEG_DATE', 'USE_END_DATE']\n",
    "df300=pd.read_csv(FileInput3,encoding = \"ISO-8859-1\", usecols = input_irr_cols)\n",
    "#print(len(df300))\n",
    "df300.drop_duplicates(inplace=True)\n",
    "#print(len(df300))\n",
    "df100_3=pd.merge(df100_ll, df300, left_on='WRNUM', right_on='WRNUM', how='left') #joined Irrigation master table into Master_Table\n",
    "#df100\n",
    "#print (len(df100.index))\n",
    "\n",
    "# municipal \n",
    "df350=pd.read_csv(FileInput4,encoding = \"ISO-8859-1\", usecols = ['WRNUM', 'MUNICIPALITY'])\n",
    "#print(len(df300))\n",
    "df350.drop_duplicates(inplace=True)\n",
    "#print(len(df300))\n",
    "df100_4=pd.merge(df100_3, df350, left_on='WRNUM', right_on='WRNUM', how='left') \n",
    "#df100\n",
    "#print (len(df100_4.index))\n",
    "\n",
    "# power capacity\n",
    "df360=pd.read_csv(FileInput5,encoding = \"ISO-8859-1\", usecols = ['WRNUM', 'POWER_CAPACITY'])\n",
    "#print(len(df300))\n",
    "df360.drop_duplicates(inplace=True)\n",
    "#print(len(df300))\n",
    "df100=pd.merge(df100_4, df360, left_on='WRNUM', right_on='WRNUM', how='left')\n",
    "#df100\n",
    "#print (len(df100_4.index))\n",
    "\n",
    "df100.drop_duplicates(inplace=True)\n",
    "df100 = df100.reset_index(drop=True)\n",
    "#print (len(df100.index))\n",
    "\n",
    "#df100 = df100.head(10000) #only runs first 10000 lines for testing.\n",
    "#df100\n",
    "\n",
    "df100 = df100.replace(np.nan, '')\n",
    "#df100\n",
    "\n",
    "# water sources look up\n",
    "df400 = pd.read_csv(inp_wtrsrs,encoding = \"ISO-8859-1\")\n",
    "#drop duplicate rows ---this one is not necessary once the water sources table is refined to remove duplicates\n",
    "df400 = df400.drop_duplicates(subset=['WaterSourceName'])\n",
    "#df400\n",
    "\n",
    "# sites look up\n",
    "df500 = pd.read_csv(inpt_sitdim,encoding = \"ISO-8859-1\")\n",
    "#df500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adding SiteUUID...\")\n",
    "#append 'UTDWRE'\n",
    "df100 = df100.assign(SiteUUID='')  #add new column and make is nan\n",
    "\n",
    "# for multi-to-multi site ID mapping\n",
    "df100['SiteUUID'] = df100.apply(lambda row: assignSiteID(row['WRNUM'], df500), axis=1)\n",
    "#df100['SiteUUID'] = df100['WRNUM'].apply(lambda row: assignSiteID(row, df500), axis=1)\n",
    "\n",
    "#df100['SiteUUID'] = df100.apply(lambda row: ('' if (str(row['RECORD_ID']) == '') else (\"_\".join([\"UTDWRE\", str(row['RECORD_ID'])]))) , axis=1)\n",
    "\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beneficial uses...\")\n",
    "#\n",
    "df100 = df100.assign(BeneficialUseCategory='')\n",
    "## df100 = df100.dropna(subset=['WATER_USES']) 10.15.19 not application here---there are empty cells\n",
    "##df100 = df100.reset_index(drop=True)\n",
    "df100['BeneficialUseCategory'] = df100.apply(lambda row: assignBenUseCategory(row['WATER_USES']), axis=1)\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Water sources...\")\n",
    "df100 = df100.assign(WaterSourceUUID='')\n",
    "df100['WaterSourceUUID'] = df100.apply(lambda row: assignWaterSourceID(row['WREX_SOURCE'], df400), axis=1)\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AllocationTypeCV...\")\n",
    "df100 = df100.assign(AllocationTypeCV='')\n",
    "#\n",
    "df100['AllocationTypeCV'] = df100.apply(lambda row: assignallocTypeCV(row['TYPE_OF_RIGHT']), axis=1)\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AllocationOwner...\")\n",
    "df100 = df100.assign(AllocationOwner='')\n",
    "df100['AllocationOwner'] = df100.apply(lambda row: assignownerName(row['OWNER_LAST_NAME'], row['OWNER_FIRST_NAME']), axis=1)\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Allocation Legal Status...\")\n",
    "df100 = df100.assign(AllocationLegalStatusCV='')\n",
    "df100['AllocationLegalStatusCV'] = df100.apply(lambda row: assignallocLegalStatausCV(row['WREX_STATUS']), axis=1)\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Allocation application date...\")\n",
    "\n",
    "df100 = df100.assign(AllocationApplicationDate='')\n",
    "\n",
    "df100['AllocationApplicationDate'] = df100.apply(lambda row: \n",
    "                                               strLiteralToDateString(row['DATE_FILED']), axis=1)\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Allocation priority date...\")\n",
    "\n",
    "df100 = df100.assign(AllocationPriorityDate='')\n",
    "\n",
    "df100['AllocationPriorityDate'] = df100.apply(lambda row: \n",
    "                                        strLiteralToDateString(row['DATE_PRIORITY']), axis=1)\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Power capacity\")\n",
    "\n",
    "df100 = df100.assign(PowerGeneratedGWh='')\n",
    "\n",
    "# input POWER_UNITS KW; target GW /div by 10000\n",
    "# TODO: note the target name needs to change to GW\n",
    "df100['PowerGeneratedGWh'] = df100.apply(lambda row: row['POWER_CAPACITY']/1000000, axis=1)\n",
    "#df100['PowerGeneratedGWh'] = df100['POWER_CAPACITY'].apply(lambda cp: cp/1000000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Copying all columns...\")\n",
    "#\n",
    "destCols=[\"SiteUUID\",\n",
    "          \"WaterSourceUUID\",\n",
    "          \"BeneficialUseCategory\", \"AllocationNativeID\",\n",
    "          \"AllocationTypeCV\",\n",
    "          \"AllocationOwner\", \n",
    "          \"AllocationApplicationDate\", \"AllocationPriorityDate\",\n",
    "          \"AllocationLegalStatusCV\",\"AllocationAmount\", \"AllocationMaximum\", \"AllocationCropDutyAmount\",\n",
    "          \"AllocationExpirationDate\", \n",
    "          \"IrrigatedAcreage\",\n",
    "          \"AllocationTimeframeStart\", \"AllocationTimeframeEnd\",\n",
    "          'AllocationCommunityWaterSupplySystem',\n",
    "          'PowerGeneratedGWh'\n",
    "         ]\n",
    "#\n",
    "sourCols=[\"SiteUUID\",\n",
    "          \"WaterSourceUUID\",\n",
    "          \"BeneficialUseCategory\", \"WRNUM\",\n",
    "          \"AllocationTypeCV\",\n",
    "          \"AllocationOwner\",\n",
    "          \"AllocationApplicationDate\", \"AllocationPriorityDate\",\n",
    "          \"AllocationLegalStatusCV\",\"WREX_CFS\",\"WREX_ACFT\", \"IRRIGATION_DEPLETION\",\n",
    "          \"DATE_TERMINATED\",\n",
    "          \"IRRIGATION_ACREAGE\",\n",
    "          \"USE_BEG_DATE\", \"USE_END_DATE\",\n",
    "          'MUNICIPALITY',\n",
    "          'PowerGeneratedGWh'\n",
    "         ]\n",
    "\n",
    "outdf100[destCols] = df100[sourCols]\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded\n",
    "print(\"Hard coded...\")\n",
    "#hard coded\n",
    "outdf100.OrganizationUUID = \"UTDWRE\"\n",
    "outdf100.VariableSpecificUUID = \"Water Allocation all\"\n",
    "outdf100.MethodUUID = \"UT_WaterAllocation\"\n",
    "outdf100.AllocationBasisCV = \"Unknown\"\n",
    "# check this later\n",
    "outdf100.PrimaryUseCategory = \"Irrigation\"\n",
    "outdf100.DataPublicationDate = datetime.now().strftime('%m/%d/%Y')    #\"10/31/2019\" # edit this to the code run date\n",
    "\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null allocations...\")\n",
    "# if both Allocation amount and Allocation maximum are empty drop row and save it to a Allocations_missing.csv\n",
    "#outdf100 = outdf100.replace('', np.nan) #replace blank strings by NaN,\n",
    "outdf100purge = outdf100.loc[(outdf100[\"AllocationAmount\"] == '') & (outdf100[\"AllocationMaximum\"] == '')]\n",
    "if len(outdf100purge.index) > 0:\n",
    "    outdf100purge.to_csv('waterallocations_missing.csv')    #index=False,\n",
    "    dropIndex = outdf100.loc[(outdf100[\"AllocationAmount\"] == '') & (outdf100[\"AllocationMaximum\"] == '')].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null SiteUUIDs...\")\n",
    "outdf100nullID = outdf100.loc[outdf100[\"SiteUUID\"] == '']\n",
    "if len(outdf100nullID.index) > 0:\n",
    "    dropIndex = outdf100.loc[outdf100[\"SiteUUID\"] == ''].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null Priority date...\")\n",
    "outdf100nullPR = outdf100.loc[outdf100[\"AllocationPriorityDate\"] == '']\n",
    "if len(outdf100nullPR.index) > 0:\n",
    "    dropIndex = outdf100.loc[outdf100[\"AllocationPriorityDate\"] == ''].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null WaterSourceUUID...\")\n",
    "outdf100nullPR = outdf100.loc[outdf100[\"WaterSourceUUID\"] == '']\n",
    "if len(outdf100nullPR.index) > 0:\n",
    "    dropIndex = outdf100.loc[outdf100[\"WaterSourceUUID\"] == ''].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping duplicate rows...\")\n",
    "#drop duplicate rows; just make sure\n",
    "outdf100Duplicated=outdf100.loc[outdf100.duplicated()]\n",
    "if len(outdf100Duplicated.index) > 0:\n",
    "    outdf100Duplicated.to_csv(\"waterallocations_duplicaterows.csv\")  # index=False,\n",
    "    outdf100.drop_duplicates(inplace=True)   #\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping duplicate key IDs...\")\n",
    "\"\"\"from merge statement of stored procedure for waterallocations import:\n",
    "\tMERGE INTO Core.AllocationAmounts_fact AS Target\n",
    "\tUSING q1 AS Source ON\n",
    "\t\tISNULL(Target.OrganizationID, '') = ISNULL(Source.OrganizationID, '')\n",
    "\t\tAND ISNULL(Target.AllocationNativeID, '') = ISNULL(Source.AllocationNativeID, '')\n",
    "\t\tAND ISNULL(Target.VariableSpecificID, '') = ISNULL(Source.VariableSpecificID, '')\n",
    "\t\tAND ISNULL(Target.PrimaryUseCategoryCV, '') = ISNULL(Source.PrimaryUseCategory, '')\n",
    "\"\"\"\n",
    "\n",
    "dupColumns = [\"OrganizationUUID\", \"AllocationNativeID\", \"VariableSpecificUUID\", \"PrimaryUseCategory\"]\n",
    "\n",
    "outdf100Duplicated=outdf100.loc[outdf100.duplicated(subset=dupColumns)]\n",
    "if len(outdf100Duplicated.index) > 0:\n",
    "    print(\"There are duplicate key IDs\")\n",
    "    outdf100Duplicated.to_csv(\"waterallocations_duplicateKeyID_rows.csv\")  # index=False,\n",
    "    outdf100.drop_duplicates(subset=dupColumns, inplace=True)   #\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100\n",
    "\n",
    "outdf100Duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking required is not null...\")\n",
    "# check if any cell of these columns is null\n",
    "requiredCols = [\"OrganizationUUID\", \"VariableSpecificUUID\", \"WaterSourceUUID\", \"MethodUUID\", \"AllocationPriorityDate\"] #SiteUUID\n",
    "# outdf100_nullMand = outdf100.loc[outdf100.isnull().any(axis=1)] --for all cols\n",
    "# outdf100_nullMand = outdf100.loc[outdf100[requiredCols].isnull().any(axis=1)]\n",
    "#(outdf100[\"SiteUUID\"].isnull()) |\n",
    "outdf100_nullMand = outdf100.loc[(outdf100[\"OrganizationUUID\"] == '') |\n",
    "                                (outdf100[\"VariableSpecificUUID\"] == '') |\n",
    "                                (outdf100[\"WaterSourceUUID\"] == '') |\n",
    "                                (outdf100[\"MethodUUID\"] == '') |\n",
    "                                (outdf100[\"AllocationPriorityDate\"] == '')]\n",
    "#outdf100_nullMand = outdf100.loc[[False | (outdf100[varName].isnull()) for varName in requiredCols]]\n",
    "if(len(outdf100_nullMand.index) > 0):\n",
    "    outdf100_nullMand.to_csv('waterallocations_mandatoryFieldMissing.csv')  # index=False,\n",
    "#ToDO: purge these cells if there is any missing? #For now left to be inspected\n",
    "\n",
    "#outdf100_nullMand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Do not run the following with the rest of the code  (it is for inspection)\n",
    "\"\"\"\n",
    "print(\"Long site ids...\")\n",
    "\n",
    "outdf100Long = outdf100[outdf100['SiteUUID'].apply(lambda x: len(x) > 500)]\n",
    "if len(outdf100Long.index) > 0:\n",
    "    print(\"There are rows with too long siteids\")\n",
    "    outdf100Long.to_csv(\"waterallocations_longsiteid.csv\")  # index=False,\n",
    "    dropIndex = outdf100[outdf100['SiteUUID'].apply(lambda x: len(x) > 500)].index\n",
    "    outdf100 = outdf100.drop(dropIndex)   #\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100\n",
    "\n",
    "outdf100Long\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing outputs...\")\n",
    "#write out\n",
    "outdf100.to_csv(allocCSV, index=False, encoding = \"utf-8\")\n",
    "\n",
    "print(\"Done Water Allocation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
