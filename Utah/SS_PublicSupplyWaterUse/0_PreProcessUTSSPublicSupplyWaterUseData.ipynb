{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Utah Site Specific data for WaDEQA upload.\n",
    "- Date Updated: 11/14/2021\n",
    "- Purpose:  To preprocess the UDWRi and UDWRe data into one master file for simple DataFrame creation and extraction\n",
    "\n",
    "Notes:\n",
    "- Will treat UDWRi System + UDWRe data as POUs, and UDWRi Source data as PODs.\n",
    "- For annual data, assume start = 01/01 & end =  12/31 for now.\n",
    "- Seperate out water use System data data by customer type / benefical use (e.g. Domestic, Commerical, Industrial, Insitutional).  Do not use the Total fields.\n",
    "- Seperate out the water use Source data by monthly and again by annual.\n",
    "- create missing elements (water source type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Utah/SS_PublicSupplyWaterUse/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place of Use Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UDWRi_SystemData_PerUse_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - UDWRi_SystemData_PerUse_input.csv\n",
    "fileInput = \"UDWRi_SystemData_PerUse_input.csv\"\n",
    "dfsyspu = pd.read_csv(fileInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfsyspu:\n",
    "    dfsyspu['WaDEUUID'] = \"utsyspu\" + dfsyspu.index.astype(str)\n",
    "    dfsyspu.to_csv('UDWRi_SystemData_PerUse_input.csv', index=False)\n",
    "\n",
    "print(len(dfsyspu))\n",
    "dfsyspu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up input data\n",
    "# ---------------------------\n",
    "\n",
    "#active recods only\n",
    "dfsyspu = dfsyspu[dfsyspu['System Status'] == \"Active\"]\n",
    "\n",
    "# drop rows with a null Year value\n",
    "dfsyspu = dfsyspu.dropna(subset=['History Year'])\n",
    "\n",
    "# Adjust data type of fields\n",
    "dfsyspu['Year'] = dfsyspu['History Year'].astype(int)\n",
    "\n",
    "print(len(dfsyspu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useTypeList = ['Domestic', 'Commercial', 'Industrial', 'Institutional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfsyspuOut = pd.DataFrame()\n",
    "\n",
    "for x in useTypeList:\n",
    "    useTypeString = str(x)\n",
    "    print(useTypeString)\n",
    "    \n",
    "    dftemp = pd.DataFrame(index=dfsyspu.index)\n",
    "    # Variable Info\n",
    "    dftemp['in_VariableCV'] = \"Delivered Water Use\"\n",
    "    dftemp['in_VariableSpecificCV'] = \"Delivered Water Use_Annual_\" + useTypeString\n",
    "    \n",
    "    # SiteVariableAmounts_fact Info\n",
    "    amountUseStr = useTypeString + \" Use\"\n",
    "    dftemp['in_Amount'] = dfsyspu[amountUseStr]\n",
    "    dftemp['in_PopulationServed'] = dfsyspu['Domestic Connections']\n",
    "    dftemp['in_BenUse'] = useTypeString\n",
    "#     dftemp['in_CustomerTypeCV'] = useTypeString\n",
    "    dftemp['in_ReportYearCV'] = dfsyspu['History Year']\n",
    "    dftemp['in_TimeframeEnd'] = '12/31/' + dfsyspu['History Year'].astype(str)\n",
    "    dftemp['in_TimeframeStart'] = '01/01/' + dfsyspu['History Year'].astype(str)\n",
    "    \n",
    "    # Water Source Info\n",
    "    dftemp['in_WaterSourceTypeCV'] = \"Unspecified\"\n",
    "    \n",
    "    # link to site data\n",
    "    dftemp['linkKey'] = dfsyspu['System ID']\n",
    "    \n",
    "    dfsyspuOut = pd.concat([dfsyspuOut, dftemp])   \n",
    "\n",
    "print(len(dfsyspuOut))\n",
    "dfsyspuOut.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UDWRi_SystemData_Total_no0Null_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - UDWRi_SystemData_Total_no0Null_input.csv\n",
    "fileInput = \"UDWRi_SystemData_Total_no0Null_input.csv\"\n",
    "dfsyst = pd.read_csv(fileInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfsyst:\n",
    "    dfsyst['WaDEUUID'] = \"utsyst\" + dfsyst.index.astype(str)\n",
    "    dfsyst.to_csv('UDWRi_SystemData_Total_no0Null_input.csv', index=False)\n",
    "\n",
    "print(len(dfsyst))\n",
    "dfsyst.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up input data\n",
    "# ---------------------------\n",
    "\n",
    "#active recods only\n",
    "dfsyst = dfsyst[dfsyst['System Status'] == \"Active\"]\n",
    "\n",
    "# drop rows with a null Year value\n",
    "dfsyst = dfsyst.dropna(subset=['History Year'])\n",
    "\n",
    "# Adjust data type of fields\n",
    "dfsyst['Year'] = dfsyst['History Year'].astype(int)\n",
    "\n",
    "print(len(dfsyst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useTypeList = ['Total Use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfsystOut = pd.DataFrame()\n",
    "\n",
    "for x in useTypeList:\n",
    "    useTypeString = str(x)\n",
    "    print(useTypeString)\n",
    "    \n",
    "    dftemp = pd.DataFrame(index=dfsyst.index)\n",
    "    # Variable Info\n",
    "    dftemp['in_VariableCV'] = \"Delivered Water Use\"\n",
    "    dftemp['in_VariableSpecificCV'] = \"Delivered Water Use_Annual_DCII\"\n",
    "    \n",
    "    # SiteVariableAmounts_fact Info\n",
    "    amountUseStr = useTypeString\n",
    "    dftemp['in_Amount'] = dfsyst[amountUseStr]\n",
    "    dftemp['in_PopulationServed'] = dfsyst['Domestic Connections']\n",
    "    dftemp['in_BenUse'] = \"DCII\"\n",
    "#     dftemp['in_CustomerTypeCV'] = \"DCII\"\n",
    "    dftemp['in_ReportYearCV'] = dfsyst['History Year']\n",
    "    dftemp['in_TimeframeEnd'] = '12/31/' + dfsyst['History Year'].astype(str)\n",
    "    dftemp['in_TimeframeStart'] = '01/01/' + dfsyst['History Year'].astype(str)\n",
    "    \n",
    "    # Water Source Info\n",
    "    dftemp['in_WaterSourceTypeCV'] = \"Unspecified\"\n",
    "    \n",
    "    # link to site data\n",
    "    dftemp['linkKey'] = dfsyst['System ID']\n",
    "    \n",
    "    dfsystOut = pd.concat([dfsystOut, dftemp])   \n",
    "\n",
    "print(len(dfsystOut))\n",
    "dfsystOut.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UDWRe Culinary Service Area Data\n",
    "- Need to tie the UDWRi system data to the UDWRe site info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "ShapeFileInput = gpd.read_file('shapefile/CulinaryWaterServiceAreas.shp')\n",
    "dfcsa = pd.DataFrame(ShapeFileInput)\n",
    "dfcsa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input File - StreamGageGetStationList.csv\n",
    "# fileInput = \"UDWRe_CulinaryWaterServiceAreas_input.csv\"\n",
    "# dfcsa = pd.read_csv(fileInput)\n",
    "\n",
    "# # WaDE UUID tracker for data assessment\n",
    "# if 'WaDEUUID' not in dfcsa:\n",
    "#     dfcsa['WaDEUUID'] = \"utcsa\" + dfcsa.index.astype(str)\n",
    "#     dfcsa.to_csv('UDWRe_CulinaryWaterServiceAreas_input.csv', index=False)\n",
    "\n",
    "# print(len(dfcsa))\n",
    "# dfcsa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataframe for Culinary Service Area Data\n",
    "\n",
    "dfcsa_Out = pd.DataFrame(index=dfcsa.index)\n",
    "dfcsa_Out['linkKey'] = dfcsa['WRID']\n",
    "\n",
    "# Site Info\n",
    "dfcsa_Out['in_CoordinateMethodCV'] = \"Centroid of Area\"\n",
    "dfcsa_Out['in_County'] = dfcsa['COUNTY']\n",
    "dfcsa_Out['in_Latitude'] = dfcsa['Latitude'].astype(float)\n",
    "dfcsa_Out['in_Longitude'] = dfcsa['Longitude'].astype(float)\n",
    "dfcsa_Out['in_PODorPOUSite'] = \"POU\"\n",
    "dfcsa_Out['in_SiteName'] = dfcsa['WRENAME']\n",
    "dfcsa_Out['in_SiteNativeID'] = \"POU\" + dfcsa['WRID'].astype(str)\n",
    "dfcsa_Out['in_SiteTypeCV'] = \"Unspecified\"\n",
    "\n",
    "dfcsa_Out = dfcsa_Out.replace(np.nan, \"\").drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfcsa_Out))\n",
    "dfcsa_Out.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge site data to System_Per Use data\n",
    "dfsyspuOut = pd.merge(dfsyspuOut, dfcsa_Out, on='linkKey', how='left')\n",
    "dfsyspuOut = dfsyspuOut.replace(np.nan, \"\").drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfsyspuOut))\n",
    "dfsyspuOut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge site data to System_Total data\n",
    "dfsystOut = pd.merge(dfsystOut, dfcsa_Out, on='linkKey', how='left')\n",
    "dfsystOut = dfsystOut.replace(np.nan, \"\").drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfsystOut))\n",
    "dfsystOut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all System Data into one long dataframe.\n",
    "frames = [dfsyspuOut, dfsystOut]\n",
    "dfsysOut = pd.concat(frames)\n",
    "\n",
    "dfsysOut = dfsysOut.replace(np.nan, \"\").drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfsysOut))\n",
    "dfsysOut.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDWRi Source (POD) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UDWRi_SourceData_Monthly_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - UDWRi_SourceData_Monthly_input.csv\n",
    "fileInput = \"UDWRi_SourceData_Monthly_input.csv\"\n",
    "dfsourm = pd.read_csv(fileInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfsourm:\n",
    "    dfsourm['WaDEUUID'] = \"utsourm\" + dfsourm.index.astype(str)\n",
    "    dfsourm.to_csv('UDWRi_SourceData_Monthly_input.csv', index=False)\n",
    "\n",
    "print(len(dfsourm))\n",
    "dfsourm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up input data\n",
    "# ---------------------------\n",
    "\n",
    "#active recods only\n",
    "dfsourm = dfsourm[dfsourm['Source Status'] == \"Active\"]\n",
    "\n",
    "# drop rows with a null Year value\n",
    "dfsourm = dfsourm.dropna(subset=['Year'])\n",
    "\n",
    "# Adjust data type of fields\n",
    "dfsourm['Year'] = dfsourm['Year'].astype(int)\n",
    "\n",
    "print(len(dfsourm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop data list.  Use this to search for specific fields.\n",
    "variableTypeList = ['Withdrawal', 'Transfer In', 'Transfer Out', 'Delivery', 'Return']\n",
    "\n",
    "useTypeList = ['Industrial', 'Irrigation', 'Domestic', 'Commercial', 'Geothermal', 'Agricultural', 'Mining', \n",
    "               'Power (Fossil-Fuel)', 'Power (Geothermal)', 'Power (Hydro-Elec)', 'Sewage Treatment', 'Water Supplier']\n",
    "\n",
    "monthUseList = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "startDateList = [\"01/01/\", \"02/01/\", \"03/01/\", \"04/01/\", \"05/01/\", \"06/01/\", \"07/01/\", \"08/01/\", \"09/01/\", \"10/01/\", \"11/01/\", \"12/01/\"]\n",
    "endDateList = [\"01/31/\", \"02/28/\", \"03/31/\", \"04/30/\", \"05/31/\", \"06/30/\", \"07/31/\", \"08/31/\", \"09/30/\", \"10/31/\", \"11/30/\", \"12/31/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time series data\n",
    "\n",
    "# the output dataframe\n",
    "dfsourm_Out = pd.DataFrame()\n",
    "\n",
    "# for each value in variableTypeList\n",
    "for x in variableTypeList:\n",
    "    \n",
    "    # trim down input data to match variable Type\n",
    "    variableTypeStr = str(x)\n",
    "    print(variableTypeStr) \n",
    "    dfsourm2 = dfsourm.copy()\n",
    "    dfsourm2 = dfsourm2[dfsourm2['Diversion Type'] == variableTypeStr].reset_index(drop=True)\n",
    "    print(f\"length of dfsour2 \", variableTypeStr, \" is \", len(dfsourm2))\n",
    "          \n",
    "    # for each value in useTypeList\n",
    "    for y in useTypeList:\n",
    "        \n",
    "        # trim down input data to match Use Type\n",
    "        useTypeString = str(y)\n",
    "        print(f\"..\", useTypeString)\n",
    "        dfsourm3 = dfsourm2.copy()\n",
    "        dfsourm3 = dfsourm3[dfsourm3['Use Type'] == useTypeString].reset_index(drop=True)\n",
    "        print(f\"..length of df \", useTypeString, \" is \", len(dfsourm3))\n",
    "    \n",
    "        # Create Output for that Use Type\n",
    "        dftemp2 = pd.DataFrame(index=dfsourm3.index)\n",
    "    \n",
    "        # Variable Info\n",
    "        dftemp2['in_VariableCV'] = dfsourm3['Diversion Type'].astype(str)\n",
    "        dftemp2['in_VariableSpecificCV'] = dfsourm3['Diversion Type'].astype(str) + \"_Monthly_\" + useTypeString\n",
    "        \n",
    "        # SiteVariableAmounts_fact Info\n",
    "        dftemp2['in_PopulationServed'] = \"\"\n",
    "        dftemp2['in_BenUse'] = dfsourm3['Use Type']\n",
    "#         dftemp2['in_CustomerTypeCV'] = dfsourm3['Use Type']\n",
    "        dftemp2['in_ReportYearCV'] = dfsourm3['Year']\n",
    "    \n",
    "        # Water Source Info\n",
    "        dftemp2['in_WaterSourceTypeCV'] = dfsourm3['Source Type']\n",
    "    \n",
    "        # Site Info\n",
    "        dftemp2['in_CoordinateMethodCV'] = \"Representation Node\"\n",
    "        dftemp2['in_Latitude'] = dfsourm3['Lat NAD83'].astype(float)\n",
    "        dftemp2['in_Longitude'] = dfsourm3['Lon NAD83'].astype(float)\n",
    "        dftemp2['in_PODorPOUSite'] = \"POD\"\n",
    "        dftemp2['in_SiteName'] = dfsourm3['Source Name']\n",
    "        dftemp2['in_SiteNativeID'] = \"POD\" + dfsourm3['Source ID'].astype(str)\n",
    "        dftemp2['in_SiteTypeCV'] = dfsourm3['Source Type']\n",
    "        \n",
    "        # link to other sites\n",
    "        dftemp2['linkKey'] = dfsourm3['System ID']\n",
    "        \n",
    "        # for each value in monthUseList\n",
    "        for z in range(len(monthUseList)):\n",
    "            monthUseString = str(monthUseList[z])\n",
    "            startDateString = str(startDateList[z])\n",
    "            endDateString = str(endDateList[z])\n",
    "            dftemp3 = dftemp2.copy()\n",
    "            dftemp3['monthCheck'] = monthUseString\n",
    "            dftemp3['in_Amount'] = dfsourm3[monthUseList[z]] # insert column name here\n",
    "            dftemp3['in_TimeframeStart'] = startDateString + dfsourm3['Year'].astype(str)\n",
    "            dftemp3['in_TimeframeEnd'] = endDateString + dfsourm3['Year'].astype(str)\n",
    "            dfsourm_Out = pd.concat([dfsourm_Out, dftemp3])\n",
    "\n",
    "print(len(dfsourm_Out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UDWRi_SourceData_Annual_no0Null_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - UDWRi_SourceData_Annual_no0Null_input.csv\n",
    "fileInput = \"UDWRi_SourceData_Annual_no0Null_input.csv\"\n",
    "dfsoura = pd.read_csv(fileInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfsoura:\n",
    "    dfsoura['WaDEUUID'] = \"utsoura\" + dfsoura.index.astype(str)\n",
    "    dfsoura.to_csv('UDWRi_SourceData_Annual_no0Null_input.csv', index=False)\n",
    "\n",
    "print(len(dfsoura))\n",
    "dfsoura.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up input data\n",
    "# ---------------------------\n",
    "\n",
    "#active recods only\n",
    "dfsoura = dfsoura[dfsoura['Source Status'] == \"Active\"]\n",
    "\n",
    "# drop rows with a null Year value\n",
    "dfsoura = dfsoura.dropna(subset=['Year'])\n",
    "\n",
    "# Adjust data type of fields\n",
    "dfsoura['Year'] = dfsoura['Year'].astype(int)\n",
    "\n",
    "print(len(dfsoura))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop data list.  Use this to search for specific fields.\n",
    "variableTypeList = ['Withdrawal', 'Transfer In', 'Transfer Out', 'Delivery', 'Return']\n",
    "\n",
    "useTypeList = ['Industrial', 'Irrigation', 'Domestic', 'Commercial', 'Geothermal', 'Agricultural', 'Mining', \n",
    "               'Power (Fossil-Fuel)', 'Power (Geothermal)', 'Power (Hydro-Elec)', 'Sewage Treatment', 'Water Supplier']\n",
    "\n",
    "monthUseList = ['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time series data\n",
    "\n",
    "# the output dataframe\n",
    "dfsoura_Out = pd.DataFrame()\n",
    "\n",
    "# for each value in variableTypeList\n",
    "for x in variableTypeList:\n",
    "    \n",
    "    # trim down input data to match variable Type\n",
    "    variableTypeStr = str(x)\n",
    "    print(variableTypeStr) \n",
    "    dfsoura2 = dfsoura.copy()\n",
    "    dfsoura2 = dfsoura2[dfsoura2['Diversion Type'] == variableTypeStr].reset_index(drop=True)\n",
    "    print(f\"length of dfsour2 \", variableTypeStr, \" is \", len(dfsoura2))\n",
    "          \n",
    "    # for each value in useTypeList\n",
    "    for y in useTypeList:\n",
    "        \n",
    "        # trim down input data to match Use Type\n",
    "        useTypeString = str(y)\n",
    "        print(f\"..\", useTypeString)\n",
    "        dfsoura3 = dfsoura2.copy()\n",
    "        dfsoura3 = dfsoura3[dfsoura3['Use Type'] == useTypeString].reset_index(drop=True)\n",
    "        print(f\"..length of df \", useTypeString, \" is \", len(dfsoura3))\n",
    "    \n",
    "        # Create Output for that Use Type\n",
    "        dftemp2 = pd.DataFrame(index=dfsoura3.index)\n",
    "    \n",
    "        # Variable Info\n",
    "        dftemp2['in_VariableCV'] = dfsoura3['Diversion Type'].astype(str)\n",
    "        dftemp2['in_VariableSpecificCV'] = dfsoura3['Diversion Type'].astype(str) + \"_Annual_\" + useTypeString\n",
    "        \n",
    "        # SiteVariableAmounts_fact Info\n",
    "        dftemp2['in_PopulationServed'] = \"\"\n",
    "        dftemp2['in_BenUse'] = dfsoura3['Use Type']\n",
    "#         dftemp2['in_CustomerTypeCV'] = dfsoura3['Use Type']\n",
    "        dftemp2['in_ReportYearCV'] = dfsoura3['Year']\n",
    "    \n",
    "        # Water Source Info\n",
    "        dftemp2['in_WaterSourceTypeCV'] = dfsoura3['Source Type']\n",
    "    \n",
    "        # Site Info\n",
    "        dftemp2['in_CoordinateMethodCV'] = \"Representation Node\"\n",
    "        dftemp2['in_Latitude'] = dfsoura3['Lat NAD83'].astype(float)\n",
    "        dftemp2['in_Longitude'] = dfsoura3['Lon NAD83'].astype(float)\n",
    "        dftemp2['in_PODorPOUSite'] = \"POD\"\n",
    "        dftemp2['in_SiteName'] = dfsoura3['Source Name']\n",
    "        dftemp2['in_SiteNativeID'] = \"POD\" + dfsoura3['Source ID'].astype(str)\n",
    "        dftemp2['in_SiteTypeCV'] = dfsoura3['Source Type']\n",
    "        \n",
    "        # link to other sites\n",
    "        dftemp2['linkKey'] = dfsoura3['System ID']\n",
    "        \n",
    "        # for each value in monthUseList\n",
    "        for z in range(len(monthUseList)):\n",
    "            monthUseString = str(monthUseList[z])\n",
    "            startDateString = str(startDateList[z])\n",
    "            endDateString = str(endDateList[z])\n",
    "            dftemp3 = dftemp2.copy()\n",
    "            dftemp3['monthCheck'] = monthUseString\n",
    "            dftemp3['in_Amount'] = dfsoura3[monthUseList[z]] # insert column name here\n",
    "            dftemp3['in_TimeframeEnd'] = '12/31/' + dfsoura3['Year'].astype(str)\n",
    "            dftemp3['in_TimeframeStart'] = '01/01/' + dfsoura3['Year'].astype(str)\n",
    "            dfsoura_Out = pd.concat([dfsoura_Out, dftemp3])\n",
    "\n",
    "print(len(dfsoura_Out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all Source Data into one long dataframe.\n",
    "frames = [dfsourm_Out, dfsoura_Out]\n",
    "dfsour_Out = pd.concat(frames)\n",
    "\n",
    "dfsour_Out = dfsour_Out.replace(np.nan, \"\").drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfsour_Out))\n",
    "dfsour_Out.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate System Data (POUs) with Source Data (PODs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Source Data into one long dataframe.\n",
    "frames = [dfsysOut, dfsour_Out]\n",
    "dfout = pd.concat(frames)\n",
    "\n",
    "dfout = dfout.replace(np.nan, \"\").drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfout))\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix blank / null WaterSourcetypeCV\n",
    "# simplify to WaDE specific categories\n",
    "\n",
    "wsTypeDict = {\n",
    "    \"Well\" : \"Groundwater\",\n",
    "    \"Well/Spring\" : \"Groundwater\",\n",
    "    \"Well Field\" : \"Groundwater\",\n",
    "    \"Well/Stream\" : \"Groundwater\",\n",
    "    \"Tunnel\" : \"Groundwater\",\n",
    "    \"Drain\" : \"Groundwater\",\n",
    "    \"Stream\" : \"Surface Water\",\n",
    "    \"Spring\" : \"Surface Water\",\n",
    "    \"Reservoir\" : \"Surface Water\",\n",
    "    \"Lake\" : \"Surface Water\"}\n",
    "\n",
    "def fixWaterSourceTypeCV(valA):\n",
    "    valA = str(valA).strip()\n",
    "    if valA == \"\" or pd.isnull(valA):\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        try:\n",
    "            outString = wsTypeDict[valA]\n",
    "        except:\n",
    "            outString = \"Unspecified\"\n",
    "    return outString\n",
    "\n",
    "dfout['in_WaterSourceTypeCV'] = dfout.apply(lambda row: fixWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert History Year to string.\n",
    "\n",
    "dfout['in_TimeframeEnd'] = pd.to_datetime(dfout['in_TimeframeEnd'], errors = 'coerce')\n",
    "dfout['in_TimeframeEnd'] = pd.to_datetime(dfout[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout['in_TimeframeStart'] = pd.to_datetime(dfout['in_TimeframeStart'], errors = 'coerce')\n",
    "dfout['in_TimeframeStart'] = pd.to_datetime(dfout[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting in_PopulationServed to int value.\n",
    "dfout['in_PopulationServed'] = dfout['in_PopulationServed'].replace(np.nan, 0, regex=True)\n",
    "dfout['in_PopulationServed'] = dfout['in_PopulationServed'].replace('', 0, regex=True)\n",
    "dfout['in_PopulationServed'] = dfout['in_PopulationServed'].astype(int)\n",
    "\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Latitude & Longitude to float values\n",
    "dfout['in_Latitude'] = dfout['in_Latitude'].replace(np.nan, 0, regex=True)\n",
    "dfout['in_Latitude'] = dfout['in_Latitude'].replace('', 0, regex=True)\n",
    "dfout['in_Latitude'] = dfout['in_Latitude'].astype(float)\n",
    "\n",
    "dfout['in_Longitude'] = dfout['in_Longitude'].replace(np.nan, 0, regex=True)\n",
    "dfout['in_Longitude'] = dfout['in_Longitude'].replace('', 0, regex=True)\n",
    "dfout['in_Longitude'] = dfout['in_Longitude'].astype(float)\n",
    "\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting in_Amount to float values\n",
    "# issue of some values are strings.\n",
    "dfout['in_Amount'] = dfout['in_Amount'].replace('-','', regex=True)\n",
    "dfout['in_Amount'] = dfout['in_Amount'].replace(',','', regex=True)\n",
    "dfout['in_Amount'] = dfout['in_Amount'].replace('FALSE','', regex=True)\n",
    "dfout['in_Amount'] = dfout['in_Amount'].str.strip()\n",
    "dfout['in_Amount'] = pd.to_numeric(dfout['in_Amount'])\n",
    "\n",
    "dfout['in_Amount'] = dfout['in_Amount'].astype(float)\n",
    "\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinPOD['nativeID'] = dfinPOD['AquiferCod'].str.split('-')[0]\n",
    "dfinPOD['name'] = dfinPOD['AquiferCod'].str.split('-')[1] (edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNativeIDFunc(A):\n",
    "    A = str(A).strip()\n",
    "    try:\n",
    "        outString = A.str.split('-')[0]\n",
    "    except:\n",
    "        outString = A\n",
    "    return outString\n",
    "\n",
    "dfinPOD['nativeID'] = dfinPOD.apply(lambda row: extractNativeIDFunc(row['AquiferCod']), axis=1)\n",
    "dfinPOD['nativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updaing VariableSpecificCV to include a water source type\n",
    "\n",
    "def updateVariableSpecificCV(valA, valB):\n",
    "    valA = str(valA).strip()\n",
    "    valB = str(valB).strip()       \n",
    "    outString = valA + \"_\" + valB\n",
    "    return outString\n",
    "\n",
    "dfout['in_VariableSpecificCV'] = dfout.apply(lambda row: updateVariableSpecificCV(row['in_VariableSpecificCV'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDEUT_WS\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = dfout['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    if (A == '') or (pd.isnull(A)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceTypeCV'] == A), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfout['in_WaterSourceNativeID'] = dfout.apply(lambda row: retrieveWaterSourceNativeID(row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching gemetry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "ShapeFileInput = gpd.read_file('shapefile/CulinaryWaterServiceAreas.shp')\n",
    "dfPoUshapetemp = pd.DataFrame(ShapeFileInput)\n",
    "dfPoUshapetemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp['WRID'].astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check datatype\n",
    "print(len(dfout))\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dfout.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting output files.\n",
    "dfout.to_csv('P_MasterUTSiteSpecific.csv', index=False)  # The output.\n",
    "dfPoUshape.to_csv('P_utSSGeometry.csv', index=False) # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
