{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Texas Commission on Environmental Quality for Site-Specific Division & Withdrawl Site data for WaDE upload\n",
    "- Purpose:  To pre-process the data into one main file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working Directory is: G:/Shared drives/WaDE Data/Texas/WaterAllocation_WaterUse_TCEQ\n"
     ]
    }
   ],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"G:/Shared drives/WaDE Data/Texas/WaterAllocation_WaterUse_TCEQ\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input 1 - timeseries WaterUse\n",
    "- clean up ben use values\n",
    "- explode / separate out non-timeseries info & re-attach timseries info with specific month value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Water Right ID</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Use</th>\n",
       "      <th>Year</th>\n",
       "      <th>JAN_DIV</th>\n",
       "      <th>FEB_DIV</th>\n",
       "      <th>MAR_DIV</th>\n",
       "      <th>APR_DIV</th>\n",
       "      <th>MAY_DIV</th>\n",
       "      <th>JUN_DIV</th>\n",
       "      <th>JUL_DIV</th>\n",
       "      <th>AUG_DIV</th>\n",
       "      <th>SEPT_DIV</th>\n",
       "      <th>OCT_DIV</th>\n",
       "      <th>NOV_DIV</th>\n",
       "      <th>DEC_DIV</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>WaDEUUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60750362</td>\n",
       "      <td>C1009</td>\n",
       "      <td>LUMINANT GENERATION COMPANY LLC</td>\n",
       "      <td>INDUSTRIAL</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>171.00000</td>\n",
       "      <td>in10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID Water Right ID                            Owner         Use  Year  \\\n",
       "0  60750362          C1009  LUMINANT GENERATION COMPANY LLC  INDUSTRIAL  2018   \n",
       "\n",
       "   JAN_DIV  FEB_DIV  MAR_DIV  APR_DIV  MAY_DIV  JUN_DIV  JUL_DIV  AUG_DIV  \\\n",
       "0  0.00000  5.00000 20.00000 28.00000 20.00000 14.00000 22.00000 18.00000   \n",
       "\n",
       "   SEPT_DIV  OCT_DIV  NOV_DIV  DEC_DIV     TOTAL WaDEUUID  \n",
       "0   9.00000  7.00000 17.00000 11.00000 171.00000     in10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input File - WaterUse\n",
    "fileInput = \"RawInputData/WaterUse.zip\"\n",
    "dfin1 = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin1:\n",
    "    dfin1['WaDEUUID'] = \"in1\" + dfin1.index.astype(str)\n",
    "    dfin1.to_csv(\"RawInputData/WaterUse.zip\", compression=dict(method='zip', archive_name='WaterUse.csv'), index=False)\n",
    "\n",
    "print(len(dfin1))\n",
    "dfin1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean ben use info\n",
    "# replace \"&\" with \",\", remove white space\n",
    "dfin1['Use'] = dfin1['Use'].str.strip().str.replace(\"  \", \" \").str.title()\n",
    "dfin1['Use'] = dfin1['Use'].str.replace(\" And \", \", \").str.strip()\n",
    "dfin1['Use'] = dfin1['Use'].str.replace(\". \", \", \").str.strip()\n",
    "\n",
    "def fixBenUse(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"Domestic And Livestock\":\n",
    "        outString = \"Domestic, Livestock\"\n",
    "    elif val == \"Domestic And Livestock & Livestock\":\n",
    "        outString = \"Domestic, Livestock\"\n",
    "    elif val == \"Non-Consumptive\":\n",
    "        outString = \"Non Consumptive\"\n",
    "    elif val == \"Instraem\":\n",
    "        outString = \"Instream\"\n",
    "    elif val == \"Wilflife Management\":\n",
    "        outString = \"Wildlife Management\"\n",
    "    elif val == \"Watwe Quality\":\n",
    "        outString = \"Water Quality\"\n",
    "    elif val == \"Minng\":\n",
    "        outString = \"Mining\"\n",
    "    elif val == \"Muncipal\":\n",
    "        outString = \"Municipal\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString\n",
    "\n",
    "dfin1['Use'] = dfin1.apply(lambda row: fixBenUse(row['Use']), axis=1)\n",
    "for x in dfin1['Use'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp dataframe of non-timseries info\n",
    "dfin1_b = dfin1[[\"OBJECTID\", \"Water Right ID\", \"Owner\", \"Use\", \"Year\"]]\n",
    "print(len(dfin1_b))\n",
    "dfin1_b.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract timeseries data / month values, attach to non-timseries info\n",
    "\n",
    "divColList = [\"JAN_DIV\", \"FEB_DIV\", \"MAR_DIV\", \"APR_DIV\", \"MAY_DIV\", \"JUN_DIV\", \"JUL_DIV\", \n",
    "              \"AUG_DIV\", \"SEPT_DIV\", \"OCT_DIV\", \"NOV_DIV\", \"DEC_DIV\"] # list of column names with Amount values\n",
    "monthNumList = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"] # list of month num values\n",
    "lastDayMonNumLisdt = [\"31\", \"28\", \"31\", \"30\", \"31\", \"30\", \"31\", \"31\", \"30\", \"31\", \"30\", \"31\"]\n",
    "dfin1_c =pd.DataFrame() # empty dataframe\n",
    "\n",
    "for x in range(11):\n",
    "    # divColName = \n",
    "    # divMonthNumVal = \n",
    "    # divLastDayMontNumVal = \n",
    "    \n",
    "    dftemp = dfin1_b.copy()\n",
    "    dftemp['in_Amount'] = dfin1[divColList[x]]\n",
    "    dftemp['in_TimeframeEnd'] = monthNumList[x] + \"/\" + lastDayMonNumLisdt[x] + \"/\" + dftemp['Year'].astype(str)\n",
    "    dftemp['in_TimeframeStart'] = monthNumList[x] + \"/\" + \"01\" + \"/\" + dftemp['Year'].astype(str)\n",
    "    \n",
    "    dfin1_c = pd.concat([dfin1_c, dftemp])\n",
    "\n",
    "print(len(dfin1_c))\n",
    "dfin1_c.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input 2 - owner info\n",
    "- remove special characters\n",
    "- group by \"Water Right ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>WaterRightID</th>\n",
       "      <th>Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17294228</td>\n",
       "      <td>C925</td>\n",
       "      <td>SOZA, JOSE JR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID WaterRightID          Owner\n",
       "0  17294228         C925  SOZA, JOSE JR"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe creation - owners\n",
    "ownerInput = \"RawinputData/WaterRightOwner.zip\"\n",
    "dfowner = pd.read_csv(ownerInput).replace(np.nan, \"\")\n",
    "dfowner = dfowner.rename(columns={\"Water Right ID\": \"WaterRightID\"})\n",
    "\n",
    "print(len(dfowner))\n",
    "dfowner.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Owner info.  Remove special characters. Change to title format.\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = str(Val).strip()\n",
    "    Val = re.sub(\"[$'\\\"'@&.;,/\\)(-]\", \"\", Val).title().strip()\n",
    "    return Val\n",
    "\n",
    "dfowner['Owner'] = dfowner.apply(lambda row: cleanOwnerDataFunc(row['Owner']), axis=1)\n",
    "for x in dfowner['Owner'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group owner info by WR_ID\n",
    "dfowner = dfowner.drop(['OBJECTID'], axis=1) # drop unused 'OBJECTID' columns\n",
    "dfowner = dfowner.groupby('WaterRightID').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem != \"\"])).replace(np.nan, \"\").reset_index()\n",
    "print(len(dfowner))\n",
    "dfowner.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input 3 - WaterRightsAsSinglePoints\n",
    "- clean up Type\n",
    "- attach owner info to sites\n",
    "- merge site/owner info to ben use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>TCEQ ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location Method</th>\n",
       "      <th>Location Accuracy</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Location Date</th>\n",
       "      <th>Location Organization</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Water Right ID</th>\n",
       "      <th>Water Right Type and Number</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>WaDEUUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14591275</td>\n",
       "      <td>10503942001</td>\n",
       "      <td>Diversion Point</td>\n",
       "      <td>2</td>\n",
       "      <td>32.79544</td>\n",
       "      <td>-95.20610</td>\n",
       "      <td>DRG</td>\n",
       "      <td>12</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>8/25/2008</td>\n",
       "      <td>TCEQ</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>P3942</td>\n",
       "      <td>WRPERM3942</td>\n",
       "      <td>Point</td>\n",
       "      <td>in30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID      TCEQ ID             Type  Verified  Latitude  Longitude  \\\n",
       "0  14591275  10503942001  Diversion Point         2  32.79544  -95.20610   \n",
       "\n",
       "  Location Method  Location Accuracy Reference Location Date  \\\n",
       "0             DRG                 12     OTHER     8/25/2008   \n",
       "\n",
       "  Location Organization  Datum Water Right ID Water Right Type and Number  \\\n",
       "0                  TCEQ  NAD83          P3942                  WRPERM3942   \n",
       "\n",
       "   SHAPE WaDEUUID  \n",
       "0  Point     in30  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input File\n",
    "fileInput = \"RawinputData/WaterRightsAsSinglePoints.zip\"\n",
    "dfinPOD = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOD:\n",
    "    dfinPOD['WaDEUUID'] = \"in3\" + dfinPOD.index.astype(str)\n",
    "    dfinPOD.to_csv('RawinputData/WaterRightsAsSinglePoints.zip', compression=dict(method='zip', archive_name='WaterRightsAsSinglePoints.csv'), index=False)\n",
    "\n",
    "print(len(dfinPOD))\n",
    "dfinPOD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean TYPE info\n",
    "dfinPOD['Type'] = dfinPOD['Type'].str.strip().str.replace(\"  \", \" \")\n",
    "\n",
    "def fixTypeFunc(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"On-channel Reservior\":\n",
    "        outString = \"On-channel Reservoir\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString\n",
    "\n",
    "dfinPOD['Type'] = dfinPOD.apply(lambda row: fixTypeFunc(row['Type']), axis=1)   \n",
    "for x in dfinPOD['Type'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach owner info to Site info\n",
    "\n",
    "# Loop up dictonary using owner dataframe\n",
    "OwnerDict = pd.Series(dfowner.Owner.values, index=dfowner.WaterRightID).to_dict()\n",
    "\n",
    "def retrieveOwner(val):\n",
    "    if val == \"\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        String1 = str(val).strip()\n",
    "        try:\n",
    "            outString = OwnerDict[String1]\n",
    "        except:\n",
    "            outString = \"\"\n",
    "    return outString\n",
    "\n",
    "dfinPOD['in_AllocationOwner'] = dfinPOD.apply(lambda row: retrieveOwner(row['Water Right ID']), axis=1)\n",
    "dfinPOD['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge site/owner info to ben use\n",
    "\n",
    "dfin1_c = dfin1_c.merge(dfinPOD, how='left', left_on='Water Right ID', right_on='Water Right ID')\n",
    "print(len(dfin1_c))\n",
    "dfin1_c.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfin1_c['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"TCEQwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"TCEQwr_V1\" # for wr records portion only\n",
    "df['in_AggregationIntervalUnitCV'] = \"Monthly\"\n",
    "df['in_VariableCV'] = \"Water Use\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"TCEQwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"WaDE Blank\" # need this for auto fill below\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "df['in_WaterSourceTypeCV'] = \"Surface Water\" # need this for auto fill below\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfin1_c['Latitude']\n",
    "df['in_Longitude'] = dfin1_c['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"wade\" + dfin1_c['OBJECTID_y'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = dfin1_c['Type']\n",
    "df['in_StateCV'] = \"TX\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = \"\" #empty\n",
    "df['in_AllocationLegalStatusCV'] = \"\"\n",
    "df['in_AllocationNativeID'] =  dfin1_c['Water Right ID']\n",
    "df['in_AllocationOwner'] = dfin1_c['in_AllocationOwner']\n",
    "df['in_AllocationPriorityDate'] = \"\" #empty\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = \"\" #empty\n",
    "df['in_BeneficialUseCategory'] = dfin1_c['Use']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 1 # we want this data excempt\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "#df['in_WaterAllocationNativeURL'] = \"https://gisweb.tceq.texas.gov/WRRetrieveRights/?ID=\" + dfin1_c['Water Right ID'].replace(\"\", 0).fillna(0).str.strip().astype(str)\n",
    "df['in_WaterAllocationNativeURL'] = \"https://gisweb.tceq.texas.gov/WRRetrieveRights/?ID=\" + dfin1_c['Water Right Type and Number'].replace(\"\", 0).fillna(0).str.strip().astype(str)\n",
    "\n",
    "\n",
    "# Site VariableAmounts Info\n",
    "df['in_Amount'] = dfin1_c['in_Amount']\n",
    "df['in_AssociatedNativeAllocationIDs'] = dfin1_c['Water Right ID']\n",
    "df['in_PowerGeneratedGWh'] = \"\"\n",
    "df['in_PrimaryUseCategory'] = \"\"\n",
    "df['in_ReportYearCV'] = dfin1_c['Year']\n",
    "df['in_SDWISIdentifier'] = \"\"\n",
    "df['in_TimeframeEnd'] = dfin1_c['in_TimeframeEnd']\n",
    "df['in_TimeframeStart'] = dfin1_c['in_TimeframeStart']\n",
    "# df['in_AllocationCropDutyAmount'] = \"\" see above AllocationAmount Info\n",
    "# df['in_BeneficialUseCategory'] = \"\" see above AllocationAmount Info\n",
    "# df['in_CommunityWaterSupplySystem'] = \"\" see above AllocationAmount Info\n",
    "# df['in_CropTypeCV'] = \"\" see above AllocationAmount Info\n",
    "# df['in_CustomerTypeCV'] = \"\" see above AllocationAmount Info\n",
    "# df['in_DataPublicationDate'] = \"\" see above AllocationAmount Info\n",
    "# df['in_DataPublicationDOI'] = \"\" see above AllocationAmount Info\n",
    "# df['in_Geometry'] = \"\" see above Site Info\n",
    "# df['in_IrrigatedAcreage'] = \"\" see above AllocationAmount Info\n",
    "# df['in_IrrigationMethodCV'] = \"\" see above AllocationAmount Info\n",
    "# df['in_PopulationServed'] = \"\" see above AllocationAmount Info\n",
    "# df['in_PowerType'] = \"\" see above AllocationAmount Info\n",
    "# df['in_SDWISIdentifier'] = \"\" see above AllocationAmount Info\n",
    "\n",
    "outdf1 = df.copy()\n",
    "outdf1 = outdf1.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdf1))\n",
    "outdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input 2\n",
    "- site info\n",
    "- timeseries info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc etc,\n",
    "# outdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate DataFrames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outdf1] # list all out dataframes here\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # updating in_WaterSourceTypeCV to be more machine readable / WaDE specific\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def createWaterSourceTypeCV(inWST):\n",
    "#     inWST = str(inWST).strip()\n",
    "    \n",
    "#     if inWST == \"\":\n",
    "#         outString = \"WaDE Blank\"\n",
    "#     elif inWST == \"Ground Water\":\n",
    "#         outString = \"Groundwater\"\n",
    "#     else:\n",
    "#         outString =  inWST\n",
    "      \n",
    "#     return outString\n",
    "\n",
    "# outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: createWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "# outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean name entries of spcial characters\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;/\\),(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: ensureEmptyString(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Latitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Longitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Amount entry is either numireic or blank, no 0 entries\n",
    "outdf['in_Amount'] = pd.to_numeric(outdf['in_Amount'], errors='coerce').round(2).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure PopulationServed entry is numireic WITH 0 entries (no blank strings)\n",
    "outdf['in_PopulationServed'] = pd.to_numeric(outdf['in_PopulationServed'], errors='coerce').round().replace(\"\",0).fillna(0).astype(int).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_PopulationServed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'])\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeEnd to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf['in_TimeframeEnd'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeEnd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeStart to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf['in_TimeframeStart'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeStart'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year out\n",
    "# outdf['in_ReportYearCV'] = pd.to_datetime(outdf['in_ReportYearCV'], utc=True)\n",
    "# outdf['in_ReportYearCV'] = pd.to_datetime(outdf[\"in_ReportYearCV\"].dt.strftime('%m/%d/%Y'))\n",
    "# outdf['in_ReportYearCV'] = outdf['in_ReportYearCV'].dt.year\n",
    "outdf['in_ReportYearCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Primary Use Category\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/rjame/Documents/WSWC Documents/MappingStatesDataToWaDE2.0/5_CustomFunctions/AssignPrimaryUseCategory\")\n",
    "import AssignPrimaryUseCategoryFile # Use Custom import file\n",
    "\n",
    "outdf['in_PrimaryUseCategory'] = outdf.apply(lambda row: AssignPrimaryUseCategoryFile.retrievePrimaryUseCategory(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_PrimaryUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom VariableSpecificCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "def createVariableSpecificCV(inV, inAIU, inPU, inWST):\n",
    "    inV = str(inV).strip()\n",
    "    inAIU = str(inAIU).strip()\n",
    "    inPU = str(inPU).strip().title()\n",
    "    inWST = str(inWST).strip()\n",
    "    outString = inV + \"_\" + inAIU + \"_\" + inPU + \"_\" + inWST\n",
    "    return outString\n",
    "\n",
    "outdf['in_VariableSpecificCV'] = outdf.apply(lambda row: createVariableSpecificCV(row['in_VariableCV'], \n",
    "                                                                                  row['in_AggregationIntervalUnitCV'],\n",
    "                                                                                  row['in_PrimaryUseCategory'],\n",
    "                                                                                  row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# use unique WaterSourceName and WaterSourceType values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_WaterSourceNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_WaterSourceName'] = outdf['in_WaterSourceName'].astype(str).str.strip()\n",
    "dfTempID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_WaterSourceNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_WaterSourceName'].astype(str) + dfTempID['in_WaterSourceTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_WaterSourceNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_WaterSourceNativeID'], \n",
    "                                                                              row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom site native ID for easy site identification\n",
    "# use Unique Latitude, Longitude, SiteName and SiteTypeCV values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_SiteNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_Latitude'] = outdf['in_Latitude'].astype(str).str.strip()\n",
    "dfTempID['in_Longitude'] = outdf['in_Longitude'].astype(str).str.strip()\n",
    "dfTempID['in_SiteName'] = outdf['in_SiteName'].astype(str).str.strip()\n",
    "dfTempID['in_SiteTypeCV'] = outdf['in_SiteTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_SiteNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_Latitude'].astype(str) + dfTempID['in_Longitude'].astype(str) + dfTempID['in_SiteName'].astype(str)+ dfTempID['in_SiteTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_SiteNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB, valC, valD):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip() + str(valC).strip() + str(valD).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_SiteNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_SiteNativeID'], \n",
    "                                                                       row['in_Latitude'], row['in_Longitude'],\n",
    "                                                                       row['in_SiteName'], row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('RawInputData/Pssdw_Main.zip', compression=dict(method='zip', archive_name='Pssdw_Main.csv'), index=False)  # The output, save as a zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = outdf.copy()\n",
    "# df['in_Amount'] = df['in_Amount'].astype(str).astype(float)\n",
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df[df.groupby(['in_AssociatedNativeAllocationIDs', 'in_VariableSpecificCV', 'in_ReportYearCV'])['in_Amount'].sum().reset_index() > 0]\n",
    "# printlen(filtered_df)\n",
    "# filtered_df.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
