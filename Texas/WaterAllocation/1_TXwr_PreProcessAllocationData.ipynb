{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Texas TCEQ Allocation data for WaDEQA upload.\n",
    "Date Updated: 03/28/2023\n",
    "Purpose:  To pre-process the Texas data into one master file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Texas/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Owner Name\n",
    "- create dictionary of owner names\n",
    "- will use a dictionary to assign owner name for output main file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe creation - owners\n",
    "ownerInput = \"WaterRightOwner.csv\"\n",
    "df_owner = pd.read_csv(ownerInput, usecols=['Water Right ID', 'Owner'], encoding=\"ISO-8859-1\")\n",
    "df_owner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Owner info.  Remove special characters\n",
    "\n",
    "import re\n",
    "\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).title().strip()\n",
    "    return Val\n",
    "\n",
    "df_owner['Owner'] = df_owner.apply(lambda row: cleanOwnerDataFunc(row['Owner']), axis=1)\n",
    "df_owner['Owner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge onwers, assign ID\n",
    "# Issue of multiple owners per water Right ID\n",
    "\n",
    "def retrieveNames(df):\n",
    "    ids = df['Water Right ID'].drop_duplicates()\n",
    "    outdf = pd.DataFrame(ids)\n",
    "    outdf.reset_index(drop=True, inplace=True)\n",
    "    outdf['owners'] = ''\n",
    "    outdf.set_index(outdf['Water Right ID'], inplace=True)\n",
    "\n",
    "    for id in ids:\n",
    "        vals = df.loc[df['Water Right ID'] == id]\n",
    "        vals.reset_index(inplace=True)\n",
    "        names = []\n",
    "        for i, row in vals.iterrows():\n",
    "            names.append(row['Owner'])\n",
    "\n",
    "        outdf.at[id, 'owners'] = ', '.join(names)\n",
    "\n",
    "    return outdf\n",
    "\n",
    "df_owners = retrieveNames(df_owner)\n",
    "df_owners['WaterRightID'] = df_owners['Water Right ID']\n",
    "df_owners.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Ben Use\n",
    "- create dictionary of ben use\n",
    "- will use a dictionary to assign ben use for output main file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe creation - ben use\n",
    "useInput = \"WaterUse.csv\"\n",
    "df_use = pd.read_csv(useInput, usecols=['Water Right ID', 'Use'])\n",
    "df_use['Use'] = df_use['Use'].str.title()\n",
    "df_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveUses(df):\n",
    "    ids = df['Water Right ID'].drop_duplicates()\n",
    "    outdf = pd.DataFrame(ids)\n",
    "    outdf.reset_index(drop=True, inplace=True)\n",
    "    outdf['uses'] = ''\n",
    "    outdf.set_index(outdf['Water Right ID'], inplace=True)\n",
    "\n",
    "    for id in ids:\n",
    "        vals = df.loc[df['Water Right ID'] == id]\n",
    "        vals.reset_index(inplace=True)\n",
    "        uses = []\n",
    "        for i, row in vals.iterrows():\n",
    "            new_use = row['Use']\n",
    "\n",
    "            if new_use not in uses:\n",
    "                uses.append(new_use)\n",
    "\n",
    "        outdf.at[id, 'uses'] = ','.join(uses)\n",
    "\n",
    "    return outdf\n",
    "\n",
    "df_uses = retrieveUses(df_use)\n",
    "df_uses['WaterRightID'] = df_uses['Water Right ID']\n",
    "df_uses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POD: Water Right Points and Output file\n",
    "- maint output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "fileInput = \"WaterRightPoint.csv\"\n",
    "dfinPOD = pd.read_csv(fileInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOD:\n",
    "    dfinPOD['WaDEUUID'] = \"txWR\" + dfinPOD.index.astype(str)\n",
    "    dfinPOD.to_csv('WaterRightPoint.zip', compression=dict(method='zip', archive_name='WaterRightPoint.csv'), index=False)\n",
    "\n",
    "print(len(dfinPOD))\n",
    "dfinPOD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assining owner name to output file\n",
    "\n",
    "# Loop up dictonary using owner dataframe\n",
    "OwnerDict = pd.Series(df_owners.owners.values, index=df_owners.WaterRightID).to_dict()\n",
    "\n",
    "def retrieveOwner(val):\n",
    "    if val == '' or pd.isnull(val):\n",
    "        outString = \"WaDE Unspecified\"\n",
    "    else:\n",
    "        String1 = str(val).strip()\n",
    "        try:\n",
    "            outString = OwnerDict[String1]\n",
    "        except:\n",
    "            outString = \"WaDE Unspecified\"\n",
    "    return outString\n",
    "\n",
    "dfinPOD['in_AllocationOwner'] = dfinPOD.apply(lambda row: retrieveOwner(row['WR_ID']), axis=1)\n",
    "dfinPOD['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assining ben use to output file\n",
    "\n",
    "# Loop up dictonary using ben use dataframe\n",
    "BenuseDict = pd.Series(df_uses.uses.values, index=df_uses.WaterRightID).to_dict()\n",
    "\n",
    "def retrieveBenUse(val):\n",
    "    if val == '' or pd.isnull(val):\n",
    "        outString = \"WaDE Unspecified\"\n",
    "    else:\n",
    "        String1 = str(val).strip()\n",
    "        try:\n",
    "            outString = BenuseDict[String1]\n",
    "        except:\n",
    "            outString = \"WaDE Unspecified\"\n",
    "    return outString\n",
    "\n",
    "dfinPOD['in_BeneficialUseCategory'] = dfinPOD.apply(lambda row: retrieveBenUse(row['WR_ID']), axis=1)\n",
    "dfinPOD['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tx projection = EPSG:4269.  WGS84 projection used by WaDE 2.0 = epsg:4326.\n",
    "\n",
    "from pyproj import Transformer, transform # for transforming coordinates to a new projection\n",
    "transformer = Transformer.from_proj(4269, 4326)  \n",
    "\n",
    "def assignLat(colrowValueLat, colrowValueLong):\n",
    "    lat, long = transformer.transform(colrowValueLat, colrowValueLong)\n",
    "    return lat\n",
    "\n",
    "def assignLong(colrowValueLat, colrowValueLong):\n",
    "    lat, long = transformer.transform(colrowValueLat, colrowValueLong)\n",
    "    return long\n",
    "\n",
    "\n",
    "\n",
    "dfinPOD['in_Latitude'] = dfinPOD.apply(lambda row: assignLat(row['LAT_DD'], row['LONG_DD']), axis=1)\n",
    "dfinPOD['in_Longitude'] = dfinPOD.apply(lambda row: assignLong(row['LAT_DD'], row['LONG_DD']), axis=1)\n",
    "dfinPOD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing Spelling issues in TCEQ TYPE field\n",
    "TYPEdict = {\n",
    "\"Dischrage Point\" : \"Discharge Point\",\n",
    "\"Dishcharge Point\" : \"Discharge Point\",\n",
    "\"IBT -  Diversion Point\" : \"IBT - Diversion Point\",\n",
    "\"On-channel  Reservoir\" : \"On-channel Reservoir\",\n",
    "\"On-channel Reservior\" : \"On-channel Reservoir\",\n",
    "\"GW -  Release Point\" : \"GW - Release Point\"\n",
    "}\n",
    "\n",
    "def updateTYPE(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = colrowValue\n",
    "    else:\n",
    "        String1 = colrowValue  # remove whitespace chars\n",
    "        try:\n",
    "            outList = TYPEdict[String1]\n",
    "        except:\n",
    "            outList = colrowValue\n",
    "    return outList\n",
    "\n",
    "dfinPOD['TYPE'] = dfinPOD.apply(lambda row: updateTYPE(row['TYPE']), axis=1)\n",
    "dfinPOD['TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOD['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"TXwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"TXwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"TXwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"WaDE Unspecified\"\n",
    "df['in_WaterSourceNativeID'] = \"\" # autfo fill in below\n",
    "df['in_WaterSourceTypeCV'] = \"WaDE Unspecified\"\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"WaDE Unspecified\"\n",
    "df['in_CoordinateMethodCV'] = \"Digitized\"\n",
    "df['in_County'] = \"WaDE Unspecified\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOD['in_Latitude']\n",
    "df['in_Longitude'] = dfinPOD['in_Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = \"WaDE Unspecified\"\n",
    "df['in_SiteNativeID'] = \"POD\" + dfinPOD['TCEQ_ID'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = dfinPOD['TYPE']\n",
    "df['in_StateCV'] = \"TX\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = \"\" #empty\n",
    "df['in_AllocationLegalStatusCV'] = \"WaDE Unspecified\"\n",
    "df['in_AllocationNativeID'] =  dfinPOD['WR_ID'].replace(\"\", 0).fillna(0).str.strip().astype(str)\n",
    "df['in_AllocationOwner'] = dfinPOD['in_AllocationOwner']\n",
    "df['in_AllocationPriorityDate'] = \"\" #empty\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = \"\" #empty\n",
    "df['in_BeneficialUseCategory'] = dfinPOD['in_BeneficialUseCategory']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 1 # we want this data excempt\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = \"https://gisweb.tceq.texas.gov/WRRetrieveRights/?ID=\" + dfinPOD['WR_TYPE_NO'].replace(\"\", 0).fillna(0).str.strip().astype(str)\n",
    "\n",
    "outPOD = df.copy()\n",
    "outPOD = outPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOD))\n",
    "outPOD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outPOD]\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing empty string names\n",
    "\n",
    "def fixEmptyString(val):\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"WaDE Unspecified\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: fixEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: fixEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: fixEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude & in_Longitude\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').fillna(0)\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').fillna(0)\n",
    "outdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'])\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').fillna(0)\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').fillna(0)\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# Change 'outstring' name to be state specific.\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceName'] == A) & \n",
    "                                       (dfWaterSourceNativeID['in_WaterSourceTypeCV'] == B), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('Pwr_txMain.zip', index=False, compression=\"zip\")  # The output, save as a zip\n",
    "#dfPoUshape.to_csv('P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
