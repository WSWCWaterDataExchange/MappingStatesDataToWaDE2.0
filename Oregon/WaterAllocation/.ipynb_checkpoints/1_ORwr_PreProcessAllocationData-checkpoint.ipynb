{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Oregon Allocation data for WaDE upload.\n",
    "\n",
    "Purpose:  To pre-process the Oregon data into one master file for simple DataFrame creation and extraction\n",
    "\n",
    "Useful Links to Data:\n",
    "\n",
    "- Data Avalaible (use 'Statewide Water Right Spatial Data with Metadata'): https://www.oregon.gov/OWRD/access_Data/Pages/Data.aspx\n",
    "\n",
    "- POD metadata: https://arcgis.wrd.state.or.us/data/wr_pod_metadata.pdfPOD\n",
    "\n",
    "- POU metadata: https://arcgis.wrd.state.or.us/data/wr_pou_metadata.pdfPOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Oregon/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point of Diversoin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pod data\n",
    "inputFile = 'shapefile/wr_v_pod_public.zip'\n",
    "dfinPOD = gpd.read_file(inputFile).replace(np.nan, \"\").replace(\"nan,nan\", \"\") #geodataframe read\n",
    "dfinPOD = dfinPOD.drop(['geometry'], axis=1)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOD:\n",
    "    dfinPOD['WaDEUUID'] = \"orD\" + dfinPOD.index.astype(str)\n",
    "    dfinPOD.to_csv('wr_v_pod_public.zip', compression=dict(method='zip', archive_name='wr_v_pod_public.csv'), index=False)\n",
    "\n",
    "dfinPOD = dfinPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfinPOD))\n",
    "dfinPOD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating SiteTypeCV\n",
    "STCVDict = {\n",
    "\"LK\" : \"lake\",\n",
    "\"DR\" : \"drain\",\n",
    "\"SP\" : \"spring\",\n",
    "\"ST\" : \"stream\",\n",
    "\"SL\" : \"slough\",\n",
    "\"WW\" : \"waste water\",\n",
    "\"WE\" : \"well\",\n",
    "\"WR\" : \"winter runoff\",\n",
    "\"SM\" : \"sump\",\n",
    "\"PD\" : \"pond\",\n",
    "\"RS\" : \"reservoir\",\n",
    "\"DT\" : \"ditch\",\n",
    "\"SE\" : \"sewage effluent\",\n",
    "\"CN\" : \"canal\"}\n",
    "def assignSiteTypeCV(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outList = \"\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()\n",
    "        try:\n",
    "            outList = STCVDict[String1]\n",
    "        except:\n",
    "            outList = \"\"\n",
    "    return outList\n",
    "\n",
    "dfinPOD['in_SiteTypeCV'] = dfinPOD.apply(lambda row: assignSiteTypeCV(row['source_typ']), axis=1)\n",
    "dfinPOD['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Ownername.\n",
    "# Concatenating first and last name of individual.\n",
    "# Determining if company is available, split string.\n",
    "# combine together for output.\n",
    "\n",
    "import re\n",
    "\n",
    "# first & last name funciton\n",
    "def assignownerName(colrowValue1, colrowValue2):\n",
    "    if colrowValue1 == '' or pd.isnull(colrowValue1):\n",
    "        outList1 = ''\n",
    "    else:\n",
    "        outList1 = colrowValue1.strip()  # remove whitespace chars\n",
    "    if colrowValue2 == '' or pd.isnull(colrowValue2):\n",
    "        outList2 = ''\n",
    "    else:\n",
    "        outList2 = colrowValue2.strip()  # remove whitespace chars\n",
    "\n",
    "    if outList1 == '' and outList2 == '':\n",
    "        outList = ''\n",
    "    elif outList1 == '':\n",
    "        outList = outList2\n",
    "    elif outList2 == '':\n",
    "        outList = outList1\n",
    "    else:\n",
    "        outList = \" \".join(map(str, [colrowValue1, colrowValue2]))\n",
    "    return outList\n",
    "\n",
    "\n",
    "# Business name and Concatenate\n",
    "def assignownerNameORCompany(buisName, fName, lName):\n",
    "    \n",
    "    # Concatenating First and Last name together.\n",
    "    frilasName = assignownerName(fName, lName)\n",
    "    \n",
    "    # Clearn Company Name Entry\n",
    "    if buisName == \"\" or pd.isnull(buisName):\n",
    "        outBuisString = \"\"\n",
    "    else:\n",
    "        buisName = str(buisName).strip()\n",
    "        if \";\" in buisName:\n",
    "            xList = buisName.split(\";\")\n",
    "            for index, item in enumerate(xList):\n",
    "                if \",\" in item:\n",
    "                    list1 = item.split(\",\")\n",
    "                    list1.reverse()\n",
    "                    xList[index] = \"\".join(list1)\n",
    "                else:\n",
    "                    xList[index] = item\n",
    "            outBuisString = \",\".join(xList)\n",
    "        elif \",\" in buisName:\n",
    "            xList = buisName.split(\",\")\n",
    "            outBuisString = str(xList[0]).strip() + \",\" + str(xList[1]).strip()\n",
    "        else:\n",
    "            outBuisString = buisName\n",
    "    \n",
    "    #Concatenating together, create outString\n",
    "    if frilasName == \"\"  or pd.isnull(frilasName):\n",
    "        if outBuisString == \"\"  or pd.isnull(outBuisString):\n",
    "            outString = \"\"\n",
    "        else:\n",
    "            outString = outBuisString\n",
    "    else:\n",
    "        if outBuisString == \"\"  or pd.isnull(outBuisString):\n",
    "            outString = frilasName\n",
    "        else:\n",
    "            outString = frilasName + \", \" + outBuisString\n",
    "        \n",
    "    outString = outString.strip()\n",
    "    outString = re.sub(\"[$@&.;,/\\)(-]\", \"\", outString).replace(\"  \", \" \").title().strip()\n",
    "    \n",
    "    return outString\n",
    "\n",
    "dfinPOD['in_AllocationOwner'] = dfinPOD.apply(lambda row: assignownerNameORCompany(row['name_compa'], row['name_first'], row['name_last']), axis=1)\n",
    "dfinPOD['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining AllocationTimeframe Start & End time for each site.\n",
    "\n",
    "def formatDateString(inString1, inString2):\n",
    "    #print(inString)\n",
    "    try:\n",
    "        valndf = str(int(inString1)).strip() + '/' + str(int(inString2)).strip()\n",
    "    except:\n",
    "        valndf = ''\n",
    "\n",
    "    return valndf;\n",
    "\n",
    "dfinPOD['in_AllocationTimeframeStart'] = dfinPOD.apply(lambda row: formatDateString(row['begin_mont'], row['begin_day']), axis=1)\n",
    "dfinPOD['in_AllocationTimeframeEnd'] = dfinPOD.apply(lambda row: formatDateString(row['end_month'], row['end_day']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOD['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"ORwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"ORwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"ORwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfinPOD['source']\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = dfinPOD['wr_type']\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOD['Latitude']\n",
    "df['in_Longitude'] = dfinPOD['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"POD\" + dfinPOD['pod_locati'].replace(\"\", 0).fillna(0).astype(int).astype(str).str.strip()\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = dfinPOD['in_SiteTypeCV']\n",
    "df['in_StateCV'] = \"OR\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = dfinPOD['duty']\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfinPOD['rate_cfs']\n",
    "df['in_AllocationLegalStatusCV'] = \"\"\n",
    "df['in_AllocationNativeID'] =  dfinPOD['snp_id'].replace(\"\", 0).fillna(0).astype(int).astype(str).str.strip()\n",
    "df['in_AllocationOwner'] = dfinPOD['in_AllocationOwner']\n",
    "df['in_AllocationPriorityDate'] = dfinPOD['priority_d']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = dfinPOD['in_AllocationTimeframeEnd']\n",
    "df['in_AllocationTimeframeStart'] = dfinPOD['in_AllocationTimeframeStart']\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfinPOD['acre_feet']\n",
    "df['in_BeneficialUseCategory'] = dfinPOD['use_code_d']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfinPOD['wris_link']  #for WaterAllocationNativeURL\n",
    "\n",
    "outPOD = df.copy()\n",
    "outPOD = outPOD.drop_duplicates().reset_index(drop=True).replace(np.nan, '')\n",
    "print(len(outPOD))\n",
    "outPOD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place of Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - PoU Shapefile Data\n",
    "# export dataframe as zipped csv\n",
    "pouInput = 'shapefile/wr_v_pou_public.zip'\n",
    "dfinPOU = gpd.read_file(pouInput).replace(np.nan, \"\").replace(\"nan,nan\", \"\") #geodataframe read\n",
    "dfinPOU = dfinPOU.drop(['geometry'], axis=1)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOU:\n",
    "    dfinPOU['WaDEUUID'] = \"orU\" + dfinPOU.index.astype(str)\n",
    "    dfinPOU.to_csv('wr_v_pou_public.zip', compression=dict(method='zip', archive_name='wr_v_pou_public.csv'), index=False)\n",
    "\n",
    "print(len(dfinPOU))\n",
    "dfinPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POU data is missing key inputs, will combine with POD data to fill in missing gaps.\n",
    "dfinPOU['snp_id'] = dfinPOU['snp_id'].replace(\"\", 0).fillna(0).astype(str).str.strip()  #for AllocationNativeID\n",
    "\n",
    "dfinPOU = pd.merge(dfinPOU, outPOD, left_on='snp_id', right_on='in_AllocationNativeID', how='left')\n",
    "print(len(dfinPOU))\n",
    "dfinPOU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOU['WaDEUUID_x']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"ORwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"ORwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"ORwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfinPOU['in_WaterSourceName'] # from POD\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = dfinPOU['in_WaterSourceTypeCV'] # from POD\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOU['cent_Latit']\n",
    "df['in_Longitude'] = dfinPOU['cent_Longi']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POU\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"POU\" + dfinPOU['pou_use_id'].replace(\"\", 0).fillna(0).astype(int).astype(str).str.strip()\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"OR\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = dfinPOU['in_AllocationCropDutyAmount'] # from POD\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfinPOU['in_AllocationFlow_CFS'] # From POD\n",
    "df['in_AllocationLegalStatusCV'] = \"\"\n",
    "df['in_AllocationNativeID'] =  dfinPOU['snp_id'].replace(\"\", 0).fillna(0).astype(int).astype(str).str.strip()\n",
    "df['in_AllocationOwner'] = dfinPOU['in_AllocationOwner'] # from POD\n",
    "df['in_AllocationPriorityDate'] = dfinPOU['priority_d']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = dfinPOU['in_AllocationTimeframeEnd'] # from POD\n",
    "df['in_AllocationTimeframeStart'] = dfinPOU['in_AllocationTimeframeStart'] # from POD\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfinPOU['in_AllocationVolume_AF']  # from POD\n",
    "df['in_BeneficialUseCategory'] = dfinPOU['use_code_d']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfinPOU['wris_acres']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfinPOU['in_WaterAllocationNativeURL']  #for WaterAllocationNativeURL\n",
    "\n",
    "outPOU = df.copy()\n",
    "outPOU = outPOU.drop_duplicates().reset_index(drop=True).replace(np.nan, '')\n",
    "print(len(outPOU))\n",
    "outPOU.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outPOD, outPOU]\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom WaDE Elements due to missing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating WaterSourceTypeCV\n",
    "WSTypeDict = {\n",
    "    \"ST\": \"Storage\",\n",
    "    \"GW\": \"Groundwater\",\n",
    "    \"SW\": \"Surface Water\"}\n",
    "def assignWaterSourceTypeCV(colrowValue):\n",
    "    colrowValue = str(colrowValue).strip()\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outList = \"WaDE Blank\"\n",
    "    else:\n",
    "        try:\n",
    "            outList = WSTypeDict[colrowValue]\n",
    "        except:\n",
    "            outList = \"WaDE Blank\"\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: assignWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing Beneficial Uses PRIMARY_PURPOSE\n",
    "\n",
    "def fixBenUse(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"IRRIGATION, LIVESTOCK AND DOMESTIC\":\n",
    "        outString = \"IRRIGATION, LIVESTOCK, DOMESTIC\"\n",
    "    elif val == \"IRRIGATION AND LIVESTOCK\":\n",
    "        outString = \"IRRIGATION, LIVESTOCK\"\n",
    "    elif val == \"LIVESTOCK AND WILDLIFE\":\n",
    "        outString = \"LIVESTOCK, WILDLIFE\"\n",
    "    elif val == \"DOMESTIC AND LIVESTOCK\":\n",
    "        outString = \"DOMESTIC, LIVESTOCK\"\n",
    "    elif val == \"IRRIGATION AND DOMESTIC\":\n",
    "        outString = \"IRRIGATION, DOMESTIC\"\n",
    "    elif val == \"HUMAN CONSUMPTION AND LIVESTOCK\":\n",
    "        outString = \"HUMAN CONSUMPTION, LIVESTOCK\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString\n",
    "\n",
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: fixBenUse(row['in_BeneficialUseCategory']), axis=1)\n",
    "for x in outdf['in_BeneficialUseCategory'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean owner name up\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;/\\)(-]\", \"\", Val).title().strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationLegalStatusCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Longitude\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationCropDutyAmount datatype\n",
    "outdf['in_AllocationCropDutyAmount'] = pd.to_numeric(outdf['in_AllocationCropDutyAmount'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationCropDutyAmount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_IrrigatedAcreage datatype\n",
    "outdf['in_IrrigatedAcreage'] = pd.to_numeric(outdf['in_IrrigatedAcreage'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_IrrigatedAcreage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str) + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching gemetry to csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "dfPoUshapetemp = gpd.read_file('shapefile/wr_v_pou_public.zip')\n",
    "dfPoUshapetemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if dupbliate siteNative IDs\n",
    "dfPoUshapetemp['pou_use_id'] = np.where(dfPoUshapetemp['pou_use_id'].duplicated(keep=False),\n",
    "                                        dfPoUshapetemp['pou_use_id'].astype(str).str.cat(dfPoUshapetemp.groupby('pou_use_id').cumcount().add(1).astype(str), sep='_'),\n",
    "                                        dfPoUshapetemp['pou_use_id'])\n",
    "\n",
    "print(dfPoUshapetemp['pou_use_id'].nunique())\n",
    "dfPoUshapetemp['pou_use_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp['pou_use_id'].replace(\"\", 0).fillna(0).astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('Pwr_orMain.zip', compression=dict(method='zip', archive_name='Pwr_orMain.csv'), index=False)  # The output, save as a zip\n",
    "dfPoUshape.to_csv('P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
