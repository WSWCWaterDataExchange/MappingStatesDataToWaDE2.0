{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Oregon Reservoir and Gage data for WaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Oregon/SS_ReservoirsGages/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - OWRD_gages.csv\n",
    "sgInput = \"OWRD_gages.csv\"\n",
    "dfsg = pd.read_csv(sgInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfsg:\n",
    "    dfsg['WaDEUUID'] = \"orSRG\" + dfsg.index.astype(str)\n",
    "    dfsg.to_csv('OWRD_gages.csv', index=False)\n",
    "\n",
    "print(len(dfsg))\n",
    "dfsg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null rows for the time periods\n",
    "\n",
    "dfsg = dfsg.dropna(subset=['period_of_', 'period_of1']).reset_index(drop=True)\n",
    "print(len(dfsg))\n",
    "dfsg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use Active site records\n",
    "\n",
    "dfsg = dfsg[dfsg['station__1'] == 'Active'].drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfsg))\n",
    "dfsg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert start and end data to MM/DD/YYYY format.\n",
    "\n",
    "dfsg['period_of_'] = pd.to_datetime(dfsg['period_of_'], utc=True)\n",
    "dfsg['period_of_'] = pd.to_datetime(dfsg[\"period_of_\"].dt.strftime('%m/%d/%Y').astype(str))\n",
    "\n",
    "dfsg['period_of1'] = pd.to_datetime(dfsg['period_of1'], utc=True)\n",
    "dfsg['period_of1'] = pd.to_datetime(dfsg[\"period_of1\"].dt.strftime('%m/%d/%Y').astype(str))\n",
    "\n",
    "dfsg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of StationNumber\n",
    "streamgageIdList = dfsg['station_nb'].tolist()\n",
    "print(len(streamgageIdList))\n",
    "streamgageIdList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of start date\n",
    "startDateList = dfsg['period_of_'].astype(str).tolist()\n",
    "print(len(startDateList))\n",
    "startDateList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of end date\n",
    "endDateList = dfsg['period_of1'].astype(str).tolist()\n",
    "print(len(endDateList))\n",
    "endDateList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done already\n",
    "\n",
    "# %%time\n",
    "# # get timeseries results\n",
    "\n",
    "# # create empty dataframe\n",
    "# dfts = pd.DataFrame()\n",
    "\n",
    "# sglength = len(streamgageIdList)\n",
    "# for i in range(sglength):\n",
    "#     url = \"https://apps.wrd.state.or.us/apps/sw/hydro_near_real_time/hydro_download.aspx?station_nbr=\" + str(streamgageIdList[i]) + \"&start_date=\" + str(startDateList[i]) + \"&end_date=\" + str(endDateList[i]) + \"&dataset=MDF&format=html\"\n",
    "#     print(url)\n",
    "#     try:\n",
    "#         # store in dataframe\n",
    "#         dftemp = pd.DataFrame()\n",
    "#         dftemp = pd.read_csv(url, sep=\"\\t\")\n",
    "#         dftemp['url'] = url\n",
    "#         dfts = pd.concat([dfts, dftemp])\n",
    "    \n",
    "#     except:\n",
    "#         dftemp = pd.DataFrame()\n",
    "#         dftemp['url'] = url\n",
    "#         dfts = pd.concat([dfts, dftemp])\n",
    "#         print(\"Error, issue with API return.\")\n",
    "\n",
    "# dfts.to_csv('timeseriesData.csv', index=False)  # The output.\n",
    "# print(len(dfts))\n",
    "# dfts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - timeseriesData.csv\n",
    "# read the dataset from a zip\n",
    "fileInput = \"timeseriesData.zip\"\n",
    "dfts = pd.read_csv(fileInput)\n",
    "\n",
    "print(len(dfts))\n",
    "dfts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use published data\n",
    "\n",
    "dfts = dfts[dfts['published_status'] == 'Published'].drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfts))\n",
    "dfts.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes into one, using left-join.\n",
    "df = pd.merge(dfts, dfsg, left_on='<pre>station_nbr', right_on='station_nb', how='left')\n",
    "print(len(df))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Water Source Info\n",
    "dfout['in_WaterSourceTypeCV'] = df['streamfl_1']\n",
    "\n",
    "# Site Info\n",
    "dfout['in_County'] = df['county_nam']\n",
    "dfout['in_Latitude'] = df['latitude_d']\n",
    "dfout['in_Longitude'] = df['longitude_']\n",
    "dfout['in_PODorPOUSite'] = \"Gage\"\n",
    "dfout['in_SiteName'] = df['station_na']\n",
    "dfout['in_SiteNativeID'] = df['station_nb']\n",
    "dfout['in_SiteTypeCV'] = df['source_t_1']\n",
    "\n",
    "# Site VariableAmounts Info\n",
    "dfout['in_Amount'] = df['mean_daily_flow_cfs']\n",
    "dfout['in_BeneficialUseCategory'] = \"Unspecified\"\n",
    "dfout['in_ReportYearCV'] = df['record_date']\n",
    "dfout['in_TimeframeEnd'] = df['record_date']\n",
    "dfout['in_TimeframeStart'] = df['record_date']\n",
    "\n",
    "print(len(dfout))\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate values\n",
    "dfout = dfout.drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout.info()\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing empty water source types\n",
    "\n",
    "def fixWaterSourceTypeCV(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or pd.isnull(val) or val == \"nan\":\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString\n",
    "\n",
    "dfout['in_WaterSourceTypeCV'] = dfout.apply(lambda row: fixWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing empty site types names\n",
    "\n",
    "def fixSiteTypeCV(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or pd.isnull(val) or val == \"nan\":\n",
    "        outString = \"Unspecified\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString\n",
    "\n",
    "dfout['in_SiteTypeCV'] = dfout.apply(lambda row: fixSiteTypeCV(row['in_SiteTypeCV']), axis=1)\n",
    "dfout['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert History Year to MM/DD/YYYY format.\n",
    "dfout['in_TimeframeEnd'] = pd.to_datetime(dfout['in_TimeframeEnd'], utc=True)\n",
    "dfout['in_TimeframeEnd'] = pd.to_datetime(dfout[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout['in_TimeframeStart'] = pd.to_datetime(dfout['in_TimeframeStart'], utc=True)\n",
    "dfout['in_TimeframeStart'] = pd.to_datetime(dfout[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year out\n",
    "dfout['in_ReportYearCV'] = pd.to_datetime(dfout['in_ReportYearCV'], utc=True)\n",
    "dfout['in_ReportYearCV'] = pd.to_datetime(dfout[\"in_ReportYearCV\"].dt.strftime('%m/%d/%Y'))\n",
    "dfout['in_ReportYearCV'] = dfout['in_ReportYearCV'].dt.year\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"WaDEOR_WS\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = dfout['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceTypeCV'] == A), 'in_WaterSourceNativeID']\n",
    "    if not (ml.empty):  # check if the series is empty\n",
    "        outList = ml.iloc[0]\n",
    "    else:\n",
    "        outList = ''\n",
    "    return outList\n",
    "\n",
    "dfout['in_WaterSourceNativeID'] = dfout.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceTypeCV']), axis=1)\n",
    "dfout['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dfout.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to Finished File\n",
    "dfout.to_csv('P_orSSRGMain.csv', index=False)  # The output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout.to_csv('P_orSSRGMain.zip', compression={'method': 'zip', 'archive_name': 'sample.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
