{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Overlay data for WaDE upload.\n",
    "- Purpose: To preprocess state overlay data into one main file for simple DataFrame creation and extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"G:/Shared drives/WaDE Data/WaDE Data Folder/Oregon/Overlays\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay Area Data #1\n",
    "- Administrative Basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "inputFile = \"RawInputData/shapefiles/oregon-water-resources-department-owrd-administrative-basins.zip\"\n",
    "dfin1 = gpd.read_file(inputFile).replace(np.nan, \"\")\n",
    "dfin1['geometry'] = dfin1['geometry'].to_crs(epsg=4326) # Realign Geometry Projection\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin1:\n",
    "    dfin1['WaDEUUID'] = \"ov\" + dfin1.index.astype(str)\n",
    "    dfin1.to_csv('RawInputData/oregon-water-resources-department-owrd-administrative-basins.zip', compression=dict(method='zip', archive_name='oregon-water-resources-department-owrd-administrative-basins.csv'), index=False)\n",
    "\n",
    "print(len(dfin1))\n",
    "dfin1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output for Regulatory Area #1 dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfin1['WaDEUUID']\n",
    "\n",
    "# Date Info\n",
    "df['in_Date'] = \"10/29/2024\"\n",
    "df['in_Year'] = \"2024\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"ORov_O1\"\n",
    "\n",
    "# ReportingUnit Info\n",
    "df['in_EPSGCodeCV'] = \"4326\"\n",
    "df['in_ReportingUnitName'] = dfin1[\"BASIN_NAME\"]\n",
    "df['in_ReportingUnitNativeID'] = \"orAB\" + dfin1[\"BASIN_NUM\"].astype(str)\n",
    "df['in_ReportingUnitProductVersion'] = \"9.6\"\n",
    "df['in_ReportingUnitTypeCV'] = \"Administrative Basins\"\n",
    "df['in_ReportingUnitUpdateDate'] = \"9/22/2021\"\n",
    "df['in_StateCV'] = \"OR\"\n",
    "df['in_Geometry'] = dfin1['geometry']\n",
    "\n",
    "# RegulatoryOverlay Info\n",
    "df['in_OversightAgency'] = \"Oregon Water Resources Department\"\n",
    "df['in_RegulatoryDescription'] = \"Administrative rules which establish water management policies and objectives and which govern the appropriation and use of the surface and ground water.\"\n",
    "df['in_RegulatoryName'] = dfin1[\"BASIN_NAME\"]\n",
    "df['in_RegulatoryOverlayNativeID'] = \"orAB\" + dfin1[\"BASIN_NUM\"].astype(str)\n",
    "df['in_RegulatoryStatusCV'] = \"Active\"\n",
    "df['in_RegulatoryStatute'] = \"\"\n",
    "df['in_RegulatoryStatuteLink'] = \"https://www.oregon.gov/owrd/programs/administrativebasins/pages/default.aspx\"\n",
    "df['in_StatutoryEffectiveDate'] = \"1993-10-07\"\n",
    "df['in_StatutoryEndDate'] = \"\"\n",
    "df['in_RegulatoryOverlayTypeCV'] = \"Administrative Basins\"\n",
    "df['in_WaterSourceTypeCV'] = \"Surface and Groundwater\"\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "outdf1 = df.copy()\n",
    "print(len(outdf1))\n",
    "outdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay Area Data #2\n",
    "- Restricted Groundwater Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "inputFile = \"RawInputData/shapefiles/GW_Restricted_Areas.zip\"\n",
    "dfin2 = gpd.read_file(inputFile).replace(np.nan, \"\")\n",
    "dfin2['geometry'] = dfin2['geometry'].to_crs(epsg=4326) # Realign Geometry Projection\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin2:\n",
    "    dfin2['WaDEUUID'] = \"ov\" + dfin2.index.astype(str)\n",
    "    dfin2.to_csv('RawInputData/GW_Restricted_Areas.zip', compression=dict(method='zip', archive_name='GW_Restricted_Areas.csv'), index=False)\n",
    "\n",
    "print(len(dfin2))\n",
    "dfin2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output for Regulatory Area #1 dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfin2['WaDEUUID']\n",
    "\n",
    "# Date Info\n",
    "df['in_Date'] = \"10/29/2024\"\n",
    "df['in_Year'] = \"2024\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"ORov_O1\"\n",
    "\n",
    "# ReportingUnit Info\n",
    "df['in_EPSGCodeCV'] = \"4326\"\n",
    "df['in_ReportingUnitName'] = dfin2[\"gwra_area_\"]\n",
    "df['in_ReportingUnitNativeID'] = \"\"\n",
    "df['in_ReportingUnitProductVersion'] = \"\"\n",
    "df['in_ReportingUnitTypeCV'] = \"Groundwater Restricted Areas\"\n",
    "df['in_ReportingUnitUpdateDate'] = \"07/23/2023\"\n",
    "df['in_StateCV'] = \"OR\"\n",
    "df['in_Geometry'] = dfin2['geometry']\n",
    "\n",
    "# RegulatoryOverlay Info\n",
    "df['in_OversightAgency'] = \"Oregon Water Resources Department\"\n",
    "df['in_RegulatoryDescription'] = \"To protect existing water rights by preventing excessive groundwater declines, restoring aquifer stability, and preserving aquifers with limited storage capacity for designated high public value uses.\"\n",
    "df['in_RegulatoryName'] = dfin2[\"gwra_area_\"]\n",
    "df['in_RegulatoryOverlayNativeID'] = \"\"\n",
    "df['in_RegulatoryStatusCV'] = dfin2[\"gwra_statu\"]\n",
    "df['in_RegulatoryStatute'] = \"\"\n",
    "df['in_RegulatoryStatuteLink'] = dfin2[\"source_lin\"]\n",
    "df['in_StatutoryEffectiveDate'] = dfin2[\"effective_\"]\n",
    "df['in_StatutoryEndDate'] = \"\"\n",
    "df['in_RegulatoryOverlayTypeCV'] = \"Groundwater Restricted Areas\"\n",
    "df['in_WaterSourceTypeCV'] = \"Groundwater\"\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "outdf2 = df.copy()\n",
    "print(len(outdf2))\n",
    "outdf2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate DataFrames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outdf1, outdf2] # list all out dataframes here\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_ReportingUnitName'] = outdf.apply(lambda row: ensureEmptyString(row['in_ReportingUnitName']), axis=1)\n",
    "outdf['in_ReportingUnitName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_RegulatoryDescription'] = outdf.apply(lambda row: ensureEmptyString(row['in_RegulatoryDescription']), axis=1)\n",
    "outdf['in_RegulatoryDescription'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_RegulatoryName'] = outdf.apply(lambda row: ensureEmptyString(row['in_RegulatoryName']), axis=1)\n",
    "outdf['in_RegulatoryName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update datatype of StatutoryEffectiveDate to fit WaDE 2.0 structure\n",
    "outdf['in_StatutoryEffectiveDate'] = pd.to_datetime(outdf['in_StatutoryEffectiveDate'], errors = 'coerce')\n",
    "outdf['in_StatutoryEffectiveDate'] = pd.to_datetime(outdf['in_StatutoryEffectiveDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_StatutoryEffectiveDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom Reporting Unit Area native ID for easy area identification\n",
    "# use Unique ReportingUnitName and ReportingUnitTypeCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_SiteNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_ReportingUnitName'] = outdf['in_ReportingUnitName'].astype(str).str.strip()\n",
    "dfTempID['in_ReportingUnitTypeCV'] = outdf['in_ReportingUnitTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_ReportingUnitNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_ReportingUnitName'].astype(str) + dfTempID['in_ReportingUnitTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_ReportingUnitNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_ReportingUnitNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_ReportingUnitNativeID'], \n",
    "                                                                       row['in_ReportingUnitName'], row['in_ReportingUnitTypeCV']), axis=1)\n",
    "outdf['in_ReportingUnitNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom Regulatory Overlay Native ID for easy area identification\n",
    "# use Unique RegulatoryName and RegulatoryOverlayTypeCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_SiteNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_RegulatoryName'] = outdf['in_RegulatoryName'].astype(str).str.strip()\n",
    "dfTempID['in_RegulatoryOverlayTypeCV'] = outdf['in_RegulatoryOverlayTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_RegulatoryOverlayNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_RegulatoryName'].astype(str) + dfTempID['in_RegulatoryOverlayTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_RegulatoryOverlayNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_RegulatoryOverlayNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_RegulatoryOverlayNativeID'], \n",
    "                                                                                    row['in_RegulatoryName'], row['in_RegulatoryOverlayTypeCV']), axis=1)\n",
    "outdf['in_RegulatoryOverlayNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry Data\n",
    "- For attaching geometry to overlay reporting unit area info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlay Area #1 shapefile info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input File / or use same input as above\n",
    "gdfin1 = outdf[outdf['in_ReportingUnitTypeCV'] == \"Administrative Basins\"].copy()\n",
    "gdfin1 = gpd.GeoDataFrame(gdfin1, geometry=gdfin1['in_Geometry'], crs=\"EPSG:4326\") # covert to geodataframe\n",
    "print(len(gdfin1))\n",
    "gdfin1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shape info to map\n",
    "gdfin1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output for Regulatory Area #1 dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "columnsList = ['in_ReportingUnitNativeID', 'geometry']\n",
    "goutdf1 = pd.DataFrame(columns=columnsList, index=gdfin1.index)\n",
    "\n",
    "goutdf1['in_ReportingUnitNativeID'] =  gdfin1[\"in_ReportingUnitNativeID\"].astype(str)  # in_ReportingUnitNativeID needs to match source from above equivlaent datframe\n",
    "goutdf1['geometry'] = gdfin1['geometry']\n",
    "goutdf1 = goutdf1.drop_duplicates().reset_index(drop=True)\n",
    "print(len(goutdf1))\n",
    "goutdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlay Area #2 shapefile info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input File / or use same input as above\n",
    "gdfin2 = outdf[outdf['in_ReportingUnitTypeCV'] == \"Groundwater Restricted Areas\"].copy()\n",
    "gdfin2 = gpd.GeoDataFrame(gdfin2, geometry=gdfin2['in_Geometry'], crs=\"EPSG:4326\") # covert to geodataframe\n",
    "print(len(gdfin2))\n",
    "gdfin2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shape info to map\n",
    "gdfin2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output for Regulatory Area #1 dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "columnsList = ['in_ReportingUnitNativeID', 'geometry']\n",
    "goutdf2 = pd.DataFrame(columns=columnsList, index=gdfin2.index)\n",
    "\n",
    "goutdf2['in_ReportingUnitNativeID'] =  gdfin2[\"in_ReportingUnitNativeID\"].astype(str)  # in_ReportingUnitNativeID needs to match source from above equivlaent datframe\n",
    "goutdf2['geometry'] = gdfin2['geometry']\n",
    "goutdf2 = goutdf2.drop_duplicates().reset_index(drop=True)\n",
    "print(len(goutdf2))\n",
    "goutdf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate goutdf shapefile info into single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Basin & Subbasin DataFrames\n",
    "frames = [goutdf1, goutdf2] # add geoutdf dataframes here\n",
    "goutdf = pd.concat(frames).reset_index(drop=True)\n",
    "\n",
    "print(len(goutdf))\n",
    "goutdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    outdf = outdf.drop(['in_Geometry'], axis=1)\n",
    "except:\n",
    "    print(\"No geometry to drop\")\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(outdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(goutdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out to CSV.\n",
    "outdf.to_csv('RawInputData/Pov_Main.zip', compression=dict(method='zip', archive_name='Pov_Main.csv'), index=False)  # The output, save as a zip\n",
    "goutdf.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
