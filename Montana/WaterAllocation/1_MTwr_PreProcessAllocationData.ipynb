{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Montana Allocation data for WaDE upload.\n",
    "- Purpose:  To pre-process the data into one main file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"G:/Shared drives/WaDE Data/Montana/WaterAllocation\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point of Diversion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "FI_PoD = \"RawInputData/PointsofDiversion.zip\"\n",
    "dfinPOD = pd.read_csv(FI_PoD).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOD:\n",
    "    dfinPOD['WaDEUUID'] = \"d\" + dfinPOD.index.astype(str)\n",
    "    dfinPOD.to_csv('RawInputData/PointsofDiversion.zip', compression=dict(method='zip', archive_name='PointsofDiversion.csv'), index=False)\n",
    "\n",
    "print(len(dfinPOD))\n",
    "dfinPOD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out PERIOD_OF_DIVERSIONS to start date\n",
    "def SeparatePERIODOFDIVERSIONSStartFunc(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        if \";\" in val:\n",
    "            val = val.split(\";\")[0].strip()\n",
    "        outString = val.split(\"to\")[0].strip()\n",
    "    return outString\n",
    "\n",
    "dfinPOD['in_AllocationTimeframeStart'] = dfinPOD.apply(lambda row: SeparatePERIODOFDIVERSIONSStartFunc(row['PERIOD_OF_DIVERSIONS']), axis=1)\n",
    "dfinPOD['in_AllocationTimeframeStart'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out PERIOD_OF_DIVERSIONS to end date\n",
    "def SeparatePERIODOFDIVERSIONSEndFunc(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        if \";\" in val:\n",
    "            val = val.split(\";\")[0].strip()\n",
    "        outString = val.split(\"to\")[1].strip()\n",
    "    return outString\n",
    "\n",
    "dfinPOD['in_AllocationTimeframeEnd'] = dfinPOD.apply(lambda row: SeparatePERIODOFDIVERSIONSEndFunc(row['PERIOD_OF_DIVERSIONS']), axis=1)\n",
    "dfinPOD['in_AllocationTimeframeEnd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and round MAX_FLOW\n",
    "def ConvertMAXFLOWFunc(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"CFS\" or val == \"GPM\" or val == \"POF\" or val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outVal = \"\"\n",
    "    else:\n",
    "        if \"CFS\" in val:\n",
    "            val = val.split(\" \")[0].strip()\n",
    "            outVal = float(val)\n",
    "        elif \"GPM\" in val:\n",
    "            val = val.split(\" \")[0].strip()\n",
    "            outVal = (float(val) * 0.0026757275153786)\n",
    "        elif \"POF\" in val:\n",
    "            outVal = \"\"\n",
    "        else:\n",
    "            outVal = float(val)\n",
    "    return outVal\n",
    "\n",
    "dfinPOD['MAX_FLOW'] = dfinPOD.apply(lambda row: ConvertMAXFLOWFunc(row['MAX_FLOW']), axis=1)\n",
    "dfinPOD['MAX_FLOW'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOD['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"MTwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"MTwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"MTwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"Fresh\"\n",
    "df['in_WaterSourceName'] = dfinPOD['SOURCE_NAME']\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below if not provdied\n",
    "df['in_WaterSourceTypeCV'] = dfinPOD['SOURCE_TYPE']\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"WaDE Blank\"\n",
    "df['in_CoordinateMethodCV'] = \"WaDE Blank\"\n",
    "df['in_County'] = dfinPOD['COUNTY']\n",
    "df['in_EPSGCodeCV'] = \"4326\"\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOD['wadeLatitude']\n",
    "df['in_Longitude'] = dfinPOD['wadeLongitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"  # \"Point of Diversion\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = dfinPOD['PODV_ID_SEQ']\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = dfinPOD['MEANS_OF_DIV']\n",
    "df['in_StateCV'] = \"MT\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfinPOD['MAX_FLOW']\n",
    "df['in_AllocationLegalStatusCV'] = dfinPOD['WR_STATUS']\n",
    "df['in_AllocationNativeID'] = dfinPOD['WR_NUMBER']\n",
    "df['in_AllocationOwner'] = dfinPOD['OWNERS']\n",
    "df['in_AllocationPriorityDate'] = dfinPOD['ENF_PRTY_DT_DATE']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = dfinPOD['in_AllocationTimeframeEnd']\n",
    "df['in_AllocationTimeframeStart'] = dfinPOD['in_AllocationTimeframeStart']\n",
    "df['in_AllocationTypeCV'] = dfinPOD['WR_TYPE']\n",
    "df['in_AllocationVolume_AF'] = dfinPOD['MAX_VOL']\n",
    "df['in_BeneficialUseCategory'] = dfinPOD['PURPOSES']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = \"0\" # either a 1 or 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfinPOD['MAX_ACRES']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfinPOD['URL_ABSTRACT']\n",
    "\n",
    "outPOD = df.copy()\n",
    "outPOD = outPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOD))\n",
    "outPOD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place of Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - place of use data\n",
    "FI_POU = \"RawInputData/shapefiles/PlaceofUse.zip\"\n",
    "dfinPOU = gpd.read_file(FI_POU).replace(np.nan, \"\").reset_index()\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfinPOU:\n",
    "    dfinPOU['WaDEUUID'] = \"u\" + dfinPOU.index.astype(str)\n",
    "    dfinPOU.to_csv('RawInputData/PlaceofUse.zip', compression=dict(method='zip', archive_name='PlaceofUse.csv'), index=False)\n",
    "\n",
    "print(len(dfinPOU))\n",
    "dfinPOU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out PERIOD_OF_DIVERSIONS to start date\n",
    "\n",
    "# replace \"-\" char with a \"/\" char to match POD data\n",
    "dfinPOU['PERIOD_OF_'] = dfinPOU['PERIOD_OF_'].str.replace(\"-\", \"/\").str.replace(\";\", \",\")\n",
    "\n",
    "def SeparatePERIODOFDIVERSIONSStartFunc(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        if \";\" in val:\n",
    "            val = val.split(\";\")[0].strip()\n",
    "        outString = val.split(\"to\")[0].strip()\n",
    "    return outString\n",
    "\n",
    "dfinPOU['in_AllocationTimeframeStart'] = dfinPOU.apply(lambda row: SeparatePERIODOFDIVERSIONSStartFunc(row['PERIOD_OF_']), axis=1)\n",
    "dfinPOU['in_AllocationTimeframeStart'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out PERIOD_OF_DIVERSIONS to end date\n",
    "def SeparatePERIODOFDIVERSIONSEndFunc(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        if \";\" in val:\n",
    "            val = val.split(\";\")[0].strip()\n",
    "        outString = val.split(\"to\")[1].strip()\n",
    "    return outString\n",
    "\n",
    "dfinPOU['in_AllocationTimeframeEnd'] = dfinPOU.apply(lambda row: SeparatePERIODOFDIVERSIONSEndFunc(row['PERIOD_OF_']), axis=1)\n",
    "dfinPOU['in_AllocationTimeframeEnd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and round MAX_FLOW\n",
    "def ConvertMAXFLOWFunc(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"CFS\" or val == \"GPM\" or val == \"POF\" or val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outVal = \"\"\n",
    "    else:\n",
    "        if \"CFS\" in val:\n",
    "            val = val.split(\" \")[0].strip()\n",
    "            outVal = float(val)\n",
    "        elif \"GPM\" in val:\n",
    "            val = val.split(\" \")[0].strip()\n",
    "            outVal = (float(val) * 0.0026757275153786)\n",
    "        elif \"POF\" in val:\n",
    "            outVal = \"\"\n",
    "        else:\n",
    "            outVal = float(val)\n",
    "    return outVal\n",
    "\n",
    "dfinPOU['MAX_FLOW'] = dfinPOU.apply(lambda row: ConvertMAXFLOWFunc(row['MAX_FLOW']), axis=1)\n",
    "dfinPOU['MAX_FLOW'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left-join outPOD to ensure water source information matches POD records\n",
    "\n",
    "dfinPOU = pd.merge(dfinPOU, outPOD[['in_AllocationNativeID', 'in_WaterSourceName', 'in_WaterSourceTypeCV']], left_on='WR_NUMBER', right_on='in_AllocationNativeID', how='left')\n",
    "print(len(dfinPOU))\n",
    "dfinPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfinPOU['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"MTwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"MTwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"MTwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfinPOU['in_WaterSourceName'] # from POD info\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below if not provdied\n",
    "df['in_WaterSourceTypeCV'] = dfinPOU['in_WaterSourceTypeCV'] # from POD info\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"WaDE Blank\"\n",
    "df['in_CoordinateMethodCV'] = \"Centroid of Area\"\n",
    "df['in_County'] = dfinPOU['COUNTY']\n",
    "df['in_EPSGCodeCV'] = \"4326\"\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfinPOU['wadeLatitu']\n",
    "df['in_Longitude'] = dfinPOU['wadeLongit']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POU\"  # \"Place of Use\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"u\" + dfinPOU['index'].astype(str).str.strip() \n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"MT\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfinPOU['MAX_FLOW']\n",
    "df['in_AllocationLegalStatusCV'] =dfinPOU['WR_STATUS']\n",
    "df['in_AllocationNativeID'] = dfinPOU['WR_NUMBER']\n",
    "df['in_AllocationOwner'] = dfinPOU['OWNERS']\n",
    "df['in_AllocationPriorityDate'] = dfinPOU['ENF_PRTY_D']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = dfinPOU['in_AllocationTimeframeEnd']\n",
    "df['in_AllocationTimeframeStart'] = dfinPOU['in_AllocationTimeframeStart']\n",
    "df['in_AllocationTypeCV'] = dfinPOU['WR_TYPE']\n",
    "df['in_AllocationVolume_AF'] = dfinPOU['MAX_VOL']\n",
    "df['in_BeneficialUseCategory'] = dfinPOU['PURPOSES']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = \"0\" # either a 1 or 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfinPOU['MAX_ACRES']\n",
    "df['in_IrrigationMethodCV'] = dfinPOU['IRR_TYPE']\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfinPOU['URL_ABSTRA']\n",
    "\n",
    "\n",
    "outPOU = df.copy()\n",
    "outPOU = outPOU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outPOU))\n",
    "outPOU.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU Data.  Make needed changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outPOD, outPOU]  # list all out dataframes here\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ';' from benefical use, replace with commas ','\n",
    "\n",
    "outdf['in_BeneficialUseCategory'] = outdf['in_BeneficialUseCategory'].str.replace(\";\", \",\")\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ';' from owner, replace with commas ','\n",
    "\n",
    "outdf['in_AllocationOwner'] = outdf['in_AllocationOwner'].str.replace(\";\", \",\")\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean name entries of spcial characters\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "uniqueList = list(set([i.strip() for i in ','.join(outdf['in_BeneficialUseCategory'].astype(str)).split(',')]))\n",
    "uniqueList.sort()\n",
    "uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Latitude entry is either numireic or a 0\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Longitude entry is either numireic or a 0\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype of Priority Date to date fields entry\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf[\"in_AllocationPriorityDate\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Flow entry is either numireic or a 0\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').round(2).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Volume entry is either numireic or a 0\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').round(2).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# use unique WaterSourceName and WaterSourceType values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_WaterSourceNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_WaterSourceName'] = outdf['in_WaterSourceName'].astype(str).str.strip()\n",
    "dfTempID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_WaterSourceNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_WaterSourceName'].astype(str) + dfTempID['in_WaterSourceTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_WaterSourceNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_WaterSourceNativeID'], \n",
    "                                                                              row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom site native ID for easy site identification\n",
    "# use Unique Latitude, Longitude, SiteName and SiteTypeCV values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_SiteNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_Latitude'] = outdf['in_Latitude'].astype(str).str.strip()\n",
    "dfTempID['in_Longitude'] = outdf['in_Longitude'].astype(str).str.strip()\n",
    "dfTempID['in_SiteName'] = outdf['in_SiteName'].astype(str).str.strip()\n",
    "dfTempID['in_SiteTypeCV'] = outdf['in_SiteTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_SiteNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_Latitude'].astype(str) + dfTempID['in_Longitude'].astype(str) + dfTempID['in_SiteName'].astype(str)+ dfTempID['in_SiteTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_SiteNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB, valC, valD):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip() + str(valC).strip() + str(valD).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_SiteNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_SiteNativeID'], \n",
    "                                                                       row['in_Latitude'], row['in_Longitude'],\n",
    "                                                                       row['in_SiteName'], row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop non-Active AllocationLegalStatusCV Water Rights\n",
    "- For MT, we don't want water rights that are considered: {enter stringentries here}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-active AllocationLegalStatusCV values specific to that state.\n",
    "\n",
    "# drop the list\n",
    "dropLegalStatusList = ['WITHDRAWN', \n",
    "                       'TERMINATED', \n",
    "                       'PENDING', \n",
    "                       'CANCELLED',\n",
    "                       'DISMISSED', \n",
    "                       'SUSPENDED', \n",
    "                       'DENIED', \n",
    "                       'SEVERED', \n",
    "                       'EXPIRED',\n",
    "                       'REVOKED'\n",
    "] # enter string entries here\n",
    "\n",
    "# drop rows from above list\n",
    "outdf = outdf[outdf.in_AllocationLegalStatusCV.isin(dropLegalStatusList) == False].reset_index(drop=True)\n",
    "\n",
    "print(len(outdf))\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PoU Shapefile Data\n",
    "# shapefileInput = \"RawInputData/shapefiles/{enter file name here}.zip\" # ziped folder of the shp file\n",
    "\n",
    "# dfPoUshapetemp = gpd.read_file(shapefileInput)\n",
    "# dfPoUshapetemp['geometry'] = dfPoUshapetemp['geometry'].to_crs(epsg=4326) # Realign Geometry Projection\n",
    "# print(len(dfPoUshapetemp))\n",
    "# dfPoUshapetemp.head()\n",
    "\n",
    "\n",
    "# use above POU input file\n",
    "dfPoUshapetemp = dfinPOU.copy()\n",
    "# print(len(dfPoUshapetemp))\n",
    "# dfPoUshapetemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp dataframe to hold native ID and geometry from shapefile input\n",
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "\n",
    "# assing values to temp dataframe based on shapefile input\n",
    "# for in_SiteNativeID assure ID value is the same as that listed above for POU info.\n",
    "dfPoUshape['in_SiteNativeID'] = \"u\" + dfPoUshapetemp['index'].astype(str).str.strip() \n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "print(len(dfPoUshape))\n",
    "dfPoUshape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "# change output name / abbreviation to match native state provdier and wade data type \n",
    "outdf.to_csv('RawInputData/Pwr_mtMain.zip', compression=dict(method='zip', archive_name='Pwr_Main.csv'), index=False)  # The output, save as a zip\n",
    "dfPoUshape.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
