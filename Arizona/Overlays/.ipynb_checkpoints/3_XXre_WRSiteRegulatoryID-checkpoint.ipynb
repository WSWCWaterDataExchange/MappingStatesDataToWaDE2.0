{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1726ea",
   "metadata": {},
   "source": [
    "# Assign OverlayUUIDs Values to Water Right sites.csv\n",
    "Purpose:  To assign OverlayUUIDs values to state water right sites.csv File.\n",
    "\n",
    "Notes: \n",
    "- requires the completed pre-processed sites.csv & watersource.csv files from the state \"WaterAllocation/ProcessedInputData\" folder to be copied over to the \"Regulatory/ProcessedInputData\" folder.  Rename to wr_sites.csv & wr_watersource.csv to preserve inputs.\n",
    "- requires awareness of unique WaterSourceTypeCV of each water right site match up to corresponding WaterSourceTypeCV of Overlays per reportingunits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6bb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "import geoplot as gplt # for plotting maps\n",
    "import geoplot.crs as gcrs #used to pull in webdata\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67694dfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ---- working directory ----\u001b[39;00m\n\u001b[0;32m      2\u001b[0m workingDirString \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# set working directory folder string here\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkingDirString\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe working Directory is:\u001b[39m\u001b[38;5;124m'\u001b[39m, workingDirString)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: ''"
     ]
    }
   ],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422914c",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb68590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regulatory Input Data\n",
    "dfov = pd.read_csv(\"ProcessedInputData/overlays.csv\")\n",
    "dfru = pd.read_csv(\"ProcessedInputData/reportingunits.csv\")\n",
    "dfrru = pd.read_csv(\"ProcessedInputData/overlayreportingunits.csv\")\n",
    "\n",
    "# Water right Input Data\n",
    "dfws = pd.read_csv('ProcessedInputData/wr_watersources.csv')\n",
    "dfs = pd.read_csv('ProcessedInputData/wr_sites.csv', engine = \"python\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ad00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### regulatory watersource info with reporting unit info\n",
    "\n",
    "# merge Overlays -to- regulatoryreportingunits -to- reportingunits\n",
    "dfov = pd.merge(dfov[['OverlayUUID ', 'OverlayTypeCV', 'WaterSourceTypeCV']], dfrru[['OverlayUUID ', 'ReportingUnitUUID']], left_on='OverlayUUID ', right_on='OverlayUUID ', how='left')\n",
    "dfru = pd.merge(dfru, dfov, left_on='ReportingUnitUUID', right_on='ReportingUnitUUID', how='left')\n",
    "\n",
    "print(dfru['OverlayTypeCV'].unique()) # check WaterSourceTypeCV for unique values for\n",
    "print(dfru['WaterSourceTypeCV'].unique()) # check WaterSourceTypeCV for unique values for\n",
    "print(len(dfru))\n",
    "dfru.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### water right watersource info with site info\n",
    "\n",
    "# explode site.csv on WaterSourceUUIDs\n",
    "dfs = dfs.assign(WaterSourceUUIDs=dfs['WaterSourceUUIDs'].str.split(',')).explode('WaterSourceUUIDs').reset_index(drop=True)\n",
    "\n",
    "# merge watersources to dfs via WaterSourceUUIDs -to -WaterSourceUUID\n",
    "dfs = pd.merge(dfs, dfws[['WaterSourceUUID', 'WaterSourceTypeCV']], left_on='WaterSourceUUIDs', right_on='WaterSourceUUID', how='left')\n",
    "print(dfs['WaterSourceTypeCV'].unique()) # check WaterSourceTypeCV for unique values for\n",
    "print(len(dfs))\n",
    "dfs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6312364",
   "metadata": {},
   "source": [
    "## Extract RegulatoryOverlay from Reporting Units and assing to WR Sites\n",
    "- repeat scripts based on the number of ReportingUnitTypeCV types.\n",
    "- merge all geo-dataframes into one output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166df3a0",
   "metadata": {},
   "source": [
    "#### Regulatory Area Data #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of reportingunits dataframe\n",
    "# Extract out ReportingUnitTypeCV from reportingunits dataframe\n",
    "# note unique WaterSourceTypeCV\n",
    "\n",
    "dfru1 = dfru.copy()\n",
    "nameOfReportingUnitTypeVar = \"add name here\" # change here for ReportingUnitTypeCV of interest\n",
    "dfru1 = dfru1[dfru1['OverlayTypeCV'] == nameOfReportingUnitTypeVar]\n",
    "print(len(dfru1))\n",
    "print(dfru1['WaterSourceTypeCV'].unique())\n",
    "dfru1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c04405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe -to- geodataframe & plot\n",
    "contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "\n",
    "dfru1 = dfru1[dfru1['Geometry'] != \"\"].reset_index(drop=True)\n",
    "dfru1['Geometry'] = gpd.GeoSeries.from_wkt(dfru1['Geometry'], crs=\"EPSG:4326\")\n",
    "gdfru1 = gpd.GeoDataFrame(dfru1, geometry=dfru1['Geometry'], crs=\"EPSG:4326\") # covert to geodataframe\n",
    "gplt.polyplot(gdfru1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of water right sites dataframe\n",
    "# Extract out WaterSourceTypeCV and match to that of above reportingunits dataframe\n",
    "\n",
    "dfs1 = dfs.copy()\n",
    "nameOfWaterSourceTypeCV= \"add name here\" # change here for WaterSourceTypeCV of interest\n",
    "dfs1 = dfs1[dfs1['WaterSourceTypeCV'] == nameOfWaterSourceTypeCV]\n",
    "dfs1 = dfs1[dfs1['PODorPOUSite'] == 'POD']\n",
    "print(len(dfs1))\n",
    "print(dfs1['WaterSourceTypeCV'].unique())\n",
    "dfs1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765401a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert extracted water right sites -to- geodataframe & plot\n",
    "contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "\n",
    "gdfs1 = gpd.GeoDataFrame(dfs1, geometry=gpd.points_from_xy(dfs1.Longitude.astype(float), dfs1.Latitude.astype(float)), crs=\"EPSG:4326\")\n",
    "gplt.pointplot(gdfs1, hue='WaterSourceTypeCV', legend=True, legend_var='hue', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1473534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sites within polygon.\n",
    "gdfs1_ru1 = gpd.sjoin(left_df=gdfs1, right_df=gdfru1[['ReportingUnitUUID', 'OverlayUUID ', 'geometry']], op='within').replace(np.nan, \"\")\n",
    "print(len(gdfs1_ru1))\n",
    "gdfs1_ru1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bdf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the selected points\n",
    "contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "\n",
    "gplt.pointplot(gdfs1_ru1, hue='WaterSourceTypeCV', legend=True, legend_var='hue', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66216012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set OverlayUUIDs\n",
    "gdfs1_ru1['OverlayUUIDs'] = gdfs1_ru1['OverlayUUID ']\n",
    "gdfs1_ru1 = gdfs1_ru1.drop(['OverlayUUID ', 'geometry', 'index_right', 'ReportingUnitUUID', 'WaterSourceUUID', 'WaterSourceTypeCV'], axis=1)\n",
    "gdfs1_ru1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bbf31",
   "metadata": {},
   "source": [
    "#### Regulatory Area Data #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfru2 = dfru.copy()\n",
    "# etc etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a1916",
   "metadata": {},
   "source": [
    "## Concatenate all Regulatory Area Data Types together\n",
    "- drop geometry from the wade wr sites.csv geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acd398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes into single output\n",
    "frames = [dfs, gdfs1_ru1] # list all out dataframes here\n",
    "outdfs = pd.concat(frames)\n",
    "outdfs = outdfs.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "outdfs = outdfs.groupby('SiteUUID').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem != \"\"])).replace(np.nan, \"\").reset_index()\n",
    "print(len(outdfs))\n",
    "outdfs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3760f8b9",
   "metadata": {},
   "source": [
    "# Inspect Output Data & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aae641",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdfs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0289257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26339f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out to CSV.\n",
    "outdfs.to_csv('ProcessedInputData/sites.csv', index=False) # this is in the Regulatory data folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
