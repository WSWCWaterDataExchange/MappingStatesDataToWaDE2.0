{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Arizona Allocation data for WaDEQA upload.\n",
    "Purpose:  To preprocess the Arizona data into one mail file for simple DataFrame creation and extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Arizona/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groundwater Data (POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input File - Well_Registry.csv\n",
    "fileInput = \"Groundwater/Well_Registry.zip\"\n",
    "dfgw = pd.read_csv(fileInput, compression='zip').replace(np.nan, \"\")\n",
    "\n",
    "if 'WaDEUUID' not in dfgw:\n",
    "    dfgw['WaDEUUID'] = \"azGW\" + dfgw.index.astype(str)\n",
    "    dfgw.to_csv('Groundwater/Well_Registry.zip', compression='zip', index=False)\n",
    "\n",
    "print(len(dfgw))\n",
    "dfgw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AZwr Groundwater PUMPRATE is in GPM, need to convert to CFS\n",
    "# 448.8 CFS = 1 GPM\n",
    "\n",
    "# Clean owner name up\n",
    "def ConvertGPMToCFSFunc(Val):\n",
    "    Val = Val / 448.8 \n",
    "    return Val\n",
    "\n",
    "dfgw['PUMPRATE'] = dfgw.apply(lambda row: ConvertGPMToCFSFunc(row['PUMPRATE']), axis=1)\n",
    "dfgw['PUMPRATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfgw['WaDEUUID']\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\" # create customID for temp solution\n",
    "df['in_WaterSourceTypeCV'] = \"Groundwater\"\n",
    "\n",
    "# Site Info\n",
    "df['in_RegulatoryOverlayUUIDs'] = \"\"\n",
    "df['in_WaterSourceUUID'] = \"\" # ???\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = dfgw['COUNTY'].str.title()\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfgw['latitude']\n",
    "df['in_Longitude'] = dfgw['longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"POD\" + dfgw['CADASTRAL'].replace(\"\", 0).fillna(0).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"Well\" # these should all be well records\n",
    "df['in_StateCV'] = \"AZ\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_MethodUUID'] = \"AZwr_M1\" # for goundwater\n",
    "df['in_OrganizationUUID'] = \"AZwr_O1\"\n",
    "df['in_SiteUUID'] = \"\" # ???\n",
    "df['in_VariableSpecificUUID'] =  \"AZwr_V1\" # for CFS\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfgw['PUMPRATE'].astype(float)\n",
    "df['in_AllocationLegalStatusCV'] = \"\"\n",
    "df['in_AllocationNativeID'] =  dfgw['REGISTRY_I'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_AllocationOwner'] = dfgw['OWNER_NAME']\n",
    "df['in_AllocationPriorityDate'] = \"\"\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"12/31\"\n",
    "df['in_AllocationTimeframeStart'] = \"01/01\"\n",
    "#df['in_AllocationTypeCV'] = dfgw['WELL_TYPE_'] # skip for now\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = \"\"\n",
    "df['in_BeneficialUseCategory'] = dfgw['WATER_USE'].str.title()\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 1 # all these gw records should be considered exempt for us.\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = \"https://app.azwater.gov/WellRegistry/Detail.aspx?\" + dfgw['REGISTRY_I'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "\n",
    "dfgwOut = df.copy()\n",
    "print(len(dfgwOut))\n",
    "dfgwOut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Water Data (POD & POU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input files - Surface Water Query by Watershed water records\n",
    "\n",
    "# Surface Water Query by Watershed water record inputs.\n",
    "csv_file_list = [\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/AGUA FRIA RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/BILL WILLIAMS RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/COLORADO RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/LITTLE COLORADO RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/LOWER GILA RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/RIO YAQUI.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/SALT RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/SAN PEDRO RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/SAN SIMON RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/SANTA CRUZ RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/UPPER GILA RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/VERDE RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/VIRGIN RIVER.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/WHITE WATER DRAW.zip\",\n",
    "    \"Surface Water/SW QUERY BY SURFACE WATERSHEDS/WILLCOX PLAYA.zip\"]\n",
    "\n",
    "\n",
    "list_of_dataframes = []\n",
    "for filename in csv_file_list:\n",
    "    list_of_dataframes.append(pd.read_csv(filename, compression='zip'))\n",
    "\n",
    "dfsw = pd.concat(list_of_dataframes).replace(np.nan, \"\").drop_duplicates().reset_index(drop=True)\n",
    "dfsw = dfsw.drop(['LEGAL'], axis=1).drop_duplicates().reset_index(drop=True) # drop 'LEGAL', not needed.\n",
    "\n",
    "if 'WaDEUUID' not in dfsw:\n",
    "    dfsw['WaDEUUID'] = \"azSW\" + dfsw.index.astype(str)\n",
    "    dfsw.to_csv('Surface Water/SW_QUERY_COMBINED.zip', compression=dict(method='zip', archive_name='SW_QUERY_COMBINED.csv'), index=False) \n",
    "\n",
    "    \n",
    "dfsw = dfsw.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(dfsw))\n",
    "dfsw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing 'REG. NO' format to match 'FILNO' in FILINGS shp file.\n",
    "\n",
    "def fixREGNO(val):\n",
    "   \n",
    "    ### first fix\n",
    "    # Create testVal to search for length, split on '-' & '.'\n",
    "    testVal = str(val).strip()\n",
    "    sep1 = '-'\n",
    "    testVal = testVal.split(sep1, 1)[1]\n",
    "    sep2 = '.'\n",
    "    testVal = testVal.split(sep2, 1)[0]\n",
    "    \n",
    "    # inerst new text into 'val' based on 'testVal' length.\n",
    "    if len(testVal) == 2:\n",
    "        val = val.replace(\"-\", \"-0000\")\n",
    "    if len(testVal) == 3:\n",
    "        val = val.replace(\"-\", \"-000\")\n",
    "    if len(testVal) == 4:\n",
    "        val = val.replace(\"-\", \"-00\")\n",
    "    if len(testVal) == 5:\n",
    "        val = val.replace(\"-\", \"-0\")\n",
    "        \n",
    "        \n",
    "    ### second fix\n",
    "    # Create testVal to search for length, split on '.' at the end\n",
    "    testVal = str(val).strip()\n",
    "    sep1 = '.'\n",
    "    testVal = testVal.split(sep1, 1)[1]\n",
    "    \n",
    "    # inerst new text into 'val' based on 'testVal' length.\n",
    "    if len(testVal) == 1:\n",
    "        val = val.replace(\".\", \".00\" + testVal)\n",
    "    if len(testVal) == 2:\n",
    "        val = val.replace(\".\", \".0\" + testVal)   \n",
    "    \n",
    "    return val\n",
    "\n",
    "dfsw['REG. NO'] = dfsw.apply(lambda row: fixREGNO(row['REG. NO']), axis=1)\n",
    "exList = dfsw['REG. NO'].unique().tolist()\n",
    "exList.sort()\n",
    "for x in exList:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input files - Fillings Layers.shp\n",
    "\n",
    "#POD layer\n",
    "fileName = \"Surface Water/shapefile/FilingPOD.zip\"\n",
    "df_PODfill = pd.read_csv(fileName, compression='zip')\n",
    "\n",
    "#POU layer\n",
    "fileName = \"Surface Water/shapefile/FillingPOU.zip\"\n",
    "df_POUfill = pd.read_csv(fileName, compression='zip')\n",
    "\n",
    "# Concatenate dataframes\n",
    "frames = [df_PODfill, df_POUfill] # add dataframes here\n",
    "df_fill = pd.concat(frames)\n",
    "df_fill = df_fill.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(df_fill))\n",
    "df_fill.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Surface Water Query by Watershed water records with Filling.\n",
    "dfsw = pd.merge(dfsw, df_fill, left_on='REG. NO', right_on='FILENO', how='left')\n",
    "print(len(dfsw))\n",
    "dfsw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'QUANTITY' into 'Amount' and 'UNIT'\n",
    "dfsw[['Amount', 'Unit']] = dfsw.QUANTITY.str.split(\"  \", expand = True)\n",
    "dfsw['Amount'] = pd.to_numeric(dfsw['Amount'], errors='coerce').fillna(0).astype(float) # make sure this is numeric.\n",
    "dfsw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03/02/2023\n",
    "# temp fix - remove recods with these 'Units'\n",
    "dropList = ['ACRES',\n",
    "            'Amount Required for Maintenance',\n",
    "            'Feet',\n",
    "            'MIT - Miners Inches Total',\n",
    "            'Miners Inches Per Annum', \n",
    "            'XX - Unknown Code at Load time',\n",
    "            'None',\n",
    "            '',\n",
    "            \" \"]\n",
    "\n",
    "dfsw = dfsw[~dfsw['Unit'].isin(dropList)]\n",
    "print(len(dfsw))\n",
    "dfsw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to update to reflect groundwater values too\n",
    "# CFS = V1, AF = V2\n",
    "\n",
    "# Create VariableSpecificCv value\n",
    "def createVariableSpecificCv(unit):\n",
    "    outString = \"\"\n",
    "    if unit == \"Cubic Feet Per Second\":\n",
    "        outString = \"AZwr_V1\"\n",
    "    if unit == \"Acre-Feet Per Annum\":\n",
    "        outString = \"AZwr_V1\"\n",
    "    if unit == \"Gallons Per Annum\":\n",
    "        outString = \"AZwr_V1\"\n",
    "    else:\n",
    "        outString = \"AZwr_V2\"\n",
    "\n",
    "    return(outString)\n",
    "\n",
    "dfsw['in_VariableSpecificUUID'] = dfsw.apply(lambda row: createVariableSpecificCv(row['Unit']), axis=1)\n",
    "dfsw['in_VariableSpecificUUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all flow values to CFS\n",
    "def convertFlowFunc(val, unit):\n",
    "    CFS_Value = None\n",
    "    if unit == \"Cubic Feet Per Second\":\n",
    "        CFS_Value = val\n",
    "    if unit == \"Acre-Feet Per Annum\":\n",
    "        CFS_Value = val / (723.968)\n",
    "    if unit == \"Gallons Per Annum\":\n",
    "        CFS_Value = val / (235905662.34)\n",
    "    else:\n",
    "        CFS_Value = 0.0\n",
    "    return(CFS_Value)\n",
    "\n",
    "dfsw['CFS_Value'] = dfsw.apply(lambda row: convertFlowFunc(row['Amount'], row['Unit']), axis=1)\n",
    "dfsw['CFS_Value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all volume values to AF\n",
    "def convertVolumeFunc(val, unit):\n",
    "    AF_Value = None\n",
    "    if unit == 'Acre-Feet':\n",
    "        AF_Value = val\n",
    "    if unit == 'Acre-Feet Total':\n",
    "        AF_Value = val\n",
    "    if unit == \"CFT - Cubic Feet Total\":\n",
    "        AF_Value = val / (43559.9)\n",
    "    if unit == 'Gallons':\n",
    "        AF_Value = val / (325850.943)\n",
    "    else:\n",
    "        AF_Value = 0.0\n",
    "    return(AF_Value)\n",
    "\n",
    "dfsw['AF_Value'] = dfsw.apply(lambda row: convertVolumeFunc(row['Amount'], row['Unit']), axis=1)\n",
    "dfsw['AF_Value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating long and lat values from data.  \n",
    "# Need to convert from UTM 12N to WGS 84.\n",
    "# I believe AZ is consiered WGS 84 / UTM zone 12N - EPSG:32612.\n",
    "\n",
    "from pyproj import Proj\n",
    "myProj = Proj(proj='utm',zone=12, ellps='WGS84', preserve_units=False)\n",
    "long, lat = myProj(dfsw['X_UTMNAD83'].values, dfsw['Y_UTMNAD83'].values, inverse=True)\n",
    "dfsw['in_Latitude'] = lat\n",
    "dfsw['in_Longitude'] = long\n",
    "dfsw = dfsw.replace(np.nan, '')  # Replaces NaN values with blank.\n",
    "dfsw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfsw['WaDEUUID']\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfsw['WATERSOURC'].str.title()\n",
    "df['in_WaterSourceNativeID'] = \"\" # create customID for temp solution\n",
    "df['in_WaterSourceTypeCV'] = \"Surface Water\"\n",
    "\n",
    "# Site Info\n",
    "df['in_RegulatoryOverlayUUIDs'] = \"\"\n",
    "df['in_WaterSourceUUID'] = \"\" # ???\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = dfsw['COUNTY'].str.title()\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfsw['in_Latitude']\n",
    "df['in_Longitude'] = dfsw['in_Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = dfsw['POU_POD']\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = dfsw['POU_POD'].str.strip() + dfsw['CADASTRAL'].replace(\"\", 0).fillna(0).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"AZ\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_MethodUUID'] = \"AZwr_M2\" # for surface water\n",
    "df['in_OrganizationUUID'] = \"AZwr_O1\"\n",
    "df['in_SiteUUID'] = \"\" # ???\n",
    "df['in_VariableSpecificUUID'] =  dfsw['in_VariableSpecificUUID']\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfsw['CFS_Value'].astype(float) # see above for conversion\n",
    "df['in_AllocationLegalStatusCV'] = dfsw['STATUS_x'].str.title()\n",
    "df['in_AllocationNativeID'] =  dfsw['REG. NO'].replace(\"\", 0).fillna(0).astype(str)\n",
    "df['in_AllocationOwner'] = dfsw['NAME']\n",
    "df['in_AllocationPriorityDate'] = dfsw['PRIOR DATE']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"12/31\"\n",
    "df['in_AllocationTimeframeStart'] = \"01/01\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfsw['AF_Value'].astype(float) # see above for conversion\n",
    "df['in_BeneficialUseCategory'] = dfsw['WATER USE'].str.title()\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = \"\"\n",
    "\n",
    "dfswOut = df.copy()\n",
    "print(len(dfswOut))\n",
    "dfswOut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate GW with SW dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dfgwOut, dfswOut] # add dataframes here\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean output dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean owner name up\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).title().strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: ensureEmptyString(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationLegalStatusCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Longitude\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str) + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop non-Active AllocationLegalStatusCV Water Rights\n",
    "- For this ADWR, we don't want water rights that are considered: \"INACTIVE - WITHDRAWN\",\n",
    "                       \"INACTIVE - CONSOLIDATED\",\n",
    "                       \"INACTIVE - AMENDED\",\n",
    "                       \"INACTIVE - CANCELLED\",\n",
    "                       \"INACTIVE - REJECTED\",\n",
    "                       \"INACTIVE - PARTIAL T&S\",\n",
    "                       \"INACTIVE - RELINQUISHED\",\n",
    "                       \"INACTIVE - FULL T&S\",\n",
    "                       \"INACTIVE - INACTIVE\",\n",
    "                       \"INACTIVE - FULL ASSIGNMENT\",\n",
    "                       \"INACTIVE - PARTIAL ASSIGNMENT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-active AllocationLegalStatusCV values specific to that state.\n",
    "\n",
    "# drop the list\n",
    "dropLegalStatusList = [\"INACTIVE - WITHDRAWN\",\n",
    "                       \"INACTIVE - CONSOLIDATED\",\n",
    "                       \"INACTIVE - AMENDED\",\n",
    "                       \"INACTIVE - CANCELLED\",\n",
    "                       \"INACTIVE - REJECTED\",\n",
    "                       \"INACTIVE - PARTIAL T&S\",\n",
    "                       \"INACTIVE - RELINQUISHED\",\n",
    "                       \"INACTIVE - FULL T&S\",\n",
    "                       \"INACTIVE - INACTIVE\",\n",
    "                       \"INACTIVE - FULL ASSIGNMENT\",\n",
    "                       \"INACTIVE - PARTIAL ASSIGNMENT\"] # enter string entries here\n",
    "\n",
    "# drop rows from above list\n",
    "outdf = outdf[outdf.in_AllocationLegalStatusCV.isin(dropLegalStatusList) == False].reset_index(drop=True)\n",
    "\n",
    "print(len(outdf))\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no shp file data to work with AZ wr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PoU Shapefile Data\n",
    "# shapefileInput = \"RawInputData/shapefiles/{enter file name here}.zip\" # ziped folder of the shp file\n",
    "# dfPoUshapetemp = gpd.read_file(shapefileInput)\n",
    "# print(len(dfPoUshapetemp))\n",
    "# dfPoUshapetemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create temp dataframe to hold native ID and geometry from shapefile input\n",
    "# columnsList = ['in_SiteNativeID', 'geometry']\n",
    "# dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "\n",
    "# # assing values to temp dataframe based on shapefile input\n",
    "# # for in_SiteNativeID assure ID value is the same as that listed above for POU info.\n",
    "# dfPoUshape['in_SiteNativeID'] = \"POU\" + \"\"\n",
    "# dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "# dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "# print(len(dfPoUshape))\n",
    "# dfPoUshape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('Pwr_azMain.zip', compression=dict(method='zip', archive_name='Pwr_azMain.csv'), index=False) # The output, save as a zip\n",
    "#dfPoUshape.to_csv('P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
