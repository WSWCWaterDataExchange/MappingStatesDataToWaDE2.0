{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing CA Site-Specific Public Supply Time Series Water Use data for WaDE Upload\n",
    "- Purpose:  To pre-process the data into one main file for simple DataFrame creation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"G:/Shared drives/WaDE Data/California/SS_PublicSupplyWaterUse\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - delivered-wate\n",
    "fileInput = \"RawInputData/delivered-water-public-system-water-reported-in-the-electronic-annual-report-ear-2013-2016.zip\"\n",
    "dfin1 = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin1:\n",
    "    dfin1['WaDEUUID'] = \"in1\" + dfin1.index.astype(str)\n",
    "    dfin1.to_csv(\"RawInputData/delivered-water-public-system-water-reported-in-the-electronic-annual-report-ear-2013-2016.zip\", compression=dict(method='zip', archive_name=\"delivered-water-public-system-water-reported-in-the-electronic-annual-report-ear-2013-2016.csv\"), index=False)\n",
    "\n",
    "dfin1['PWSID'] = dfin1['PWSID'].astype(str).str.strip()\n",
    "print(len(dfin1))\n",
    "dfin1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - produced-water\n",
    "fileInput = \"RawInputData/produced-water-public-water-system-reported-in-the-electronic-annual-report-ear-2013-2016.zip\"\n",
    "dfin2 = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin2:\n",
    "    dfin2['WaDEUUID'] = \"in2\" + dfin2.index.astype(str)\n",
    "    dfin2.to_csv(\"RawInputData/produced-water-public-water-system-reported-in-the-electronic-annual-report-ear-2013-2016.zip\", compression=dict(method='zip', archive_name=\"produced-water-public-water-system-reported-in-the-electronic-annual-report-ear-2013-2016.csv\"), index=False)\n",
    "\n",
    "dfin2['PWSID'] = dfin2['PWSID'].astype(str).str.strip()\n",
    "print(len(dfin2))\n",
    "dfin2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - Drinking Water Watch - Public Water System facilities (DWWPWSF)\n",
    "fileInput = \"RawInputData/Drinking Water Watch - Public Water System facilities.zip\"\n",
    "dfin3 = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin3:\n",
    "    dfin3['WaDEUUID'] = \"in3\" + dfin3.index.astype(str)\n",
    "    dfin3.to_csv(\"RawInputData/Drinking Water Watch - Public Water System facilities.zip\", compression=dict(method='zip', archive_name=\"Drinking Water Watch - Public Water System facilities.csv\"), index=False)\n",
    "\n",
    "dfin3['Water System No'] = dfin3['Water System No'].astype(str).str.strip()\n",
    "print(len(dfin3))\n",
    "dfin3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - California_Drinking_Water_System_Area_Boundaries (CDWSAB) shp file info\n",
    "shapefileInput = \"RawInputData/California_Drinking_Water_System_Area_Boundaries.zip\" # ziped folder of the shp file\n",
    "dfPoUshapetemp = gpd.read_file(shapefileInput).replace(np.nan, \"\")\n",
    "dfPoUshapetemp['SABL_PWSID'] = dfPoUshapetemp['SABL_PWSID'].astype(str).str.strip()\n",
    "\n",
    "dfPoUshapetemp['geometry'] = dfPoUshapetemp['geometry'].to_crs(epsg=4326) # Realign Geometry Projection\n",
    "dfPoUshapetemp[\"cent_lattitude\"] = dfPoUshapetemp.centroid.y\n",
    "dfPoUshapetemp[\"cent_longitude\"] = dfPoUshapetemp.centroid.x\n",
    "dfPoUshapetemp.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delivered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left merge DWWPWSF to delivered ts\n",
    "# left merge CDWSAB to delivered ts\n",
    "dftemp = pd.DataFrame()\n",
    "dftemp = dfin1.merge(dfin3[['Water System No', 'Primary Water Source Type', 'State Water System Type']], left_on='PWSID', right_on='Water System No', how='left').replace(np.nan, \"\")\n",
    "dftemp = dftemp.merge(dfPoUshapetemp[['SABL_PWSID', 'WATER_SY_1', 'BOUNDARY_T', 'COUNTY', 'cent_lattitude', 'cent_longitude']], left_on='PWSID', right_on='SABL_PWSID', how='left').replace(np.nan, \"\")\n",
    "\n",
    "print(len(dftemp))\n",
    "dftemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop data list.  Use this to search for specific fields.\n",
    "amountList = ['WATER DELIVERIES TO Single.family.Residential',\n",
    "'WATER DELIVERIES TO Multi.family.Residential',\n",
    "'WATER DELIVERIES TO Commercial.Institutional',\n",
    "'WATER DELIVERIES TO Industrial',\n",
    "'WATER DELIVERIES TO Landscape.Irrigation',\n",
    "'WATER DELIVERIES TO Other',\n",
    "'WATER DELIVERIES TO Agricultural',\n",
    "'WATER DELIVERIES TO Other.PWS']\n",
    "\n",
    "benUseList = ['Single Family Residential', \n",
    "              'Multi Family Residential',\n",
    "              'Commercial / Institutional',\n",
    "              'Industrial',\n",
    "              'Landscape Irrigation',\n",
    "              'Other',\n",
    "              'Agricultural',\n",
    "              'Other PWS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "outdf1 = pd.DataFrame()\n",
    "\n",
    "# for each value in variableTypeList\n",
    "for x in range(len(amountList)):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "   \n",
    "    # Data Assessment UUID\n",
    "    df['WaDEUUID'] = dftemp['WaDEUUID']\n",
    "\n",
    "    # Method Info\n",
    "    df['in_MethodUUID'] = \"CAssps_M1\"\n",
    "    \n",
    "    # Variable Info\n",
    "    df['in_VariableCV'] = \"Cumulative Delivered\"\n",
    "    df['in_AggregationIntervalUnitCV'] = \"Monthly\"\n",
    "    df['in_VariableSpecificUUID'] = \"\" # will create sa portion below\n",
    "\n",
    "    \n",
    "    # Organization Info\n",
    "    df['in_OrganizationUUID'] = \"CAssps_O1\"\n",
    "    \n",
    "    # WaterSource Info\n",
    "    df['in_Geometry'] = \"\"\n",
    "    df['in_GNISFeatureNameCV'] = \"\"\n",
    "    df['in_WaterQualityIndicatorCV'] = \"Fresh\"\n",
    "    df['in_WaterSourceName'] = \"WaDE Blank\" # need this for auto fill below\n",
    "    df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "    df['in_WaterSourceTypeCV'] = dftemp['Primary Water Source Type']\n",
    "    \n",
    "    # Site Info\n",
    "    df['in_CoordinateAccuracy'] = \"\"\n",
    "    df['in_CoordinateMethodCV'] = \"Centroid of Area\"\n",
    "    df['in_County'] = dftemp['COUNTY']\n",
    "    df['in_EPSGCodeCV'] = 4326\n",
    "    df['in_Geometry'] = \"\"\n",
    "    df['in_GNISCodeCV'] = \"\"\n",
    "    df['in_HUC12'] = \"\"\n",
    "    df['in_HUC8'] = \"\"\n",
    "    df['in_Latitude'] = dftemp['cent_lattitude']\n",
    "    df['in_Longitude'] = dftemp['cent_longitude']\n",
    "    df['in_NHDNetworkStatusCV'] = \"\"\n",
    "    df['in_NHDProductCV'] = \"\"\n",
    "    df['in_PODorPOUSite'] = \"POU\"\n",
    "    df['in_SiteName'] = dftemp['WATER_SY_1']\n",
    "    df['in_SiteNativeID'] = dftemp['SABL_PWSID'].astype(str)\n",
    "    df['in_SitePoint'] = \"\"\n",
    "    df['in_SiteTypeCV'] = dftemp['BOUNDARY_T']\n",
    "    df['in_StateCV'] = \"CA\"\n",
    "    df['in_USGSSiteID'] = \"\"\n",
    "       \n",
    "    # Site VariableAmounts Info\n",
    "    df['temp1_WaterUnits'] = dftemp['Delivered.Water.Units AS ORIGINALLY REPORTED']\n",
    "    df['temp2_WaterUnits'] = dftemp['Delivered.Water.Units.Revised BY OFFICE OF INFORMATION MANAGEMENT AND ANALYSIS'] # to check units on amounts\n",
    "    df['temp_unitCheck'] = dftemp['UNITS ADJUSTED BY OIMA?']\n",
    "    df['in_Amount'] = dftemp[amountList[x]]\n",
    "    \n",
    "    df['in_AllocationCropDutyAmount'] = \"\"\n",
    "    df['in_AssociatedNativeAllocationIDs'] = \"\"\n",
    "    df['in_BeneficialUseCategory'] = benUseList[x]\n",
    "    df['in_CommunityWaterSupplySystem'] = dftemp['Water.System.Name']\n",
    "    df['in_CropTypeCV'] = \"\"\n",
    "    df['in_CustomerTypeCV'] = dftemp['State Water System Type']\n",
    "    df['in_DataPublicationDate'] = \"\"\n",
    "    df['in_DataPublicationDOI'] = \"\"\n",
    "    df['in_Geometry'] = \"\"\n",
    "    df['in_IrrigatedAcreage'] = \"\"\n",
    "    df['in_IrrigationMethodCV'] = \"\"\n",
    "    df['in_PopulationServed'] = dftemp['Population Of Service Area']\n",
    "    df['in_PowerGeneratedGWh'] = \"\"\n",
    "    df['in_PowerType'] = \"\"\n",
    "    df['in_PrimaryUseCategory'] = \"\" # auto fill in below\n",
    "    df['in_ReportYearCV'] =  dftemp['Year'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "    df['in_SDWISIdentifier'] = \"\"\n",
    "    df['temp_Month'] = dftemp['Month'] #temp to get string of month name\n",
    "    df['temp_DaysInMonth'] = dftemp['Days.In.Month']  #temp to get last data of that month\n",
    "    df['in_TimeframeEnd'] = \"\" # will fix below using Month and DaysInMonth\n",
    "    df['in_TimeframeStart'] = dftemp['Date']\n",
    "\n",
    "    outdf1 = pd.concat([outdf1, df])\n",
    "\n",
    "outdf1 = outdf1.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdf1))\n",
    "outdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### produced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left merge DWWPWSF to delivered ts\n",
    "# left merge CDWSAB to delivered ts\n",
    "dftemp = pd.DataFrame()\n",
    "dftemp = dfin2.merge(dfin3[['Water System No', 'Primary Water Source Type', 'State Water System Type']], left_on='PWSID', right_on='Water System No', how='left').replace(np.nan, \"\")\n",
    "dftemp = dftemp.merge(dfPoUshapetemp[['SABL_PWSID', 'WATER_SY_1', 'BOUNDARY_T', 'COUNTY', 'cent_lattitude', 'cent_longitude']], left_on='PWSID', right_on='SABL_PWSID', how='left').replace(np.nan, \"\")\n",
    "\n",
    "print(len(dftemp))\n",
    "dftemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop data list.  Use this to search for specific fields.\n",
    "amountList = ['WATER PRODUCED FROM GROUNDWATER',\n",
    "'WATER PRODUCED FROM SURFACE WATER',\n",
    "'FINSIHIED WATER PURCHASED OR RECEIVED FROM ANOTHER PUBLIC WATER SYSTEM',\n",
    "'WATER SOLD TO ANOTHER PUBLIC WATER SYSTEM',\n",
    "'Non-Potable Produced Water (EXCLUDING RECYCLING)',\n",
    "'RECYCLED WATER PRODUCED']\n",
    "\n",
    "benUseList = ['Produced from Groundwater',\n",
    "'Produced from Surface Water',\n",
    "'Purchased from another PWS',\n",
    "'Sold to another PWS',\n",
    "'Non-Potable',\n",
    "'Recycled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "outdf2 = pd.DataFrame()\n",
    "\n",
    "# for each value in variableTypeList\n",
    "for x in range(len(amountList)):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "   \n",
    "    # Data Assessment UUID\n",
    "    df['WaDEUUID'] = dftemp['WaDEUUID']\n",
    "\n",
    "    # Method Info\n",
    "    df['in_MethodUUID'] = \"CAssps_M1\"\n",
    "    \n",
    "     # Variable Info\n",
    "    df['in_VariableCV'] = \"Cumulative Produced\"\n",
    "    df['in_AggregationIntervalUnitCV'] = \"Monthly\"\n",
    "    df['in_VariableSpecificUUID'] = \"\" # will create sa portion below\n",
    "    \n",
    "    # Organization Info\n",
    "    df['in_OrganizationUUID'] = \"CAssps_O1\"\n",
    "    \n",
    "    # WaterSource Info\n",
    "    df['in_Geometry'] = \"\"\n",
    "    df['in_GNISFeatureNameCV'] = \"\"\n",
    "    df['in_WaterQualityIndicatorCV'] = \"Fresh\"\n",
    "    df['in_WaterSourceName'] = \"WaDE Blank\" # need this for auto fill below\n",
    "    df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "    df['in_WaterSourceTypeCV'] = dftemp['Primary Water Source Type']\n",
    "    \n",
    "    # Site Info\n",
    "    df['in_CoordinateAccuracy'] = \"\"\n",
    "    df['in_CoordinateMethodCV'] = \"Centroid of Area\"\n",
    "    df['in_County'] = dftemp['COUNTY']\n",
    "    df['in_EPSGCodeCV'] = 4326\n",
    "    df['in_Geometry'] = \"\"\n",
    "    df['in_GNISCodeCV'] = \"\"\n",
    "    df['in_HUC12'] = \"\"\n",
    "    df['in_HUC8'] = \"\"\n",
    "    df['in_Latitude'] = dftemp['cent_lattitude']\n",
    "    df['in_Longitude'] = dftemp['cent_longitude']\n",
    "    df['in_NHDNetworkStatusCV'] = \"\"\n",
    "    df['in_NHDProductCV'] = \"\"\n",
    "    df['in_PODorPOUSite'] = \"POU\"\n",
    "    df['in_SiteName'] = dftemp['WATER_SY_1']\n",
    "    df['in_SiteNativeID'] = dftemp['SABL_PWSID'].astype(str)\n",
    "    df['in_SitePoint'] = \"\"\n",
    "    df['in_SiteTypeCV'] = dftemp['BOUNDARY_T']\n",
    "    df['in_StateCV'] = \"CA\"\n",
    "    df['in_USGSSiteID'] = \"\"\n",
    "       \n",
    "    # Site VariableAmounts Info\n",
    "    df['temp1_WaterUnits'] = dftemp['WATER PRODUCED Water.Units IN UNITS ORIGINALLY REPORTED']\n",
    "    df['temp2_WaterUnits'] = dftemp['WATER PRODUCED Water.Units REVIEWED BY OFFICE OF INFORMATION MANAGEMENT AND ANALYSIS'] # to check units on amounts\n",
    "    df['temp_unitCheck'] = dftemp['UNITS ADJUSTED BY OIMA?']\n",
    "    df['in_Amount'] = dftemp[amountList[x]]\n",
    "\n",
    "    df['in_AllocationCropDutyAmount'] = \"\"\n",
    "    df['in_AssociatedNativeAllocationIDs'] = \"\"\n",
    "    df['in_BeneficialUseCategory'] = benUseList[x]\n",
    "    df['in_CommunityWaterSupplySystem'] = dftemp['Water.System.Name']\n",
    "    df['in_CropTypeCV'] = \"\"\n",
    "    df['in_CustomerTypeCV'] = dftemp['State Water System Type']\n",
    "    df['in_DataPublicationDate'] = \"\"\n",
    "    df['in_DataPublicationDOI'] = \"\"\n",
    "    df['in_Geometry'] = \"\"\n",
    "    df['in_IrrigatedAcreage'] = \"\"\n",
    "    df['in_IrrigationMethodCV'] = \"\"\n",
    "    df['in_PopulationServed'] = dftemp['Population Of Service Area']\n",
    "    df['in_PowerGeneratedGWh'] = \"\"\n",
    "    df['in_PowerType'] = \"\"\n",
    "    df['in_PrimaryUseCategory'] = \"\" # auto fill in below\n",
    "    df['in_ReportYearCV'] =  dftemp['Year'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "    df['in_SDWISIdentifier'] = \"\"\n",
    "    df['temp_Month'] = dftemp['Month'] #temp to get string of month name\n",
    "    df['temp_DaysInMonth'] = dftemp['Days.In.Month']  #temp to get last data of that month\n",
    "    df['in_TimeframeEnd'] = \"\" # will fix below using Month and DaysInMonth\n",
    "    df['in_TimeframeStart'] = dftemp['Date']\n",
    "\n",
    "    outdf2 = pd.concat([outdf2, df])\n",
    "\n",
    "outdf2 = outdf2.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdf2))\n",
    "outdf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU Data.  Make needed changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outdf1, outdf2]  # list all out dataframes here\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix blank / null WaterSourcetypeCV\n",
    "# simplify to WaDE specific categories\n",
    "\n",
    "wsTypeDict = {\n",
    "    \"Groundwater\" : \"Groundwater\",\n",
    "    \"Groundwater Purchased\" : \"Groundwater\",\n",
    "    \"Groundwater UDI Surface Water\" : \"Groundwater\",\n",
    "    \"Surface Water\" : \"Surface Water\",\n",
    "    \"Surface Water Purchased\" : \"Surface Water\"}\n",
    "\n",
    "def fixWaterSourceTypeCV(valA):\n",
    "    valA = str(valA).strip()\n",
    "    if valA == \"\" or pd.isnull(valA):\n",
    "        outString = \"WaDE Blank\"\n",
    "    else:\n",
    "        try:\n",
    "            outString = wsTypeDict[valA]\n",
    "        except:\n",
    "            outString = \"WaDE Blank\"\n",
    "    return outString\n",
    "\n",
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: fixWaterSourceTypeCV(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating amount value for based on units. Convert to gallons from input unit.\n",
    "\n",
    "# Issue of some entries are strings. Fix unit type to float\n",
    "outdf['in_Amount'] = outdf['in_Amount'].replace('-','', regex=True)\n",
    "outdf['in_Amount'] = outdf['in_Amount'].replace(',','', regex=True)\n",
    "outdf['in_Amount'] = outdf['in_Amount'].replace('FALSE','', regex=True)\n",
    "outdf['in_Amount'] = outdf['in_Amount'].astype(str).str.strip()\n",
    "outdf['in_Amount'] = pd.to_numeric(outdf['in_Amount'])\n",
    "\n",
    "def createAmountGallon(check, unit1, unit2, val):\n",
    "    outVal = val # default\n",
    "    check = str(check).strip()\n",
    "    \n",
    "    if check == 'NO CHANGES':\n",
    "        unit = str(unit1).strip()\n",
    "    else:\n",
    "        unit = str(unit2).strip()\n",
    "\n",
    "\n",
    "    if unit == 'AF':\n",
    "        outVal = val * 325851\n",
    "    if unit == 'MG':\n",
    "        outVal = val * 1000000\n",
    "    if unit == 'TG':\n",
    "        outVal = val * 1000\n",
    "    if unit == 'HG':\n",
    "        outVal = val * 100\n",
    "    if unit == 'DG':\n",
    "        outVal = val * 10\n",
    "    if unit == 'CCF':\n",
    "        outVal = val * 748.052\n",
    "    if unit == 'CF':\n",
    "        outVal = val * 7.48052\n",
    "    if unit == '-':\n",
    "        outVal = val\n",
    "    \n",
    "    return outVal\n",
    "\n",
    "outdf['in_Amount'] = outdf.apply(lambda row: createAmountGallon(row['temp_unitCheck'], row['temp1_WaterUnits'], row['temp2_WaterUnits'], row['in_Amount']), axis=1)\n",
    "outdf['in_Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WaDE TimeframeEnd\n",
    "\n",
    "MonthDictionary = {\n",
    "\"January\" : \"01\",\n",
    "\"February\" : \"02\",\n",
    "\"March\" : \"03\",\n",
    "\"April\" : \"04\",\n",
    "\"May\" : \"05\",\n",
    "\"June\" : \"06\",\n",
    "\"July\" : \"07\",\n",
    "\"August\" : \"08\",\n",
    "\"September\" : \"09\",\n",
    "\"October\" : \"10\",\n",
    "\"November\" : \"11\",\n",
    "\"December\" : \"12\"}\n",
    "\n",
    "def createTimeframeEnd(Year, Month, Day):\n",
    "    yearString = str(Year).strip()\n",
    "    monthString = str(MonthDictionary[str(Month).strip()]).strip()\n",
    "    dayString = str(Day).strip()\n",
    "    try:\n",
    "        outString = yearString + \"/\" + monthString + \"/\" + dayString\n",
    "    except:\n",
    "        outString = ''\n",
    "    return outString\n",
    "\n",
    "outdf['in_TimeframeEnd'] = outdf.apply(lambda row: createTimeframeEnd(row['in_ReportYearCV'], row['temp_Month'], row['temp_DaysInMonth']), axis=1)\n",
    "outdf['in_TimeframeEnd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can remove ',' from this project\n",
    "\n",
    "# Clean name entries of spcial characters\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_CommunityWaterSupplySystem'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_CommunityWaterSupplySystem']), axis=1)\n",
    "outdf['in_CommunityWaterSupplySystem'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: ensureEmptyString(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_CommunityWaterSupplySystem'] = outdf.apply(lambda row: ensureEmptyString(row['in_CommunityWaterSupplySystem']), axis=1)\n",
    "outdf['in_CommunityWaterSupplySystem'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "uniqueList = list(set([i.strip() for i in ','.join(outdf['in_BeneficialUseCategory'].astype(str)).split(',')]))\n",
    "uniqueList.sort()\n",
    "uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Latitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Longitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Amount entry is either numireic or blank, no 0 entries\n",
    "outdf['in_Amount'] = pd.to_numeric(outdf['in_Amount'], errors='coerce').round(2).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure PopulationServed entry is numireic WITH 0 entries (no blank strings)\n",
    "outdf['in_PopulationServed'] = pd.to_numeric(outdf['in_PopulationServed'], errors='coerce').round().replace(\"\",0).fillna(0).astype(int).astype(str)\n",
    "outdf['in_PopulationServed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeEnd to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf['in_TimeframeEnd'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeEnd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeStart to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf['in_TimeframeStart'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeStart'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year out\n",
    "outdf['in_ReportYearCV'] = outdf['in_ReportYearCV'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "outdf['in_ReportYearCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Primary Use Category\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/rjame/Documents/WSWC Documents/MappingStatesDataToWaDE2.0/5_CustomFunctions/AssignPrimaryUseCategory\")\n",
    "import AssignPrimaryUseCategoryFile # Use Custom import file\n",
    "\n",
    "outdf['in_PrimaryUseCategory'] = outdf.apply(lambda row: AssignPrimaryUseCategoryFile.retrievePrimaryUseCategory(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_PrimaryUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating WaDE Custom VariableSpecificCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "def createVariableSpecificCV(inV, inAIU, inPU, inWST):\n",
    "    inV = str(inV).strip()\n",
    "    inAIU = str(inAIU).strip()\n",
    "    inPU = str(inPU).strip().title()\n",
    "    inWST = str(inWST).strip()\n",
    "    outString = inV + \"_\" + inAIU + \"_\" + inPU + \"_\" + inWST\n",
    "    return outString\n",
    "\n",
    "outdf['in_VariableSpecificCV'] = outdf.apply(lambda row: createVariableSpecificCV(row['in_VariableCV'], \n",
    "                                                                                  row['in_AggregationIntervalUnitCV'],\n",
    "                                                                                  row['in_PrimaryUseCategory'],\n",
    "                                                                                  row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# use unique WaterSourceName and WaterSourceType values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_WaterSourceNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_WaterSourceName'] = outdf['in_WaterSourceName'].astype(str).str.strip()\n",
    "dfTempID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_WaterSourceNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_WaterSourceName'].astype(str) + dfTempID['in_WaterSourceTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_WaterSourceNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_WaterSourceNativeID'], \n",
    "                                                                              row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom site native ID for easy site identification\n",
    "# use Unique Latitude, Longitude, SiteName and SiteTypeCV values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_SiteNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_Latitude'] = outdf['in_Latitude'].astype(str).str.strip()\n",
    "dfTempID['in_Longitude'] = outdf['in_Longitude'].astype(str).str.strip()\n",
    "dfTempID['in_SiteName'] = outdf['in_SiteName'].astype(str).str.strip()\n",
    "dfTempID['in_SiteTypeCV'] = outdf['in_SiteTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_SiteNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_Latitude'].astype(str) + dfTempID['in_Longitude'].astype(str) + dfTempID['in_SiteName'].astype(str)+ dfTempID['in_SiteTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_SiteNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB, valC, valD):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip() + str(valC).strip() + str(valD).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_SiteNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_SiteNativeID'], \n",
    "                                                                       row['in_Latitude'], row['in_Longitude'],\n",
    "                                                                       row['in_SiteName'], row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# see above for input\n",
    "\n",
    "print(len(dfPoUshapetemp))\n",
    "dfPoUshapetemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp dataframe to hold native ID and geometry from shapefile input\n",
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "\n",
    "# assing values to temp dataframe based on shapefile input\n",
    "# for in_SiteNativeID assure ID value is the same as that listed above for POU info.\n",
    "dfPoUshape['in_SiteNativeID'] = dfPoUshapetemp['SABL_PWSID']\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "print(len(dfPoUshape))\n",
    "dfPoUshape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('RawInputData/Pssps_Main.zip', compression=dict(method='zip', archive_name='Pssps_Main.csv'), index=False)  # The output, save as a zip\n",
    "dfPoUshape.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
