{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Water Supply Site Time Series data for WaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "from bs4 import BeautifulSoup # text parser\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/WaDE Data Folder/California/WaterSupply_SiteSpecific\"  # change here\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Files\n",
    "- site info for reservoirs\n",
    "- site info for streamgages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>ID</th>\n",
       "      <th>Elev</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>County</th>\n",
       "      <th>Operating Agency</th>\n",
       "      <th>WaDEUUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAKE JENNINGS</td>\n",
       "      <td>JNN</td>\n",
       "      <td>707</td>\n",
       "      <td>32.85400</td>\n",
       "      <td>-116.89200</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>None Specified</td>\n",
       "      <td>in10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Station   ID  Elev  Latitude  Longitude     County Operating Agency  \\\n",
       "0  LAKE JENNINGS  JNN   707  32.85400 -116.89200  SAN DIEGO   None Specified   \n",
       "\n",
       "  WaDEUUID  \n",
       "0     in10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input File: Reservoirs\n",
    "fileInput = \"RawInputData/Reservoirs.zip\"\n",
    "dfr = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfr:\n",
    "    dfr['WaDEUUID'] = \"in1\" + dfr.index.astype(str)\n",
    "    dfr.to_csv('RawInputData/Reservoirs.zip', compression=dict(method='zip', archive_name='Reservoirs.csv'), index=False)\n",
    "\n",
    "print(len(dfr))\n",
    "dfr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteid</th>\n",
       "      <th>sitename</th>\n",
       "      <th>gage_statu</th>\n",
       "      <th>operator</th>\n",
       "      <th>datasource</th>\n",
       "      <th>sitestatus</th>\n",
       "      <th>stage_yn</th>\n",
       "      <th>stage_por</th>\n",
       "      <th>stage_stat</th>\n",
       "      <th>stage_real</th>\n",
       "      <th>flow_yn</th>\n",
       "      <th>flow_por</th>\n",
       "      <th>flow_statu</th>\n",
       "      <th>flow_realt</th>\n",
       "      <th>watqual_yn</th>\n",
       "      <th>watqual_po</th>\n",
       "      <th>watqual_st</th>\n",
       "      <th>watqual_re</th>\n",
       "      <th>temp_yn</th>\n",
       "      <th>temp_por</th>\n",
       "      <th>temp_statu</th>\n",
       "      <th>temp_realt</th>\n",
       "      <th>strmorder</th>\n",
       "      <th>ucdstrmcla</th>\n",
       "      <th>streamtype</th>\n",
       "      <th>totdasqkm</th>\n",
       "      <th>totdasqmi</th>\n",
       "      <th>weblink</th>\n",
       "      <th>gnisid_med</th>\n",
       "      <th>rchcd_medr</th>\n",
       "      <th>comid_medr</th>\n",
       "      <th>wtrshdnm_h</th>\n",
       "      <th>huc8</th>\n",
       "      <th>wtrshdnm_1</th>\n",
       "      <th>huc10</th>\n",
       "      <th>wtrshdnm_2</th>\n",
       "      <th>huc12</th>\n",
       "      <th>gagegap_st</th>\n",
       "      <th>reactivate</th>\n",
       "      <th>gage_histo</th>\n",
       "      <th>addflow_2s</th>\n",
       "      <th>addflow_2w</th>\n",
       "      <th>addtelemet</th>\n",
       "      <th>addtemp_2f</th>\n",
       "      <th>infrastruc</th>\n",
       "      <th>waterbody</th>\n",
       "      <th>tier</th>\n",
       "      <th>primary_be</th>\n",
       "      <th>sb19_actio</th>\n",
       "      <th>cnrfc</th>\n",
       "      <th>reference_</th>\n",
       "      <th>refpotenti</th>\n",
       "      <th>ecosysmgmt</th>\n",
       "      <th>wtrsupply</th>\n",
       "      <th>wtrquality</th>\n",
       "      <th>pubsafety</th>\n",
       "      <th>wade_Latit</th>\n",
       "      <th>wade_Longi</th>\n",
       "      <th>geometry</th>\n",
       "      <th>WaDEUUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACZ</td>\n",
       "      <td>ALHAMBRA CREEK AT D STREET</td>\n",
       "      <td>Active-Limited Use</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>CDEC</td>\n",
       "      <td>Active</td>\n",
       "      <td>Y</td>\n",
       "      <td>1454</td>\n",
       "      <td>Active</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>Rain and seasonal groundwater (RGW)</td>\n",
       "      <td>Stream/River - Intermittent</td>\n",
       "      <td>42.84990</td>\n",
       "      <td>16.54443</td>\n",
       "      <td>http://cdec.water.ca.gov/cgi-progs/staMeta?sta...</td>\n",
       "      <td></td>\n",
       "      <td>18050001006347</td>\n",
       "      <td>948050078</td>\n",
       "      <td>Suisun Bay</td>\n",
       "      <td>18050001</td>\n",
       "      <td>Mount Diablo Creek-Frontal Suisun Bay Estuaries</td>\n",
       "      <td>1805000103</td>\n",
       "      <td>Arroyo del Hambre-Frontal Suisun Bay Estuaries</td>\n",
       "      <td>180500010303</td>\n",
       "      <td>AWG</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>ecosystem</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>38.00331</td>\n",
       "      <td>-122.12981</td>\n",
       "      <td>POINT Z (-122.12981 38.00331 0.00000)</td>\n",
       "      <td>in20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  siteid                    sitename          gage_statu operator datasource  \\\n",
       "0    ACZ  ALHAMBRA CREEK AT D STREET  Active-Limited Use    OTHER       CDEC   \n",
       "\n",
       "  sitestatus stage_yn  stage_por stage_stat stage_real flow_yn  flow_por  \\\n",
       "0     Active        Y       1454     Active          Y       N         0   \n",
       "\n",
       "  flow_statu flow_realt watqual_yn  watqual_po watqual_st watqual_re temp_yn  \\\n",
       "0                     N          N           0                     N       N   \n",
       "\n",
       "   temp_por temp_statu temp_realt  strmorder  \\\n",
       "0         0                     N          2   \n",
       "\n",
       "                            ucdstrmcla                   streamtype  \\\n",
       "0  Rain and seasonal groundwater (RGW)  Stream/River - Intermittent   \n",
       "\n",
       "   totdasqkm  totdasqmi                                            weblink  \\\n",
       "0   42.84990   16.54443  http://cdec.water.ca.gov/cgi-progs/staMeta?sta...   \n",
       "\n",
       "  gnisid_med      rchcd_medr comid_medr  wtrshdnm_h      huc8  \\\n",
       "0             18050001006347  948050078  Suisun Bay  18050001   \n",
       "\n",
       "                                        wtrshdnm_1       huc10  \\\n",
       "0  Mount Diablo Creek-Frontal Suisun Bay Estuaries  1805000103   \n",
       "\n",
       "                                       wtrshdnm_2         huc12 gagegap_st  \\\n",
       "0  Arroyo del Hambre-Frontal Suisun Bay Estuaries  180500010303        AWG   \n",
       "\n",
       "  reactivate  gage_histo addflow_2s addflow_2w addtelemet addtemp_2f  \\\n",
       "0          N           0          Y          N          N          Y   \n",
       "\n",
       "  infrastruc waterbody  tier primary_be sb19_actio cnrfc reference_  \\\n",
       "0                          3  ecosystem    Upgrade                    \n",
       "\n",
       "  refpotenti ecosysmgmt wtrsupply wtrquality pubsafety  wade_Latit  \\\n",
       "0                     B                                   38.00331   \n",
       "\n",
       "   wade_Longi                               geometry WaDEUUID  \n",
       "0  -122.12981  POINT Z (-122.12981 38.00331 0.00000)     in20  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input File: StreamGages shp file\n",
    "fileInput = \"RawInputData/shapefiles/StreamGages.zip\"\n",
    "dfsg = gpd.read_file(fileInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfsg:\n",
    "    dfsg['WaDEUUID'] = \"in2\" + dfsg.index.astype(str)\n",
    "    dfsg.to_csv('RawInputData/StreamGages.zip', compression=dict(method='zip', archive_name='StreamGages.csv'), index=False)\n",
    "\n",
    "print(len(dfsg))\n",
    "dfsg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File: Reservoirs_timeseries\n",
    "\n",
    "fileInput = \"RawInputData/Reservoirs_timeseries.zip\"\n",
    "dfr_ts = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "print(len(dfr_ts))\n",
    "dfr_ts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File: StreamGages_timeseries\n",
    "\n",
    "fileInput = \"RawInputData/StreamGages_timeseries.zip\"\n",
    "dfsg_ts = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "print(len(dfsg_ts))\n",
    "dfsg_ts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-join by reservoir metadata to reservoir site data\n",
    "\n",
    "dfin1 = pd.merge(dfr, dfr_ts, left_on='ID', right_on='STATION_ID', how='left')\n",
    "print(len(dfin1))\n",
    "dfin1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-join by streamgage metadata to streamgage site data\n",
    "\n",
    "dfin2 = pd.merge(dfsg, dfsg_ts, left_on='siteid', right_on='STATION_ID', how='left')\n",
    "print(len(dfin2))\n",
    "dfin2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata & timeseries data\n",
    "- https://cdec.water.ca.gov/dynamicapp/staMeta\n",
    "- this is out of order. But essnetialy steps include 1) use site info to get site ids; 2) use site ids with metadata api to determine what timeseries is available; 3) retreive timeseries data for sites based on available metadata.\n",
    "- metadata and timeseries data already retreived, use hard copies for inputs instead now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done\n",
    "\n",
    "# %%time\n",
    "# # get Reservoirs metadata\n",
    "\n",
    "# tempList = dfin1['ID'].tolist()\n",
    "# dftemp = pd.DataFrame()\n",
    "\n",
    "# for i in range(len(tempList)):\n",
    "#     idString = str(tempList[i]).strip()   \n",
    "#     url = \"https://cdec.water.ca.gov/dynamicapp/staMeta?station_id=\" + idString\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#         table = soup.find_all('table')\n",
    "#         rawData = pd.read_html(str(table))[1]\n",
    "#         rawData[\"ID\"] = idString\n",
    "#         dftemp = pd.concat([dftemp, rawData])\n",
    "#     except:\n",
    "#         print(f' did not work, {url}')\n",
    "\n",
    "# dftemp.to_csv('RawInputData/Reservoirs_Metadata.zip', compression=dict(method='zip', archive_name='Reservoirs_Metadata.csv'), index=False)\n",
    "\n",
    "# print(len(dftemp))\n",
    "# dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# already done\n",
    "\n",
    "# %%time\n",
    "# # get StreamGages metadata\n",
    "\n",
    "# tempList = dfin2['siteid'].unique().tolist()\n",
    "# dftemp = pd.DataFrame()\n",
    "\n",
    "# for i in range(len(tempList)):\n",
    "#     idString = str(tempList[i]).strip()   \n",
    "#     url = \"https://cdec.water.ca.gov/dynamicapp/staMeta?station_id=\" + idString\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#         table = soup.find_all('table')\n",
    "#         rawData = pd.read_html(str(table))[1]\n",
    "#         rawData[\"siteid\"] = idString\n",
    "#         dftemp = pd.concat([dftemp, rawData])\n",
    "#     except:\n",
    "#         print(f' did not work, {url}')\n",
    "\n",
    "# dftemp.to_csv('RawInputData/StreamGages_Metadata.zip', compression=dict(method='zip', archive_name='StreamGages_Metadata.csv'), index=False)\n",
    "\n",
    "# print(len(dftemp))\n",
    "# dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RESERVOIR STORAGE, AF</td>\n",
       "      <td>15</td>\n",
       "      <td>(daily)</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>10/01/2021 to present</td>\n",
       "      <td>JNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0   1        2          3             4  \\\n",
       "0  RESERVOIR STORAGE, AF  15  (daily)  (STORAGE)  MANUAL ENTRY   \n",
       "\n",
       "                       5   ID  \n",
       "0  10/01/2021 to present  JNN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input File: Reservoirs_Metadata\n",
    "\n",
    "fileInput = \"RawInputData/Reservoirs_Metadata.zip\"\n",
    "dfr_m = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "print(len(dfr_m))\n",
    "dfr_m.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2850\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>siteid</th>\n",
       "      <th>Zero Datum</th>\n",
       "      <th>Adj To NGVD</th>\n",
       "      <th>Peak of Record</th>\n",
       "      <th>Monitor Stage</th>\n",
       "      <th>Flood Stage</th>\n",
       "      <th>Guidance Plots</th>\n",
       "      <th>Danger Stage</th>\n",
       "      <th>Top of Levee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIVER STAGE, FEET</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>(event)</td>\n",
       "      <td>(RIV STG)</td>\n",
       "      <td>DATA XCHG-CCC</td>\n",
       "      <td>01/07/2017 to present</td>\n",
       "      <td>ACZ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1        2          3              4  \\\n",
       "0  RIVER STAGE, FEET 1.00000  (event)  (RIV STG)  DATA XCHG-CCC   \n",
       "\n",
       "                       5 siteid Zero Datum Adj To NGVD Peak of Record  \\\n",
       "0  01/07/2017 to present    ACZ                                         \n",
       "\n",
       "  Monitor Stage Flood Stage Guidance Plots Danger Stage Top of Levee  \n",
       "0                                                                     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input File: StreamGages_Metadata\n",
    "\n",
    "fileInput = \"RawInputData/StreamGages_Metadata.zip\"\n",
    "dfsg_m = pd.read_csv(fileInput).replace(np.nan, \"\")\n",
    "print(len(dfsg_m))\n",
    "dfsg_m.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor Description</th>\n",
       "      <th>SensorNums</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Data Collection</th>\n",
       "      <th>Data Available</th>\n",
       "      <th>ID</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RESERVOIR STORAGE, AF</td>\n",
       "      <td>15</td>\n",
       "      <td>(daily)</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>10/01/2021 to present</td>\n",
       "      <td>JNN</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>09/01/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor Description SensorNums Duration       Plot Data Collection  \\\n",
       "0  RESERVOIR STORAGE, AF         15  (daily)  (STORAGE)    MANUAL ENTRY   \n",
       "\n",
       "          Data Available   ID  Start Date    End Date  \n",
       "0  10/01/2021 to present  JNN  10/01/2021  09/01/2024  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up reservoir metadata\n",
    "\n",
    "dfr_m = dfr_m.rename(columns={\"0\": \"Sensor Description\",  \"1\": \"SensorNums\", \"2\" : \"Duration\", \"3\" : \"Plot\", \"4\" : \"Data Collection\", \"5\" : \"Data Available\"})\n",
    "dfr_m[['Start Date', 'End Date']] = dfr_m['Data Available'].str.split('to', n=1, expand=True)\n",
    "dfr_m['Start Date'] = dfr_m['Start Date'].str.strip()\n",
    "dfr_m['End Date'] = dfr_m['End Date'].str.replace('present','09/01/2024').str.strip()\n",
    "dfr_m.head()\n",
    "\n",
    "dfr_m.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor Description</th>\n",
       "      <th>SensorNums</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Data Collection</th>\n",
       "      <th>Data Available</th>\n",
       "      <th>siteid</th>\n",
       "      <th>Zero Datum</th>\n",
       "      <th>Adj To NGVD</th>\n",
       "      <th>Peak of Record</th>\n",
       "      <th>Monitor Stage</th>\n",
       "      <th>Flood Stage</th>\n",
       "      <th>Guidance Plots</th>\n",
       "      <th>Danger Stage</th>\n",
       "      <th>Top of Levee</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIVER STAGE, FEET</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>(event)</td>\n",
       "      <td>(RIV STG)</td>\n",
       "      <td>DATA XCHG-CCC</td>\n",
       "      <td>01/07/2017 to present</td>\n",
       "      <td>ACZ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>01/07/2017</td>\n",
       "      <td>09/01/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sensor Description SensorNums Duration       Plot Data Collection  \\\n",
       "0  RIVER STAGE, FEET    1.00000  (event)  (RIV STG)   DATA XCHG-CCC   \n",
       "\n",
       "          Data Available siteid Zero Datum Adj To NGVD Peak of Record  \\\n",
       "0  01/07/2017 to present    ACZ                                         \n",
       "\n",
       "  Monitor Stage Flood Stage Guidance Plots Danger Stage Top of Levee  \\\n",
       "0                                                                      \n",
       "\n",
       "   Start Date    End Date  \n",
       "0  01/07/2017  09/01/2024  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up streamgage metadata\n",
    "\n",
    "dfsg_m = dfsg_m.rename(columns={\"0\": \"Sensor Description\",  \"1\": \"SensorNums\", \"2\" : \"Duration\", \"3\" : \"Plot\", \"4\" : \"Data Collection\", \"5\" : \"Data Available\"})\n",
    "dfsg_m[['Start Date', 'End Date']] = dfsg_m['Data Available'].str.split('to', n=1, expand=True)\n",
    "dfsg_m['Start Date'] = dfsg_m['Start Date'].str.strip()\n",
    "dfsg_m['End Date'] = dfsg_m['End Date'].str.replace('present','09/01/2024').str.strip()\n",
    "dfsg_m.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abbreviate Duration \n",
    "\n",
    "durationDict = {\n",
    "\"(daily)\" : \"d\",\n",
    "\"(monthly)\" : \"m\",\n",
    "\"(event)\" : \"e\", \n",
    "\"(hourly)\" : \"h\"\n",
    "}\n",
    "\n",
    "def CreateDurationAPIValueFunc(val):\n",
    "    val = str(val).strip()\n",
    "    try:\n",
    "        outString = durationDict[val]\n",
    "    except:\n",
    "        outString = \"\"\n",
    "    return outString\n",
    "\n",
    "dfr_m['Duration_abb'] = dfr_m.apply(lambda row: CreateDurationAPIValueFunc(row['Duration']), axis=1)\n",
    "dfsg_m['Duration_abb'] = dfsg_m.apply(lambda row: CreateDurationAPIValueFunc(row['Duration']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>ID</th>\n",
       "      <th>Elev</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>County</th>\n",
       "      <th>Operating Agency</th>\n",
       "      <th>WaDEUUID</th>\n",
       "      <th>Sensor Description</th>\n",
       "      <th>SensorNums</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Data Collection</th>\n",
       "      <th>Data Available</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Duration_abb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAKE JENNINGS</td>\n",
       "      <td>JNN</td>\n",
       "      <td>707</td>\n",
       "      <td>32.85400</td>\n",
       "      <td>-116.89200</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>None Specified</td>\n",
       "      <td>in10</td>\n",
       "      <td>RESERVOIR STORAGE, AF</td>\n",
       "      <td>15</td>\n",
       "      <td>(daily)</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>10/01/2021 to present</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>09/01/2024</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Station   ID  Elev  Latitude  Longitude     County Operating Agency  \\\n",
       "0  LAKE JENNINGS  JNN   707  32.85400 -116.89200  SAN DIEGO   None Specified   \n",
       "\n",
       "  WaDEUUID     Sensor Description SensorNums Duration       Plot  \\\n",
       "0     in10  RESERVOIR STORAGE, AF         15  (daily)  (STORAGE)   \n",
       "\n",
       "  Data Collection         Data Available  Start Date    End Date Duration_abb  \n",
       "0    MANUAL ENTRY  10/01/2021 to present  10/01/2021  09/01/2024            d  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left-join by reservoir metadata to reservoir site data\n",
    "\n",
    "dfr = pd.merge(dfr, dfr_m, left_on='ID', right_on='ID', how='left')\n",
    "print(len(dfr))\n",
    "dfr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteid</th>\n",
       "      <th>sitename</th>\n",
       "      <th>gage_statu</th>\n",
       "      <th>operator</th>\n",
       "      <th>datasource</th>\n",
       "      <th>sitestatus</th>\n",
       "      <th>stage_yn</th>\n",
       "      <th>stage_por</th>\n",
       "      <th>stage_stat</th>\n",
       "      <th>stage_real</th>\n",
       "      <th>flow_yn</th>\n",
       "      <th>flow_por</th>\n",
       "      <th>flow_statu</th>\n",
       "      <th>flow_realt</th>\n",
       "      <th>watqual_yn</th>\n",
       "      <th>watqual_po</th>\n",
       "      <th>watqual_st</th>\n",
       "      <th>watqual_re</th>\n",
       "      <th>temp_yn</th>\n",
       "      <th>temp_por</th>\n",
       "      <th>temp_statu</th>\n",
       "      <th>temp_realt</th>\n",
       "      <th>strmorder</th>\n",
       "      <th>ucdstrmcla</th>\n",
       "      <th>streamtype</th>\n",
       "      <th>totdasqkm</th>\n",
       "      <th>totdasqmi</th>\n",
       "      <th>weblink</th>\n",
       "      <th>gnisid_med</th>\n",
       "      <th>rchcd_medr</th>\n",
       "      <th>comid_medr</th>\n",
       "      <th>wtrshdnm_h</th>\n",
       "      <th>huc8</th>\n",
       "      <th>wtrshdnm_1</th>\n",
       "      <th>huc10</th>\n",
       "      <th>wtrshdnm_2</th>\n",
       "      <th>huc12</th>\n",
       "      <th>gagegap_st</th>\n",
       "      <th>reactivate</th>\n",
       "      <th>gage_histo</th>\n",
       "      <th>addflow_2s</th>\n",
       "      <th>addflow_2w</th>\n",
       "      <th>addtelemet</th>\n",
       "      <th>addtemp_2f</th>\n",
       "      <th>infrastruc</th>\n",
       "      <th>waterbody</th>\n",
       "      <th>tier</th>\n",
       "      <th>primary_be</th>\n",
       "      <th>sb19_actio</th>\n",
       "      <th>cnrfc</th>\n",
       "      <th>reference_</th>\n",
       "      <th>refpotenti</th>\n",
       "      <th>ecosysmgmt</th>\n",
       "      <th>wtrsupply</th>\n",
       "      <th>wtrquality</th>\n",
       "      <th>pubsafety</th>\n",
       "      <th>wade_Latit</th>\n",
       "      <th>wade_Longi</th>\n",
       "      <th>geometry</th>\n",
       "      <th>WaDEUUID</th>\n",
       "      <th>Sensor Description</th>\n",
       "      <th>SensorNums</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Data Collection</th>\n",
       "      <th>Data Available</th>\n",
       "      <th>Zero Datum</th>\n",
       "      <th>Adj To NGVD</th>\n",
       "      <th>Peak of Record</th>\n",
       "      <th>Monitor Stage</th>\n",
       "      <th>Flood Stage</th>\n",
       "      <th>Guidance Plots</th>\n",
       "      <th>Danger Stage</th>\n",
       "      <th>Top of Levee</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Duration_abb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACZ</td>\n",
       "      <td>ALHAMBRA CREEK AT D STREET</td>\n",
       "      <td>Active-Limited Use</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>CDEC</td>\n",
       "      <td>Active</td>\n",
       "      <td>Y</td>\n",
       "      <td>1454</td>\n",
       "      <td>Active</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>Rain and seasonal groundwater (RGW)</td>\n",
       "      <td>Stream/River - Intermittent</td>\n",
       "      <td>42.84990</td>\n",
       "      <td>16.54443</td>\n",
       "      <td>http://cdec.water.ca.gov/cgi-progs/staMeta?sta...</td>\n",
       "      <td></td>\n",
       "      <td>18050001006347</td>\n",
       "      <td>948050078</td>\n",
       "      <td>Suisun Bay</td>\n",
       "      <td>18050001</td>\n",
       "      <td>Mount Diablo Creek-Frontal Suisun Bay Estuaries</td>\n",
       "      <td>1805000103</td>\n",
       "      <td>Arroyo del Hambre-Frontal Suisun Bay Estuaries</td>\n",
       "      <td>180500010303</td>\n",
       "      <td>AWG</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>ecosystem</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>38.00331</td>\n",
       "      <td>-122.12981</td>\n",
       "      <td>POINT Z (-122.12981 38.00331 0.00000)</td>\n",
       "      <td>in20</td>\n",
       "      <td>RIVER STAGE, FEET</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>(event)</td>\n",
       "      <td>(RIV STG)</td>\n",
       "      <td>DATA XCHG-CCC</td>\n",
       "      <td>01/07/2017 to present</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>01/07/2017</td>\n",
       "      <td>09/01/2024</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  siteid                    sitename          gage_statu operator datasource  \\\n",
       "0    ACZ  ALHAMBRA CREEK AT D STREET  Active-Limited Use    OTHER       CDEC   \n",
       "\n",
       "  sitestatus stage_yn  stage_por stage_stat stage_real flow_yn  flow_por  \\\n",
       "0     Active        Y       1454     Active          Y       N         0   \n",
       "\n",
       "  flow_statu flow_realt watqual_yn  watqual_po watqual_st watqual_re temp_yn  \\\n",
       "0                     N          N           0                     N       N   \n",
       "\n",
       "   temp_por temp_statu temp_realt  strmorder  \\\n",
       "0         0                     N          2   \n",
       "\n",
       "                            ucdstrmcla                   streamtype  \\\n",
       "0  Rain and seasonal groundwater (RGW)  Stream/River - Intermittent   \n",
       "\n",
       "   totdasqkm  totdasqmi                                            weblink  \\\n",
       "0   42.84990   16.54443  http://cdec.water.ca.gov/cgi-progs/staMeta?sta...   \n",
       "\n",
       "  gnisid_med      rchcd_medr comid_medr  wtrshdnm_h      huc8  \\\n",
       "0             18050001006347  948050078  Suisun Bay  18050001   \n",
       "\n",
       "                                        wtrshdnm_1       huc10  \\\n",
       "0  Mount Diablo Creek-Frontal Suisun Bay Estuaries  1805000103   \n",
       "\n",
       "                                       wtrshdnm_2         huc12 gagegap_st  \\\n",
       "0  Arroyo del Hambre-Frontal Suisun Bay Estuaries  180500010303        AWG   \n",
       "\n",
       "  reactivate  gage_histo addflow_2s addflow_2w addtelemet addtemp_2f  \\\n",
       "0          N           0          Y          N          N          Y   \n",
       "\n",
       "  infrastruc waterbody  tier primary_be sb19_actio cnrfc reference_  \\\n",
       "0                          3  ecosystem    Upgrade                    \n",
       "\n",
       "  refpotenti ecosysmgmt wtrsupply wtrquality pubsafety  wade_Latit  \\\n",
       "0                     B                                   38.00331   \n",
       "\n",
       "   wade_Longi                               geometry WaDEUUID  \\\n",
       "0  -122.12981  POINT Z (-122.12981 38.00331 0.00000)     in20   \n",
       "\n",
       "  Sensor Description SensorNums Duration       Plot Data Collection  \\\n",
       "0  RIVER STAGE, FEET    1.00000  (event)  (RIV STG)   DATA XCHG-CCC   \n",
       "\n",
       "          Data Available Zero Datum Adj To NGVD Peak of Record Monitor Stage  \\\n",
       "0  01/07/2017 to present                                                       \n",
       "\n",
       "  Flood Stage Guidance Plots Danger Stage Top of Levee  Start Date  \\\n",
       "0                                                       01/07/2017   \n",
       "\n",
       "     End Date Duration_abb  \n",
       "0  09/01/2024            e  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left-join by streamgage metadata to streamgage site data\n",
    "\n",
    "dfsg = pd.merge(dfsg, dfsg_m, left_on='siteid', right_on='siteid', how='left')\n",
    "print(len(dfsg))\n",
    "dfsg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that do not contain monthly (m) or dailiy (d) data.\n",
    "timestep = ['m', 'd']\n",
    "\n",
    "dfr = dfr[dfr['Duration_abb'].isin(timestep)]\n",
    "dfsg = dfsg[dfsg['Duration_abb'].isin(timestep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5082260\n",
      "CPU times: total: 8min 4s\n",
      "Wall time: 17min 25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>SENSOR_NUMBER</th>\n",
       "      <th>SENSOR_TYPE</th>\n",
       "      <th>DATE TIME</th>\n",
       "      <th>OBS DATE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>DATA_FLAG</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>Duration_abbe</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Data Collection</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JNN</td>\n",
       "      <td>D</td>\n",
       "      <td>15</td>\n",
       "      <td>STORAGE</td>\n",
       "      <td>20211001 0000</td>\n",
       "      <td>20211001 0000</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>AF</td>\n",
       "      <td>d</td>\n",
       "      <td>(PPT INC)</td>\n",
       "      <td>DATA XCHG-USACE SAC</td>\n",
       "      <td>01/23/1989</td>\n",
       "      <td>04/23/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JNN</td>\n",
       "      <td>D</td>\n",
       "      <td>15</td>\n",
       "      <td>STORAGE</td>\n",
       "      <td>20211002 0000</td>\n",
       "      <td>20211002 0000</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>AF</td>\n",
       "      <td>d</td>\n",
       "      <td>(PPT INC)</td>\n",
       "      <td>DATA XCHG-USACE SAC</td>\n",
       "      <td>01/23/1989</td>\n",
       "      <td>04/23/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JNN</td>\n",
       "      <td>D</td>\n",
       "      <td>15</td>\n",
       "      <td>STORAGE</td>\n",
       "      <td>20211003 0000</td>\n",
       "      <td>20211003 0000</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>AF</td>\n",
       "      <td>d</td>\n",
       "      <td>(PPT INC)</td>\n",
       "      <td>DATA XCHG-USACE SAC</td>\n",
       "      <td>01/23/1989</td>\n",
       "      <td>04/23/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JNN</td>\n",
       "      <td>D</td>\n",
       "      <td>15</td>\n",
       "      <td>STORAGE</td>\n",
       "      <td>20211004 0000</td>\n",
       "      <td>20211004 0000</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>AF</td>\n",
       "      <td>d</td>\n",
       "      <td>(PPT INC)</td>\n",
       "      <td>DATA XCHG-USACE SAC</td>\n",
       "      <td>01/23/1989</td>\n",
       "      <td>04/23/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JNN</td>\n",
       "      <td>D</td>\n",
       "      <td>15</td>\n",
       "      <td>STORAGE</td>\n",
       "      <td>20211005 0000</td>\n",
       "      <td>20211005 0000</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>AF</td>\n",
       "      <td>d</td>\n",
       "      <td>(PPT INC)</td>\n",
       "      <td>DATA XCHG-USACE SAC</td>\n",
       "      <td>01/23/1989</td>\n",
       "      <td>04/23/1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATION_ID DURATION SENSOR_NUMBER SENSOR_TYPE      DATE TIME       OBS DATE  \\\n",
       "0        JNN        D            15     STORAGE  20211001 0000  20211001 0000   \n",
       "1        JNN        D            15     STORAGE  20211002 0000  20211002 0000   \n",
       "2        JNN        D            15     STORAGE  20211003 0000  20211003 0000   \n",
       "3        JNN        D            15     STORAGE  20211004 0000  20211004 0000   \n",
       "4        JNN        D            15     STORAGE  20211005 0000  20211005 0000   \n",
       "\n",
       "  VALUE DATA_FLAG UNITS Duration_abbe       Plot      Data Collection  \\\n",
       "0   ---              AF             d  (PPT INC)  DATA XCHG-USACE SAC   \n",
       "1   ---              AF             d  (PPT INC)  DATA XCHG-USACE SAC   \n",
       "2   ---              AF             d  (PPT INC)  DATA XCHG-USACE SAC   \n",
       "3   ---              AF             d  (PPT INC)  DATA XCHG-USACE SAC   \n",
       "4   ---              AF             d  (PPT INC)  DATA XCHG-USACE SAC   \n",
       "\n",
       "   Start Date    End Date  \n",
       "0  01/23/1989  04/23/1997  \n",
       "1  01/23/1989  04/23/1997  \n",
       "2  01/23/1989  04/23/1997  \n",
       "3  01/23/1989  04/23/1997  \n",
       "4  01/23/1989  04/23/1997  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# get timeseries for reservoirs\n",
    "\n",
    "stationsList = dfr['ID'].tolist()\n",
    "sensorNumsList = dfr['SensorNums'].tolist()\n",
    "dur_codeList =  dfr['Duration_abb'].tolist()\n",
    "plotList = dfr['Plot'].tolist()\n",
    "datacollectionList = dfr['Data Collection'].tolist()\n",
    "startList = dfr['Start Date'].tolist()\n",
    "endList = dfr['End Date'].tolist()\n",
    "\n",
    "# Time Series Dataframe\n",
    "dfr_ts = pd.DataFrame()\n",
    "\n",
    "for i in range(len(stationsList)):\n",
    "    stationStr = str(stationsList[i]).strip()\n",
    "    sensorNumsStr = str(sensorNumsList[i]).strip()\n",
    "    dur_codeStr = str(dur_codeList[i]).strip()\n",
    "    plotStr = str(plotList[i]).strip()\n",
    "    datacollectionStr = str(datacollectionList[i]).strip()\n",
    "    startStr = str(startList[i]).strip()\n",
    "    endStr = str(endList[i]).strip()   \n",
    "    urlInput = \"https://cdec.water.ca.gov/dynamicapp/req/CSVDataServlet?Stations=\" + stationStr + \"&SensorNums=\" + sensorNumsStr + \"&dur_code=\" + dur_codeStr + \"&Start=\" + startStr +\"&End=\" + endStr\n",
    "    try:\n",
    "        tempdf = pd.read_csv(urlInput).replace(np.nan, \"\")\n",
    "        dfr_ts = pd.concat([dfr_ts, tempdf])\n",
    "        dfr_ts['Duration_abbe'] = dur_codeStr\n",
    "        dfr_ts['Plot'] = plotStr\n",
    "        dfr_ts['Data Collection'] = datacollectionStr\n",
    "        dfr_ts['Start Date'] = startStr\n",
    "        dfr_ts['End Date'] = endStr\n",
    "              \n",
    "    except:\n",
    "        print(\"...bad reponse\")\n",
    "\n",
    "dfr_ts.to_csv('RawInputData/Reservoirs_timeseries.zip', compression=dict(method='zip', archive_name='Reservoirs_timeseries.csv'), index=False)\n",
    "print(len(dfr_ts))\n",
    "dfr_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250992\n",
      "CPU times: total: 3min 54s\n",
      "Wall time: 9min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>SENSOR_NUMBER</th>\n",
       "      <th>SENSOR_TYPE</th>\n",
       "      <th>DATE TIME</th>\n",
       "      <th>OBS DATE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>DATA_FLAG</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>Duration_abbe</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Data Collection</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANH</td>\n",
       "      <td>D</td>\n",
       "      <td>100</td>\n",
       "      <td>EL COND</td>\n",
       "      <td>20080118 0000</td>\n",
       "      <td>20080118 0000</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>uS/cm</td>\n",
       "      <td>m</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>01/01/1956</td>\n",
       "      <td>09/01/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANH</td>\n",
       "      <td>D</td>\n",
       "      <td>100</td>\n",
       "      <td>EL COND</td>\n",
       "      <td>20080119 0000</td>\n",
       "      <td>20080119 0000</td>\n",
       "      <td>526</td>\n",
       "      <td></td>\n",
       "      <td>uS/cm</td>\n",
       "      <td>m</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>01/01/1956</td>\n",
       "      <td>09/01/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANH</td>\n",
       "      <td>D</td>\n",
       "      <td>100</td>\n",
       "      <td>EL COND</td>\n",
       "      <td>20080120 0000</td>\n",
       "      <td>20080120 0000</td>\n",
       "      <td>628</td>\n",
       "      <td></td>\n",
       "      <td>uS/cm</td>\n",
       "      <td>m</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>01/01/1956</td>\n",
       "      <td>09/01/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANH</td>\n",
       "      <td>D</td>\n",
       "      <td>100</td>\n",
       "      <td>EL COND</td>\n",
       "      <td>20080121 0000</td>\n",
       "      <td>20080121 0000</td>\n",
       "      <td>658</td>\n",
       "      <td></td>\n",
       "      <td>uS/cm</td>\n",
       "      <td>m</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>01/01/1956</td>\n",
       "      <td>09/01/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANH</td>\n",
       "      <td>D</td>\n",
       "      <td>100</td>\n",
       "      <td>EL COND</td>\n",
       "      <td>20080122 0000</td>\n",
       "      <td>20080122 0000</td>\n",
       "      <td>603</td>\n",
       "      <td></td>\n",
       "      <td>uS/cm</td>\n",
       "      <td>m</td>\n",
       "      <td>(STORAGE)</td>\n",
       "      <td>MANUAL ENTRY</td>\n",
       "      <td>01/01/1956</td>\n",
       "      <td>09/01/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATION_ID DURATION  SENSOR_NUMBER SENSOR_TYPE      DATE TIME  \\\n",
       "0        ANH        D            100     EL COND  20080118 0000   \n",
       "1        ANH        D            100     EL COND  20080119 0000   \n",
       "2        ANH        D            100     EL COND  20080120 0000   \n",
       "3        ANH        D            100     EL COND  20080121 0000   \n",
       "4        ANH        D            100     EL COND  20080122 0000   \n",
       "\n",
       "        OBS DATE VALUE DATA_FLAG  UNITS Duration_abbe       Plot  \\\n",
       "0  20080118 0000   ---            uS/cm             m  (STORAGE)   \n",
       "1  20080119 0000   526            uS/cm             m  (STORAGE)   \n",
       "2  20080120 0000   628            uS/cm             m  (STORAGE)   \n",
       "3  20080121 0000   658            uS/cm             m  (STORAGE)   \n",
       "4  20080122 0000   603            uS/cm             m  (STORAGE)   \n",
       "\n",
       "  Data Collection  Start Date    End Date  \n",
       "0    MANUAL ENTRY  01/01/1956  09/01/2024  \n",
       "1    MANUAL ENTRY  01/01/1956  09/01/2024  \n",
       "2    MANUAL ENTRY  01/01/1956  09/01/2024  \n",
       "3    MANUAL ENTRY  01/01/1956  09/01/2024  \n",
       "4    MANUAL ENTRY  01/01/1956  09/01/2024  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# get timeseries for streamgages\n",
    "\n",
    "dfsg['SensorNums'] = dfsg['SensorNums'].astype(int).astype(str)\n",
    "\n",
    "stationsList = dfsg['siteid'].tolist()\n",
    "sensorNumsList = dfsg['SensorNums'].tolist()\n",
    "dur_codeList =  dfsg['Duration_abb'].tolist()\n",
    "plotList = dfsg['Plot'].tolist()\n",
    "datacollectionList = dfsg['Data Collection'].tolist()\n",
    "startList = dfsg['Start Date'].tolist()\n",
    "endList = dfsg['End Date'].tolist()\n",
    "\n",
    "# Time Series Dataframe\n",
    "dfsg_ts = pd.DataFrame()\n",
    "\n",
    "for i in range(len(stationsList)):\n",
    "    stationStr = str(stationsList[i]).strip()\n",
    "    sensorNumsStr = str(sensorNumsList[i]).strip()\n",
    "    dur_codeStr = str(dur_codeList[i]).strip()\n",
    "    plotStr = str(plotList[i]).strip()\n",
    "    datacollectionStr = str(datacollectionList[i]).strip()\n",
    "    startStr = str(startList[i]).strip()\n",
    "    endStr = str(endList[i]).strip()   \n",
    "    urlInput = \"https://cdec.water.ca.gov/dynamicapp/req/CSVDataServlet?Stations=\" + stationStr + \"&SensorNums=\" + sensorNumsStr + \"&dur_code=\" + dur_codeStr + \"&Start=\" + startStr +\"&End=\" + endStr\n",
    "    try:\n",
    "        tempdf = pd.read_csv(urlInput).replace(np.nan, \"\")\n",
    "        dfsg_ts = pd.concat([dfsg_ts, tempdf])\n",
    "        dfsg_ts['Duration_abbe'] = dur_codeStr\n",
    "        dfsg_ts['Plot'] = plotStr\n",
    "        dfsg_ts['Data Collection'] = datacollectionStr\n",
    "        dfsg_ts['Start Date'] = startStr\n",
    "        dfsg_ts['End Date'] = endStr\n",
    "              \n",
    "    except:\n",
    "        print(\"...bad reponse\")\n",
    "\n",
    "dfsg_ts.to_csv('RawInputData/StreamGages_timeseries.zip', compression=dict(method='zip', archive_name='StreamGages_timeseries.csv'), index=False)\n",
    "print(len(dfsg_ts))\n",
    "dfsg_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfin1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfin1['SENSOR_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoir data\n",
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfin1['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_AggregationIntervalUnitCV'] = \"\"\n",
    "df['in_AmountUnitCV'] = \"\"\n",
    "df['in_VariableCV'] = \"\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"\" # need this for auto fill below\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "df['in_WaterSourceTypeCV'] = \"\" # need this for auto fill below\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = \"\"\n",
    "df['in_Longitude'] = \"\"\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"\"\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# Site VariableAmounts Info\n",
    "df['in_Amount'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AssociatedNativeAllocationIDs'] = \"\"\n",
    "df['in_BeneficialUseCategory'] = \"\"\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerGeneratedGWh'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryUseCategory'] = \"\"\n",
    "df['in_ReportYearCV'] =  \"\"\n",
    "df['in_SDWISIdentifier'] = \"\"\n",
    "df['in_TimeframeEnd'] = \"\"\n",
    "df['in_TimeframeStart'] = \"\"\n",
    "\n",
    "outdf1 = df.copy()\n",
    "outdf1 = outdf1.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdf1))\n",
    "outdf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outdf1]\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean name entries of spcial characters\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip().rstrip(',')\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: ensureEmptyString(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "uniqueList = list(set([i.strip() for i in ','.join(outdf['in_BeneficialUseCategory'].astype(str)).split(',')]))\n",
    "uniqueList.sort()\n",
    "uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Latitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Longitude entry is numireic, replace '0' values for removal\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Amount entry is either numireic or blank, no 0 entries\n",
    "outdf['in_Amount'] = pd.to_numeric(outdf['in_Amount'], errors='coerce').round(2).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure PopulationServed entry is numireic WITH 0 entries (no blank strings)\n",
    "outdf['in_PopulationServed'] = pd.to_numeric(outdf['in_PopulationServed'], errors='coerce').round().replace(\"\",0).fillna(0).astype(int).replace(0,\"\").fillna(\"\")\n",
    "outdf['in_PopulationServed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeEnd to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf['in_TimeframeEnd'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeEnd'] = pd.to_datetime(outdf[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeEnd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeframeStart to YYYY-MM-DD format.\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf['in_TimeframeStart'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "outdf['in_TimeframeStart'] = pd.to_datetime(outdf[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_TimeframeStart'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year out\n",
    "# outdf['in_ReportYearCV'] = pd.to_datetime(outdf['in_ReportYearCV'], utc=True, errors = 'coerce').fillna(\"\")\n",
    "# outdf['in_ReportYearCV'] = pd.to_datetime(outdf[\"in_ReportYearCV\"].dt.strftime('%m/%d/%Y'))\n",
    "# outdf['in_ReportYearCV'] = outdf['in_ReportYearCV'].dt.year\n",
    "# outdf['in_ReportYearCV'] = outdf['in_ReportYearCV'].fillna(0).astype(int)\n",
    "outdf['in_ReportYearCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Primary Use Category\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/rjame/Documents/WSWC Documents/MappingStatesDataToWaDE2.0/5_CustomFunctions/AssignPrimaryUseCategory\")\n",
    "import AssignPrimaryUseCategoryFile # Use Custom import file\n",
    "\n",
    "outdf['in_PrimaryUseCategory'] = outdf.apply(lambda row: AssignPrimaryUseCategoryFile.retrievePrimaryUseCategory(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_PrimaryUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating WaDE Custom VariableSpecificCV\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "def createVariableSpecificCV(inV, inAIU, inPU, inWST):\n",
    "    inV = str(inV).strip()\n",
    "    inAIU = str(inAIU).strip()\n",
    "    inPU = str(inPU).strip().title()\n",
    "    inWST = str(inWST).strip()\n",
    "    outString = inV + \"_\" + inAIU + \"_\" + inPU + \"_\" + inWST\n",
    "    return outString\n",
    "\n",
    "outdf['in_VariableSpecificCV'] = outdf.apply(lambda row: createVariableSpecificCV(row['in_VariableCV'], \n",
    "                                                                                  row['in_AggregationIntervalUnitCV'],\n",
    "                                                                                  row['in_PrimaryUseCategory'],\n",
    "                                                                                  row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_VariableSpecificCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# use unique WaterSourceName and WaterSourceType values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_WaterSourceNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_WaterSourceName'] = outdf['in_WaterSourceName'].astype(str).str.strip()\n",
    "dfTempID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_WaterSourceNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_WaterSourceName'].astype(str) + dfTempID['in_WaterSourceTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_WaterSourceNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_WaterSourceNativeID'], \n",
    "                                                                              row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom site native ID for easy site identification\n",
    "# use Unique Latitude, Longitude, SiteName and SiteTypeCV values\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp in_SiteNativeID dataframe of unique water source.\n",
    "def assignIdValueFunc(colRowValue):\n",
    "    string1 = str(colRowValue)\n",
    "    outstring = \"wadeId\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfTempID = pd.DataFrame()\n",
    "dfTempID['in_Latitude'] = outdf['in_Latitude'].astype(str).str.strip()\n",
    "dfTempID['in_Longitude'] = outdf['in_Longitude'].astype(str).str.strip()\n",
    "dfTempID['in_SiteName'] = outdf['in_SiteName'].astype(str).str.strip()\n",
    "dfTempID['in_SiteTypeCV'] = outdf['in_SiteTypeCV'].astype(str).str.strip()\n",
    "dfTempID = dfTempID.drop_duplicates()\n",
    "\n",
    "dfTempCount = pd.DataFrame(index=dfTempID.index)\n",
    "dfTempCount[\"Count\"] = range(1, len(dfTempCount.index) + 1)\n",
    "dfTempID['in_SiteNativeID'] = dfTempCount.apply(lambda row: assignIdValueFunc(row['Count']), axis=1)\n",
    "dfTempID['linkKey'] = dfTempID['in_Latitude'].astype(str) + dfTempID['in_Longitude'].astype(str) + dfTempID['in_SiteName'].astype(str)+ dfTempID['in_SiteTypeCV'].astype(str)\n",
    "IdDict = pd.Series(dfTempID.in_SiteNativeID.values, index=dfTempID.linkKey.astype(str)).to_dict()\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom site native ID\n",
    "def retrieveIdValueFunc(checkVal, valA, valB, valC, valD):\n",
    "    checkVal = str(checkVal).strip()\n",
    "    if checkVal == \"\":\n",
    "        linkKeyVal = str(valA).strip() + str(valB).strip() + str(valC).strip() + str(valD).strip()\n",
    "        outString = IdDict[linkKeyVal]\n",
    "    else:\n",
    "        outString = checkVal\n",
    "    return outString\n",
    "\n",
    "outdf['in_SiteNativeID'] = outdf.apply(lambda row: retrieveIdValueFunc(row['in_SiteNativeID'], \n",
    "                                                                       row['in_Latitude'], row['in_Longitude'],\n",
    "                                                                       row['in_SiteName'], row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('RawInputData/Pwsss_caMain.zip', compression=dict(method='zip', archive_name='Pssro_xxMain.csv'), index=False)  # The output, save as a zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
