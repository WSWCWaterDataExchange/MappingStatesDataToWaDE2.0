{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f571be",
   "metadata": {},
   "source": [
    "# Data Assessment & Analytics\n",
    "Notes:\n",
    "- change os directory location\n",
    "- be aware of the number of provdied native source data files\n",
    "- beware of of what data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import geoplot as gplt  # for plotting maps and geo-data\n",
    "import geoplot.crs as gcrs  #used to pull in webdata related to maps and geo-data\n",
    "import missingno as msno # creates a matrix chart to show missing values\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go  # for subplot creation\n",
    "from plotly.subplots import make_subplots  # for subplot creation\n",
    "import matplotlib.pyplot as mplt  # use with gplt to save fig to pdf\n",
    "\n",
    "# ---- cleanup ----\n",
    "import re # string regular expression manipulation\n",
    "from datetime import datetime # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24dccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = os.getcwd() # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- where to find input files ----\n",
    "InputFolderString = \"G:/Shared drives/WaDE Data/California/SS_DiversionsWithdrawalsWaterUse\" # set this to where input files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native Input Data\n",
    "#################################################################\n",
    "# ---- This needs to be custom per state ----\n",
    "\n",
    "# Data Set 1: PointsOfDiversion_input\n",
    "dfin1 = pd.read_csv(InputFolderString + '/RawinputData/water-rights-water-use-reported-2016-18.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaDE Processed Input Data\n",
    "#################################################################\n",
    "\n",
    "dfm = pd.read_csv(InputFolderString + \"/ProcessedInputData/methods.csv\", encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "dfv = pd.read_csv(InputFolderString + \"/ProcessedInputData/variables.csv\", encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "dfo = pd.read_csv(InputFolderString + \"/ProcessedInputData/organizations.csv\", encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "dfws = pd.read_csv(InputFolderString + \"/ProcessedInputData/watersources.csv\").replace(np.nan, \"\")\n",
    "dfwspurge = pd.read_csv(InputFolderString + \"/ProcessedInputData/watersources_missing.csv\").replace(np.nan, \"\")\n",
    "\n",
    "dfs = pd.read_csv(InputFolderString + \"/ProcessedInputData/sites.csv\").replace(np.nan, \"\")\n",
    "dfspurge = pd.read_csv(InputFolderString + \"/ProcessedInputData/sites_missing.csv\").replace(np.nan, \"\")\n",
    "\n",
    "dfsa = pd.read_csv(InputFolderString + \"/ProcessedInputData/sitespecificamounts.csv\").replace(np.nan, \"\")\n",
    "dfsapurge = pd.read_csv(InputFolderString + \"/ProcessedInputData/sitespecificamounts_missing.csv\").replace(np.nan, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff4e59",
   "metadata": {},
   "source": [
    "# Water Source Info (watersources.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a506fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(dfws))\n",
    "dfws.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.bar(dfws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'WaterSourceTypeCV'\n",
    "for x in dfws['WaterSourceTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6701f3",
   "metadata": {},
   "source": [
    "# Site Info (sites.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0995e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(dfs))\n",
    "dfs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ba2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.bar(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'CoordinateMethodCV'\n",
    "for x in dfs['CoordinateMethodCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c269f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'SiteTypeCV'\n",
    "for x in dfs['SiteTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e431228-ae32-40b1-810c-c9753fd06d88",
   "metadata": {},
   "source": [
    "# Site Specific Amount Info (sitespecificamounts.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7839855-2cc9-4ccb-8a94-a15ca2f364a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfsa))\n",
    "dfsa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbcfde-d0b6-4d72-945d-2cda48aba46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.bar(dfsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48a7fb-1cfc-4c5c-a196-c805ecb42c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'BeneficialUseCategory'\n",
    "uniqueList = list(set([i.strip() for i in ','.join(dfsa['BeneficialUseCategory'].astype(str)).split(',')]))\n",
    "uniqueList.sort()\n",
    "uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730fe66-0bd8-448d-9b26-181bfc0bb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_CropTypeCV'\n",
    "for x in dfsa['CropTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a3726-6dca-4a6a-975d-68cdc3ab98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_CustomerTypeCV'\n",
    "for x in dfsa['CustomerTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce7903-ca1c-4b72-8c71-2d7d41e713b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_PopulationServed'\n",
    "for x in dfsa['PopulationServed'].astype(str).sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdc3b6-9f0a-499b-bae7-83323066ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'in_ReportYearCV'\n",
    "for x in dfsa['ReportYearCV'].astype(str).sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823eb5a",
   "metadata": {},
   "source": [
    "## Num of Record Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f17728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of entries of source data\n",
    "print(f\"Num of Source #1 Entries (rows): \", \"|\", len(dfin1))\n",
    "#print(f\"Num of Source #2 Entries (rows): \", \"|\", len(dfin2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe2517-4c2e-4cf9-8e2f-49e6cf9dcf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of entries compiled into WaDE\n",
    "podString =  len(dfs[dfs['PODorPOUSite'] == 'POD'])\n",
    "pouString=  len(dfs[dfs['PODorPOUSite'] == 'POU'])\n",
    "wrString = len(dfsa)\n",
    "print(\"Dataset  | Num of Identified PODs | Num of Identified POUs | Num of Identified Water Right Records\")\n",
    "print(\"**Compiled WaDE Data** |\", podString, \"|\", pouString, \"|\", wrString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f33cf-29af-4264-b56b-ab6393cdf0e7",
   "metadata": {},
   "source": [
    "## Markdown Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e95ad6-558a-4345-a887-3c6705570dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method.csv\n",
    "dftmp = dfm.copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82304ac-b402-4ba5-b0c8-bc8f6de804be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable.csv\n",
    "dftmp = dfv.loc[[1]].copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905dfbf-854f-403d-b7af-b18356c221ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizations.csv\n",
    "dftmp = dfo.copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55beaa9b-0513-44bb-81f7-c5eb1c6de431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watersources.csv\n",
    "dftmp = dfws.loc[[1]].copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174a15b-ac7b-462c-bc77-f1e34de94bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites.csv\n",
    "dftmp = dfs.loc[[1]].copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68197b3a-79de-4212-b826-c9dc5aa64063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sitespecificamounts.csv\n",
    "dftmp = dfsa.loc[[1]].copy().to_markdown()\n",
    "print(dftmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce8fa67",
   "metadata": {},
   "source": [
    "## Why Removed Records Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70010938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Reasons why records were removed from water source info ----\")\n",
    "if len(dfwspurge) != 0:\n",
    "    print(dfwspurge['ReasonRemoved'].value_counts().astype(str) + \" | removed from watersources.csv input\")\n",
    "else:\n",
    "    print(\"...nothing removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18752994",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ---- Reasons why records were removed from site info ---- \")\n",
    "if len(dfspurge) != 0:\n",
    "    print(dfspurge['ReasonRemoved'].value_counts().astype(str) + \" | removed from sites.csv input\")\n",
    "else:\n",
    "    print(\"...nothing removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ---- Reasons why records were removed from site specific amounts  info ---- \")\n",
    "if len(dfsapurge) != 0:\n",
    "    print(dfsapurge['ReasonRemoved'].value_counts().astype(str) + \" | removed from sitespecificamounts.csv input\")\n",
    "else:\n",
    "    print(\"...nothing removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee4707",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- merge watersource.csv to sites.csv ----\n",
    "\n",
    "# explode site.csv on WaterSourceUUIDs\n",
    "dfstemp = dfs.copy()\n",
    "dfstemp = dfstemp.assign(WaterSourceUUIDs=dfstemp['WaterSourceUUIDs'].str.split(',')).explode('WaterSourceUUIDs').reset_index(drop=True)\n",
    "\n",
    "# merge\n",
    "dfstemp_ws = pd.merge(dfstemp, dfws[['WaterSourceUUID', 'WaterSourceTypeCV']], left_on='WaterSourceUUIDs', right_on='WaterSourceUUID', how='left')\n",
    "\n",
    "# groupby site-watersource.csv via SiteUUID\n",
    "dfstemp_ws = dfstemp_ws.groupby('SiteUUID').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem != \"\"])).replace(np.nan, \"\").reset_index()\n",
    "\n",
    "print(len(dfstemp_ws))\n",
    "dfstemp_ws.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a939e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Num of POD sites vs POU sites ----\n",
    "print(dfstemp_ws.PODorPOUSite.value_counts())\n",
    "\n",
    "fig = px.histogram(dfstemp_ws, x=\"PODorPOUSite\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of PODorPOUSite Entries in sites.csv\",\n",
    "                  xaxis_title=\"PODorPOUSite Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/PODorPOUSite.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cf685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Num of sites via WatersourceTypeCV ----\n",
    "print(dfstemp_ws.WaterSourceTypeCV.value_counts())\n",
    "\n",
    "fig = px.histogram(dfstemp_ws, x=\"WaterSourceTypeCV\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of WaterSourceTypeCV Entries in sites.csv\",\n",
    "                  xaxis_title=\"WaterSourceTypeCV Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/WaterSourceTypeCV.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Distribution of PrimaryUseCategory WaDE Values ----\n",
    "print(dfsa.PrimaryUseCategory.value_counts())\n",
    "\n",
    "fig = px.histogram(dfsa, x=\"PrimaryUseCategory\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of WaDE PrimaryUseCategory Entries in timeseries.csv\",\n",
    "                  xaxis_title=\"PrimaryUseCategory Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/PrimaryUseCategory.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37758f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Amount: Boxplot distribution of WaDE values ----\n",
    "\n",
    "try: \n",
    "    trace1 = go.Violin(x=dfsa['Amount'], points='outliers', name='Violin Plot')\n",
    "    trace2 = go.Histogram(x=dfsa['Amount'], name='Historgram')\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    fig.add_trace(trace1, row=1, col=1)\n",
    "    fig.add_trace(trace2, row=2, col=1)\n",
    "\n",
    "    fig.update_layout(showlegend=False, bargap=0.2, title=\"Amount Distribution in sitespecificamounts.csv\", font=dict(family=\"Arial Bold\", size=12,color=\"Black\"))\n",
    "    fig.update_xaxes(title_text=\"Amount Value\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Amount Value\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Num. of Records\", row=2, col=1)\n",
    "    fig.show()\n",
    "    fig.write_image('figures/Amount.png', engine=\"kaleido\")\n",
    "\n",
    "except: print('Could not plot Amount value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b33335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Map of Points sites ----\n",
    "\n",
    "dfstemp = dfstemp_ws.copy()\n",
    "dfstemp = dfstemp[dfstemp['Geometry'] == ''].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "    ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "    gdfstemp = gpd.GeoDataFrame(dfstemp, geometry=gpd.points_from_xy(dfstemp.Longitude.astype(float), dfstemp.Latitude.astype(float)), crs=\"EPSG:4326\")\n",
    "    gplt.pointplot(gdfstemp, hue='WaterSourceTypeCV', edgecolor='lightgray', linewidth=0.5, legend=True, legend_var='hue', ax=ax)\n",
    "    mplt.savefig(format=\"png\", fname='figures/PointMap.png') \n",
    "except:\n",
    "    print('No point data to plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac547593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Map of Polygons ----\n",
    "\n",
    "dfstemp = dfstemp_ws.copy()\n",
    "dfstemp = dfstemp[dfstemp['Geometry'] != \"\"].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "    ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "\n",
    "    dfstemp['Geometry'] = gpd.GeoSeries.from_wkt(dfstemp['Geometry'], crs=\"EPSG:4326\")\n",
    "    gdfstemp = gpd.GeoDataFrame(dfstemp, geometry=dfstemp['Geometry'], crs=\"EPSG:4326\") # covert to geodataframe\n",
    "    gplt.choropleth(gdfstemp, edgecolor='lightgray', linewidth=0.5, hue='WaterSourceTypeCV', legend=True, ax=ax)\n",
    "    mplt.savefig(format=\"png\", fname='figures/PolyMap.png')\n",
    "except:\n",
    "    print('No geometry data to plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc755d8",
   "metadata": {},
   "source": [
    "# Removed Records compared to Source Data\n",
    "- this is working just fine, just want to comment out temporarily for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79220931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explode purge.xlsx files by WaDEUUID, concat together\n",
    "# #################################################################\n",
    "\n",
    "# # Explode watersources_missing.xlsx records by WaDEUUID\n",
    "# dfwspurgeCopy = dfwspurge.assign(WaDEUUID=dfwspurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "# dfwspurgeCopy = dfwspurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# # Explode sites_missing.xlsx records by WaDEUUID\n",
    "# dfspurgeCopy = dfspurge.assign(WaDEUUID=dfspurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "# dfspurgeCopy = dfspurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# # Explode waterallocations_missing.xlsx records by WaDEUUID\n",
    "# dfsapurgeCopy = dfsapurge.assign(WaDEUUID=dfsapurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "# dfsapurgeCopy = dfsapurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# # concat purge dataframes togehter\n",
    "# frames = [dfwspurgeCopy, dfspurgeCopy, dfsapurgeCopy] \n",
    "# dfWaDEUUID = pd.concat(frames)\n",
    "# dfWaDEUUID = dfWaDEUUID.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "# print(len(dfWaDEUUID))\n",
    "# dfWaDEUUID.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c080897",
   "metadata": {},
   "source": [
    "# Custom Queries and Analysis for this Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd0e0c-a221-474b-b10f-5e921100b706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
