{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing (state / organization Name) Regulatory data for WaDE upload.\n",
    "- Purpose:  To preprocess the data into one master file for simple DataFrame creation and extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"G:/Shared drives/WaDE Data/Nebraska/Regulatory\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regulatory Area Data #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV input file\n",
    "inputFile = \"RawInputData/BND_NaturalResourceDistricts_DNR_input.csv\"\n",
    "dfin1 = pd.read_csv(inputFile, encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfin1:\n",
    "    dfin1['WaDEUUID'] = \"re\" + dfin1.index.astype(str)\n",
    "    dfin1.to_csv('RawInputData/BND_NaturalResourceDistricts_DNR_input.zip', compression=dict(method='zip', archive_name='BND_NaturalResourceDistricts_DNR_input.csv'), index=False)\n",
    "\n",
    "\n",
    "print(len(dfin1))\n",
    "dfin1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "dfin1['NRD_Name_A'] = dfin1['NRD_Name_A'].str.strip()\n",
    "dfin1['NRD_Num'] = dfin1['NRD_Num'].astype(str).str.strip()\n",
    "dfin1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL\n",
    "# URL link info was found here: https://www.nrdnet.org/\n",
    "\n",
    "URLdict = {\n",
    "\"1\" : \"https://www.lrnrd.org/\",\n",
    "\"2\" : \"https://www.tribasinnrd.org/\",\n",
    "\"3\" : \"http://www.littlebluenrd.org/\",\n",
    "\"4\" : \"http://www.lbbnrd.net\",\n",
    "\"5\" : \"https://www.nemahanrd.org/\",\n",
    "\"6\" : \"http://www.mrnrd.org\",\n",
    "\"7\" : \"http://www.urnrd.org\",\n",
    "\"8\" : \"https://www.lpsnrd.org/\",\n",
    "\"9\" : \"http://www.upperbigblue.org\",\n",
    "\"10\" : \"www.cpnrd.org\",\n",
    "\"11\" : \"http://www.spnrd.org\",\n",
    "\"12\" : \"http://www.tpnrd.org\",\n",
    "\"13\" : \"http://www.lpnnrd.org\",\n",
    "\"14\" : \"http://www.llnrd.org\",\n",
    "\"15\" : \"http://www.npnrd.org\",\n",
    "\"16\" : \"http://www.upperloupnrd.org\",\n",
    "\"17\" : \"http://www.papionrd.org\",\n",
    "\"18\" : \"http://www.lenrd.org\",\n",
    "\"19\" : \"http://www.uenrd.org\",\n",
    "\"20\" : \"https://lcnrd.nebraska.gov/\",\n",
    "\"21\" : \"http://www.lnnrd.org\",\n",
    "\"22\" : \"http://www.mnnrd.org\",\n",
    "\"23\" : \"http://www.unwnrd.org\"}\n",
    "\n",
    "def retrieveURL(valA):\n",
    "    valA = str(valA).strip()\n",
    "    if valA == '' or pd.isnull(valA):\n",
    "        outString = ''\n",
    "    else:\n",
    "        String1 = valA\n",
    "        try:\n",
    "            outString = URLdict[String1]\n",
    "        except:\n",
    "            outString = ''\n",
    "    return outString\n",
    "\n",
    "\n",
    "dfin1['in_RegulatoryStatuteLink'] = dfin1.apply(lambda row: retrieveURL(row['OBJECTID']), axis=1)\n",
    "dfin1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output for Regulatory Area #1 dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfin1['WaDEUUID']\n",
    "\n",
    "# Date Info\n",
    "df['in_Date'] = \"8/24/2021\"\n",
    "df['in_Year'] = \"2021\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"NEre_O1\"\n",
    "\n",
    "# ReportingUnit Info\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_ReportingUnitName'] = dfin1['NRD_Name_A']\n",
    "df['in_ReportingUnitNativeID'] = \"ne\" + dfin1['NRD_Num']\n",
    "df['in_ReportingUnitProductVersion'] = \"\"\n",
    "df['in_ReportingUnitTypeCV'] = \"Natural Resources Districts\"\n",
    "df['in_ReportingUnitUpdateDate'] = \"\"\n",
    "df['in_StateCV'] = \"NE\"\n",
    "df['in_Geometry'] = \"\" # get below\n",
    "\n",
    "# RegulatoryOverlay Info\n",
    "df['in_OversightAgency'] = dfin1['NRD_Name_A'] + \"NRD\"\n",
    "df['in_RegulatoryDescription'] = \"Natural Resources Districts were created to solve flood control, soil erosion, irrigation run-off, and groundwater quantity and quality issues. Nebraska's NRDs are involved in a wide variety of projects and programs to conserve and protect the state's natural resources. NRDs are charged under state law with 12 areas of responsibility including flood control, soil erosion, groundwater management and many others.\"\n",
    "df['in_RegulatoryName'] = dfin1['NRD_Name_A']\n",
    "df['in_RegulatoryOverlayNativeID'] = dfin1['NRD_Num']\n",
    "df['in_RegulatoryStatusCV'] = \"Active\"\n",
    "df['in_RegulatoryStatute'] = \"\"\n",
    "df['in_RegulatoryStatuteLink'] = dfin1['in_RegulatoryStatuteLink']\n",
    "df['in_StatutoryEffectiveDate'] = \"01/01/1972\"\n",
    "df['in_StatutoryEndDate'] = \"\"\n",
    "df['in_RegulatoryOverlayTypeCV'] = \"Natural Resources Districts\"\n",
    "df['in_WaterSourceTypeCV'] = \"Groundwater\"\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "outdf1 = df.copy()\n",
    "print(len(outdf1))\n",
    "outdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regulatory Area #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc etc,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate DataFrames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outdf1] # list all out dataframes here\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data / data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ensure Empty String / remove string value of \"nan\"\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_ReportingUnitName'] = outdf.apply(lambda row: ensureEmptyString(row['in_ReportingUnitName']), axis=1)\n",
    "outdf['in_ReportingUnitName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_RegulatoryDescription'] = outdf.apply(lambda row: ensureEmptyString(row['in_RegulatoryDescription']), axis=1)\n",
    "outdf['in_RegulatoryDescription'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_RegulatoryName'] = outdf.apply(lambda row: ensureEmptyString(row['in_RegulatoryName']), axis=1)\n",
    "outdf['in_RegulatoryName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of StatutoryEffectiveDate to fit WaDE 2.0 structure\n",
    "outdf['in_StatutoryEffectiveDate'] = pd.to_datetime(outdf['in_StatutoryEffectiveDate'], errors = 'coerce')\n",
    "outdf['in_StatutoryEffectiveDate'] = pd.to_datetime(outdf['in_StatutoryEffectiveDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_StatutoryEffectiveDate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapefile Data\n",
    "- For attaching geometry to reporting unit info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regulatory Area #1 shapefile info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "shapeInputFile = \"RawInputData/shapefiles/BND_NaturalResourceDistricts_DNR.zip\"\n",
    "gdfin1 = gpd.read_file(shapeInputFile)\n",
    "\n",
    "# Realign Geometry Projection\n",
    "gdfin1['geometry'] = gdfin1['geometry'].to_crs(epsg=4326)\n",
    "\n",
    "print(len(gdfin1))\n",
    "gdfin1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shape info to map\n",
    "gdfin1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output for Regulatory Area #1 dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "columnsList = ['in_ReportingUnitNativeID', 'geometry']\n",
    "goutdf1 = pd.DataFrame(columns=columnsList, index=gdfin1.index)\n",
    "\n",
    "goutdf1['in_ReportingUnitNativeID'] = \"ne\" + gdfin1[\"NRD_Num\"].astype(str)  # in_ReportingUnitNativeID needs to match source from above equivlaent datframe\n",
    "goutdf1['geometry'] = gdfin1['geometry']\n",
    "goutdf1 = goutdf1.drop_duplicates().reset_index(drop=True)\n",
    "print(len(goutdf1))\n",
    "goutdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regulatory Area #2 shapefile info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate goutdf shapefile info into single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Basin & Subbasin DataFrames\n",
    "frames = [goutdf1] # add geoutdf dataframes here\n",
    "goutdf = pd.concat(frames).reset_index(drop=True)\n",
    "\n",
    "print(len(goutdf))\n",
    "goutdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(outdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(goutdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out to CSV.\n",
    "outdf.to_csv('RawInputData/Pre_neMain.zip', compression=dict(method='zip', archive_name='Pre_neMain.csv'), index=False)  # The output, save as a zip\n",
    "goutdf.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
