{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Nebraska Allocation data for WaDEQA upload.\n",
    "Date Updated: 10/04/2023\n",
    "Purpose:  To pre-process the Nebraska data into one master file for simple DataFrame creation and extraction\n",
    "\n",
    "### Notes:\n",
    "- asfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import seaborn as sns  # plotting library\n",
    "\n",
    "# ---- API data retrieval ----\n",
    "import requests  # http requests\n",
    "import json  # JSON parse\n",
    "\n",
    "# ---- Cleanup ----\n",
    "import re  # string regular expression manipulation\n",
    "from datetime import datetime  # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- working directory ----\n",
    "workingDirString = \"G:/Shared drives/WaDE Data/Nebraska/WaterAllocation\" # set working directory folder string here\n",
    "os.chdir(workingDirString)\n",
    "print(f'The working Directory is:', workingDirString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POD Surface Water Data\n",
    "- data already pulled from api, used saved csv instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# %%time\n",
    "# # API retrieval\n",
    "# # shoot for 30 pages, that seemed to be all that AllSurfaceWaterPoints offered.\n",
    "# df = pd.DataFrame()\n",
    "# countPage = 1\n",
    "# while countPage < 30:\n",
    "#     url = \"https://nednr.nebraska.gov/IwipApi/api/v1/WaterRights/AllSurfaceWaterPoints?page=\" + str(countPage)\n",
    "#     print(url)\n",
    "\n",
    "#     # store in dataframe\n",
    "#     try:\n",
    "#         responseD = json.loads(requests.get(url).text)\n",
    "#         DtL = responseD['Results']\n",
    "#         length = len(DtL)\n",
    "#         for i in range(length):\n",
    "#             row = pd.DataFrame([DtL[i]])\n",
    "#             df = pd.concat([df, row])\n",
    "#     except:\n",
    "#         print(\"Error, issue with API return.\")\n",
    "    \n",
    "#     countPage = countPage + 1\n",
    "\n",
    "# # # Use only NeNDR Active provided sites\n",
    "# # df = df[df['SourceName'] == 'NeDNR']\n",
    "\n",
    "# print(len(df))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# # explode these list....\n",
    "# dftemp = df.copy()\n",
    "# dftemp = dftemp.explode('NoticeExemptions')\n",
    "# dftemp = dftemp.explode('Notices')\n",
    "# dftemp = dftemp.explode('PointOfDiversions')\n",
    "# dftemp = dftemp.explode('Contacts')\n",
    "\n",
    "# print(len(dftemp))\n",
    "# dftemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# # To unpack column's dictionary value new into separate columns -> contact to existing dataframe -> drop unpacked column\n",
    "# dftemp = pd.concat([dftemp, dftemp[\"RightUse\"].apply(pd.Series)], axis=1).drop(columns=\"RightUse\")\n",
    "# dftemp = pd.concat([dftemp, dftemp[\"NoticeExemptions\"].apply(pd.Series)], axis=1).drop(columns=\"NoticeExemptions\")\n",
    "# dftemp = pd.concat([dftemp, dftemp[\"Notices\"].apply(pd.Series)], axis=1).drop(columns=\"Notices\")\n",
    "# dftemp = pd.concat([dftemp, dftemp[\"PointOfDiversions\"].apply(pd.Series)], axis=1).drop(columns=\"PointOfDiversions\")\n",
    "# dftemp = pd.concat([dftemp, dftemp[\"Contacts\"].apply(pd.Series)], axis=1).drop(columns=\"Contacts\")\n",
    "\n",
    "# print(len(dftemp))\n",
    "# dftemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# # Clean Data\n",
    "# # we don't really need the 'NoticeExemptions' at this time\n",
    "# dropList = ['PumpSheets', 'SpecialConditions', 'NoticeID', 'NoticeType', 'NoticeDate', 'EffectiveDate', 'ReasonForAdminAction', 'Notes', 'DeleteNotice']\n",
    "# dftemp = dftemp.drop(dropList, axis=1).drop_duplicates().reset_index(drop=True)\n",
    "# #dftemp = dftemp.drop(dropList, axis=1)\n",
    "# print(len(dftemp))\n",
    "# dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# # export api data\n",
    "# dftemp.to_csv('AllSurfaceWaterPoints.zip', compression=dict(method='zip', archive_name='AllSurfaceWaterPoints.csv'), index=False)  # The output, save as a zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD Data\n",
    "# read in the above API data that was saved to hard file\n",
    "PoDAAInput = \"RawInputData/AllSurfaceWaterPoints.zip\"\n",
    "dfPoD = pd.read_csv(PoDAAInput).replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfPoD:\n",
    "    dfPoD['WaDEUUID'] = \"neD\" + dfPoD.index.astype(str)\n",
    "    dfPoD.to_csv('RawInputData/AllSurfaceWaterPoints.zip', compression=dict(method='zip', archive_name='AllSurfaceWaterPoints.csv'), index=False)\n",
    "    \n",
    "print(len(dfPoD))\n",
    "dfPoD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-Active AllocationLegalStatusCV Water Rights\n",
    "# We only want Active water rights\n",
    "# We only want active POD sites\n",
    "dfPoD = dfPoD[dfPoD['RightStatus'] == 'Active'].reset_index(drop=True)\n",
    "dfPoD = dfPoD[dfPoD['PODStatus'] == 'Active'].reset_index(drop=True)\n",
    "print(len(dfPoD))\n",
    "dfPoD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign VariableSpecificUUID\n",
    "\n",
    "def assignVariableSpecificUUID(colvA):\n",
    "    outList = ''\n",
    "    colvA = str(colvA).strip()\n",
    "    if colvA == \"CFS\":\n",
    "        outList = \"NEwr_V1\"\n",
    "    if colvA == \"AF\":\n",
    "        outList = \"NEwr_V2\"\n",
    "\n",
    "    return outList\n",
    "\n",
    "dfPoD['in_VariableSpecificUUID'] = dfPoD.apply(lambda row: assignVariableSpecificUUID(row['Units']), axis=1)\n",
    "dfPoD['in_VariableSpecificUUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationFlow_CFS - based on reporeted Unit\n",
    "\n",
    "def assignAllocationFlow_CFS(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"CFS\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfPoD['AllocationFlow_CFS'] = dfPoD.apply(lambda row: assignAllocationFlow_CFS(row['ProGrant'], row['Units']), axis=1)\n",
    "dfPoD['AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationVolume_AF - based on reporeted Unit\n",
    "\n",
    "def assignAllocationVolume_AF(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"AF\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfPoD['AllocationVolume_AF'] = dfPoD.apply(lambda row: assignAllocationVolume_AF(row['ProGrant'], row['Units']), axis=1)\n",
    "dfPoD['AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoD['WaterAllocationNativeURL'] = 'https://nednr.nebraska.gov/dynamic/WaterRights/WaterRights/SWRDetailPage?RightId=' + dfPoD['RightID'].astype(str)\n",
    "dfPoD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfPoD['WaDEUUID']\n",
    "\n",
    "# # Method Info\n",
    "df['in_MethodUUID'] = \"NEwr_M1\" # for surface water\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = dfPoD['in_VariableSpecificUUID']\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"NEwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfPoD['SourceName']\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "df['in_WaterSourceTypeCV'] = \"Surface Water\"\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = \"4326\"\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = dfPoD['HUC12']\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfPoD['LatitudeDecimalDegrees']\n",
    "df['in_Longitude'] = dfPoD['LongitudeDecimalDegrees']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"POD\" + dfPoD['PointOfDiversionID'].replace(\"\", 0).fillna(0).astype(int).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"NE\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfPoD['AllocationFlow_CFS']\n",
    "df['in_AllocationLegalStatusCV'] = dfPoD['RightStatus']\n",
    "df['in_AllocationNativeID'] =  dfPoD['RightID'].replace(\"\", 0).fillna(0).astype(str).str.lower().str.strip()\n",
    "df['in_AllocationOwner'] = dfPoD['FirstName'] + \" \" + dfPoD['LastName']\n",
    "df['in_AllocationPriorityDate'] = dfPoD['PriorityDate']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfPoD['AllocationVolume_AF']\n",
    "df['in_BeneficialUseCategory'] = dfPoD['UseDescription']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfPoD['WaterAllocationNativeURL']\n",
    "\n",
    "outdfPoD = df.copy()\n",
    "outdfPoD = outdfPoD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdfPoD))\n",
    "outdfPoD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POU Surface Water Data\n",
    "- will extract and share some elements from above POD surface water data via RightID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - PoU Shapefile Data\n",
    "# export dataframe as zipped csv\n",
    "pouInput = 'RawInputData/shapefile/BND_SurfaceWaterRights_DNR.zip'\n",
    "dfPOU = gpd.read_file(pouInput).replace(np.nan, \"\").replace(\"nan,nan\", \"\") #geodataframe read\n",
    "dfPOU = dfPOU.drop(['geometry'], axis=1)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfPOU:\n",
    "    dfPOU['WaDEUUID'] = \"waU\" + dfPOU.index.astype(str)\n",
    "    dfPOU.to_csv('RawInputData/BND_SurfaceWaterRights_DNR.zip', compression=dict(method='zip', archive_name='BND_SurfaceWaterRights_DNR.csv'), index=False)\n",
    "\n",
    "print(len(dfPOU))\n",
    "dfPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign VariableSpecificUUID\n",
    "\n",
    "def assignVariableSpecificUUID(colvA):\n",
    "    outList = ''\n",
    "    colvA = str(colvA).strip()\n",
    "    if colvA == \"CFS\":\n",
    "        outList = \"NEwr_V1\"\n",
    "    if colvA == \"AF\":\n",
    "        outList = \"NEwr_V2\"\n",
    "\n",
    "    return outList\n",
    "\n",
    "dfPOU['in_VariableSpecificUUID'] = dfPOU.apply(lambda row: assignVariableSpecificUUID(row['Units']), axis=1)\n",
    "dfPOU['in_VariableSpecificUUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationFlow_CFS - based on reporeted Unit\n",
    "\n",
    "def assignAllocationFlow_CFS(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"CFS\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfPOU['AllocationFlow_CFS'] = dfPOU.apply(lambda row: assignAllocationFlow_CFS(row['ProGrant'], row['Units']), axis=1)\n",
    "dfPOU['AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationVolume_AF - based on reporeted Unit\n",
    "\n",
    "def assignAllocationVolume_AF(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"AF\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfPOU['AllocationVolume_AF'] = dfPOU.apply(lambda row: assignAllocationVolume_AF(row['ProGrant'], row['Units']), axis=1)\n",
    "dfPOU['AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOU['WaterAllocationNativeURL'] = 'https://nednr.nebraska.gov/dynamic/WaterRights/WaterRights/SWRDetailPage?RightId=' + dfPOU['RightID'].astype(str)\n",
    "dfPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOU['RightUse'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfPOU['WaDEUUID']\n",
    "\n",
    "# # Method Info\n",
    "df['in_MethodUUID'] = \"NEwr_M1\" # for surface water\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = dfPOU['in_VariableSpecificUUID']\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"NEwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = dfPOU['SourceName']\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below\n",
    "df['in_WaterSourceTypeCV'] = \"Surface Water\"\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = \"\"\n",
    "df['in_EPSGCodeCV'] = \"4326\"\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = dfPOU['HUC12']\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfPOU['Latitude']\n",
    "df['in_Longitude'] = dfPOU['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POU\"\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = \"POU\" + dfPOU['wadeID'].replace(\"\", 0).fillna(0).astype(str)\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"NE\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = \"\"\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = dfPOU['AllocationFlow_CFS']\n",
    "df['in_AllocationLegalStatusCV'] = \"\"\n",
    "df['in_AllocationNativeID'] =  dfPOU['RightID'].replace(\"\", 0).fillna(0).astype(str).str.lower().str.strip()\n",
    "df['in_AllocationOwner'] = \"\"\n",
    "df['in_AllocationPriorityDate'] = dfPOU['PriorityDa']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfPOU['AllocationVolume_AF']\n",
    "df['in_BeneficialUseCategory'] = dfPOU['RightUse']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = dfPOU['WaterAllocationNativeURL']\n",
    "\n",
    "outdfPoU = df.copy()\n",
    "outdfPoU = outdfPoU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outdfPoU))\n",
    "outdfPoU.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POD Groundwater Data\n",
    "- data already pulled from api, used saved csv instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# # API retrieval\n",
    "# # Checked api website and would allow up to 270 input as page. \n",
    "\n",
    "#columns_to_keep = ['WellID','RegistrationNumber','Status','WellUseDescription','NRDName','CountyName','Location','SurfaceWaterAppropriation','Acres','SeriesType','Pump','OwnerContact','RegistrationDate','CompletionDate','LastChangeDate','Latitude','Longitude']\n",
    "#\n",
    "#df = pd.DataFrame(columns=columns_to_keep)\n",
    "#\n",
    "#countPage = 1\n",
    "#while countPage <= 270:\n",
    "#    url = \"https://nednr.nebraska.gov/IwipApi/api/v1/Wells/AllWells?page=\" + str(countPage)\n",
    "#    print(url)\n",
    "#\n",
    "#    # Store data in DataFrame\n",
    "#    try:\n",
    "#        response = requests.get(url)\n",
    "#        response.raise_for_status()  # Raise an exception for bad status codes (e.g., 404)\n",
    "#        responseD = json.loads(response.text)\n",
    "#        DtL = responseD['Results']\n",
    "#        length = len(DtL)\n",
    "#        for i in range(length):\n",
    "#            row = pd.DataFrame([DtL[i]])\n",
    "#            \n",
    "#            # Check if the 'Status' is 'Active Registered Well' before adding it to the DataFrame\n",
    "#            if row['Status'].iloc[0] == 'Active Registered Well':\n",
    "#                # Select only the desired columns\n",
    "#                row = row[columns_to_keep]\n",
    "#                df = pd.concat([df, row])\n",
    "#    except requests.exceptions.RequestException as e:\n",
    "#        print(f\"Request error: {e}\")\n",
    "#    except json.JSONDecodeError as e:\n",
    "#        print(f\"JSON decoding error: {e}\")\n",
    "#    except KeyError as e:\n",
    "#        print(f\"KeyError: {e}\")\n",
    "    \n",
    "#    countPage = countPage + 1\n",
    "\n",
    "# Reset the DataFrame index\n",
    "#df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#print(len(df))\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# # To unpack column's dictionary value new into separate columns -> contact to existing dataframe -> drop unpacked column\n",
    "#dftemp = df.copy()\n",
    "#dftemp = pd.concat([dftemp, dftemp[\"Pump\"].apply(pd.Series)], axis=1).drop(columns=[\"Pump\",\"PumpColumn_Diameter\",\"PumpDepth\",\"PumpInstallationDate\",\"PumpInstallerContact\"])\n",
    "#dftemp = pd.concat([dftemp, dftemp[\"OwnerContact\"].apply(pd.Series)], axis=1).drop(columns=[\"OwnerContact\",\"ContactId\",\"ContactType\",\"SeqNum\",\"BeginDate\",\"EndDate\",\"Address1\",\"Address2\",\"City\",\"State\",\"Zip\",\"Phone1\",\"Phone2\",\"Phone3\",\"LicenseNumber\",\"IsDeleted\"])\n",
    "\n",
    "#print(len(dftemp))\n",
    "#dftemp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done, skip ahead\n",
    "\n",
    "# # export api data\n",
    "#dftemp.to_csv('AllWells.zip', compression=dict(method='zip', archive_name='AllWells.csv'), index=False)  # The output, save as a zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "FIgw_PoD = \"RawInputData/AllWells.zip\"\n",
    "dfgwinPOD = pd.read_csv(FIgw_PoD, encoding = \"ISO-8859-1\").replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfgwinPOD:\n",
    "    dfgwinPOD['WaDEUUID'] = \"d\" + dfgwinPOD.index.astype(str)\n",
    "    dfgwinPOD.to_csv('RawInputData/AllWells.zip', compression=dict(method='zip', archive_name='AllWells.csv'), index=False)\n",
    "\n",
    "print(len(dfgwinPOD))\n",
    "dfgwinPOD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfgwinPOD['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"NEwr_M2\" # for groundwater\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"NEwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"NEwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"Fresh\"\n",
    "df['in_WaterSourceName'] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\" # auto fill in below if not provdied\n",
    "df['in_WaterSourceTypeCV'] = \"Groundwater\"\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = dfgwinPOD['CountyName']\n",
    "df['in_EPSGCodeCV'] = \"4326\"\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = \"\"\n",
    "df['in_Latitude'] = dfgwinPOD['Latitude']\n",
    "df['in_Longitude'] = dfgwinPOD['Longitude']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = \"POD\"  # \"Point of Diversion\"\n",
    "df['in_SiteName'] = dfgwinPOD['Location']\n",
    "df['in_SiteNativeID'] = \"PODgw\" + dfgwinPOD['WellID'].astype(str).str.strip()\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = dfgwinPOD['SeriesType']\n",
    "df['in_StateCV'] = \"NE\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = dfgwinPOD['RegistrationDate']\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = \"\"\n",
    "df['in_AllocationLegalStatusCV'] = dfgwinPOD['Status']\n",
    "df['in_AllocationNativeID'] = dfgwinPOD['RegistrationNumber']\n",
    "df['in_AllocationOwner'] = dfgwinPOD['FirstName'] + \" \" + dfPoD['LastName']\n",
    "df['in_AllocationPriorityDate'] = \"\"\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfgwinPOD['PumpRate']\n",
    "df['in_BeneficialUseCategory'] = dfgwinPOD['WellUseDescription']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"10/04/2023\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = \"1\"\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = dfgwinPOD['Acres']\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = \"https://nednr.nebraska.gov/Dynamic/Wells/Wells/WellDetails?WellId=\" + dfgwinPOD['WellID'].astype(str).str.strip()\n",
    "\n",
    "outgwPOD = df.copy()\n",
    "outgwPOD = outgwPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(outgwPOD))\n",
    "outgwPOD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "frames = [outdfPoD, outdfPoU, outgwPOD]\n",
    "outdf = pd.concat(frames)\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(outdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data & WaDE Custom Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Sure datatype of HUC12 is int.\n",
    "\n",
    "def assignHUC12(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = ''\n",
    "    else:\n",
    "        outList = int(colrowValue)\n",
    "    return outList\n",
    "\n",
    "outdf['in_HUC12'] = outdf.apply(lambda row: assignHUC12(row['in_HUC12']), axis=1)\n",
    "outdf['in_HUC12'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solving a long benefical use\n",
    "def longBenUseTempFix(val):\n",
    "    if val == \"Supplemental Cooling (an app. for water for cooling through a system that has a prior app. for cooling)\":\n",
    "        outList = \"Supplemental Cooling (app for water for cooling through a system that has a prior app for cooling)\"\n",
    "    elif val == \"Supplemental Irrigation (irrig. from reservoir on lands also covered by a natural flow appropriation)\":\n",
    "        outList = \"Supplemental Irrigation (irrig. from reservoir on lands covered by a natural flow appropriation)\"\n",
    "    else:\n",
    "        outList = val\n",
    "    return outList\n",
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: longBenUseTempFix(row['in_BeneficialUseCategory']), axis=1)\n",
    "\n",
    "for x in outdf['in_BeneficialUseCategory'].sort_values().unique():\n",
    "    print(f'\"' + str(x) + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean owner name up\n",
    "def removeSpecialCharsFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceName'] = outdf.apply(lambda row: removeSpecialCharsFunc(row['in_WaterSourceName']), axis=1)\n",
    "outdf['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_WaterSourceTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_County'] = outdf.apply(lambda row: ensureEmptyString(row['in_County']), axis=1)\n",
    "outdf['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteName'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteName']), axis=1)\n",
    "outdf['in_SiteName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_SiteTypeCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_SiteTypeCV']), axis=1)\n",
    "outdf['in_SiteTypeCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationLegalStatusCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "for x in outdf['in_BeneficialUseCategory'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Longitude\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'])\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str) + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop non-Active AllocationLegalStatusCV Water Rights\n",
    "- For this {state name / organization}, we don't want water rights that are considered: Cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-active AllocationLegalStatusCV values specific to that state.\n",
    "\n",
    "# drop the list\n",
    "dropLegalStatusList = [\"Cancelled\"] # enter string entries here\n",
    "\n",
    "# drop rows from above list\n",
    "outdf = outdf[outdf.in_AllocationLegalStatusCV.isin(dropLegalStatusList) == False].reset_index(drop=True)\n",
    "\n",
    "print(len(outdf))\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching gemetry to csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "dfPoUshapetemp = gpd.read_file('RawInputData/shapefile/BND_SurfaceWaterRights_DNR.zip')\n",
    "print(len(dfPoUshapetemp))\n",
    "dfPoUshapetemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp['wadeID'].replace(\"\", 0).fillna(0).astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to Finished File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('RawInputData/Pwr_neMain.zip', compression=dict(method='zip', archive_name='Pwr_neMain.csv'), index=False)  # The output, save as a zip\n",
    "dfPoUshape.to_csv('RawInputData/P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
