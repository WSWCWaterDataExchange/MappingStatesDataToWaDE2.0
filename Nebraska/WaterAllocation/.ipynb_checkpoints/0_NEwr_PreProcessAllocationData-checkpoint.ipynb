{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Nebraska Allocation data for WaDEQA upload.\n",
    "- Date Updated: 08/26/2020\n",
    "- Purpose:  To preprocess the Nebraska data into one master file for simple DataFrame creation and extraction.\n",
    "- Joining API surface water data - to POD shapefile data via **RightID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Nebraska/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: get NEwr POD data via API service\n",
    "- has nested data, will need to explode lists and transform dictionaries to series and concatenate by row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # already done, see nePODAPIData.zip below\n",
    "\n",
    "# # Get all surface water points from NeDNR API.\n",
    "# # Note: API has lots of NULL values, have to put a hard stop of what to search.\n",
    "# dfsw = pd.DataFrame()\n",
    "# page = 1\n",
    "\n",
    "# # for i in range(length):\n",
    "# while page < 50:\n",
    "#     url = \"https://nednr.nebraska.gov/IwipApi/api/v1/WaterRights/AllSurfaceWaterPoints?page=\" + str(page)\n",
    "#     print(url)\n",
    "#     page = 1 + page\n",
    "#     try:\n",
    "#         responseD = json.loads(requests.get(url).text)\n",
    "#         DLtL = responseD['Results']\n",
    "#         length = len(DLtL)\n",
    "#         for i in range(length):\n",
    "#             row = pd.DataFrame([DLtL[i]])\n",
    "#             dfsw = dfsw.append(row)\n",
    "#     except:\n",
    "#         print(\"...error with url\")\n",
    "\n",
    "# print(len(dfsw))\n",
    "# dfsw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # I think we can drop 'PumpSheets', 'notice', 'SpecialConditions' & 'NoticeExemptions'...\n",
    "# dfsw2 = dfsw.drop(['PumpSheets', 'Notices', 'SpecialConditions', 'NoticeExemptions'], axis=1)\n",
    "\n",
    "# dfsw2 = pd.concat([dfsw2.drop(['RightUse'], axis=1), dfsw2['RightUse'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# dfsw2 = dfsw2.explode('PointOfDiversions')\n",
    "# dfsw2 = dfsw2.explode('Contacts')\n",
    "\n",
    "# dfsw2 = pd.concat([dfsw2.drop(['PointOfDiversions'], axis=1), dfsw2['PointOfDiversions'].apply(pd.Series)], axis=1)\n",
    "# dfsw2 = pd.concat([dfsw2.drop(['Contacts'], axis=1), dfsw2['Contacts'].apply(pd.Series)], axis=1)\n",
    "\n",
    "\n",
    "# dfsw2 = dfsw2.drop_duplicates().reset_index(drop=True)\n",
    "# print(len(dfsw2))\n",
    "# dfsw2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfsw2.to_csv('nePODAPIData.zip', compression=dict(method='zip', archive_name='nePODAPIData.csv'), index=False)\n",
    "# print(len(dfsw2))\n",
    "# dfsw2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - dataframeTimeSeries.zip\n",
    "dfpodin = pd.read_csv('nePODAPIData.zip', compression='zip').replace(np.nan, \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfpodin:\n",
    "    dfpodin['WaDEUUID'] = \"nePOD\" + dfpodin.index.astype(str)\n",
    "    dfpodin.to_csv('nePODAPIData.zip', compression=dict(method='zip', archive_name='nePODAPIData.csv'), index=False)\n",
    "\n",
    "print(len(dfpodin))\n",
    "dfpodin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Beneficial Use from NeDWR Provdied code.  See metaData_SurfaceWaterWebSimpleSearch.pdf for details.\n",
    "\n",
    "NebraskaBenUseCodeDict = {\n",
    "\"CG\" : \"Conducting Groundwater for Irrigation (Source is a Registered Groundwater Well)\",\n",
    "\"CO\" : \"Cooling\",\n",
    "\"CS\" : \"Conducting Surface Water for Irrigation (Uses Water from an Existing Appropriation)\",\n",
    "\"DG\" : \"Dredge\",\n",
    "\"DI\" : \"Domestic, Irrigation and Manufacturing\",\n",
    "\"DO\" : \"Domestic\",\n",
    "\"DS\" : \"Domestic Storage\",\n",
    "\"FC\" : \"Fish Culture\",\n",
    "\"FL\" : \"Flood Control\",\n",
    "\"FW\" : \"Fish and Wildlife\",\n",
    "\"IB\" : \"Instream Basin-Management\",\n",
    "\"IF\" : \"Instream Flow\",\n",
    "\"IG\" : \"Induced Ground Water Recharge\",\n",
    "\"IN\" : \"Intentional Underground Storage\",\n",
    "\"IR\" : \"Irrigation from Natural Stream\",\n",
    "\"IS\" : \"Irrigation and Storage (an appropriation approved for both uses)\",\n",
    "\"IU\" : \"Irrigation and Incidental Underground Storage\",\n",
    "\"MF\" : \"Manufacturing\",\n",
    "\"ML\" : \"Maintain Level of a Lake\",\n",
    "\"MU\" : \"Municipal\",\n",
    "\"NL\" : \"Irrigation from Natural Lake\",\n",
    "\"OU\" : \"Storage (for irr from res on lands not covered by nat flow appropriation / Incidental UG Storage)\",\n",
    "\"PI\" : \"Power and Incidental Underground Storage\",\n",
    "\"PR\" : \"Power\",\n",
    "\"PS\" : \"Supplemental Power and Incidental Underground Storage\",\n",
    "\"PW\" : \"Public Water Supply\",\n",
    "\"RC\" : \"Groundwater Recharge\",\n",
    "\"RD\" : \"Raise Dam (for increase in head for power production)\",\n",
    "\"SC\" : \"Supplemental Cooling (prior appropriation for cooling)\",\n",
    "\"SD\" : \"Supplemental Domestic\",\n",
    "\"SF\" : \"Supplemental Fish Culture\",\n",
    "\"SI\" : \"Supplemental Irrigation (irr from res on lands also covered by nat flow appropriation)\",\n",
    "\"SO\" : \"Storage (for irr from res on lands not covered by nat flow appropriation)\",\n",
    "\"SP\" : \"Supplemental Power (prior appropriation for power)\",\n",
    "\"SS\" : \"Supplemental Storage (prior appropriation for storage)\",\n",
    "\"ST\" : \"Storage\",\n",
    "\"SU\" : \"Storage and Incidental Underground Storage\",\n",
    "\"TI\" : \"Temporary Transfer to In-Stream Use\",\n",
    "\"UI\" : \"Supplemental Irrigation and Incidental Underground Storage\",\n",
    "\"US\" : \"Incidental Underground Storage\",\n",
    "\"WS\" : \"Waste Storage\",\n",
    "\"WT\" : \"Wetlands\"}\n",
    "\n",
    "def assignRightUse(colrowValue):\n",
    "    if colrowValue == \"\" or pd.isnull(colrowValue):\n",
    "        outList = \"WaDE Unspecified\"\n",
    "    else:\n",
    "        String1 = colrowValue.strip()  # remove whitespace chars\n",
    "        try:\n",
    "            outList = NebraskaBenUseCodeDict[String1]\n",
    "        except:\n",
    "            outList = \"WaDE Unspecified\"\n",
    "    return outList\n",
    "\n",
    "dfpodin['BeneficialUseCategory'] = dfpodin.apply(lambda row: assignRightUse(row['UseCode']), axis=1)\n",
    "dfpodin['BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first & last name funciton\n",
    "def assignownerName(fName, lName):\n",
    "    \n",
    "    # Cleaning Text\n",
    "    fName = str(fName)\n",
    "    lName = str(lName)\n",
    "    fName = fName.replace(\"*\", \"\")\n",
    "    lName = lName.replace(\"*\", \"\")      \n",
    "    \n",
    "    # Check if first or last name are empty\n",
    "    if fName == \"\" or pd.isnull(fName):\n",
    "        outList1 = \"\" # use blank value\n",
    "    else:\n",
    "        outList1 = fName.strip()\n",
    "        \n",
    "    if lName == \"\" or pd.isnull(lName):\n",
    "        outList2 = \"\" # use blank value\n",
    "    else:\n",
    "        outList2 = lName.strip()\n",
    "\n",
    "    # ouput\n",
    "    if outList1 == \"\" and outList2 == \"\": # both first and last name are blank\n",
    "        outList = \"WaDE Unspecified\"\n",
    "    elif outList1 == \"\":\n",
    "        outList = outList2 # use last name only\n",
    "    elif outList2 == \"\":\n",
    "        outList = outList1 # use first name only\n",
    "    else:\n",
    "        outList = \" \".join(map(str, [fName, lName]))\n",
    "    return outList\n",
    "\n",
    "dfpodin['in_AllocationOwner'] = dfpodin.apply(lambda row: assignownerName(row['FirstName'], row['LastName']), axis=1)\n",
    "\n",
    "\n",
    "import re\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).strip()\n",
    "    return Val\n",
    "\n",
    "dfpodin['in_AllocationOwner'] = dfpodin.apply(lambda row: cleanOwnerDataFunc(row['in_AllocationOwner']), axis=1)\n",
    "dfpodin['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# AllocationFlow_CFS - based on reporeted Unit\n",
    "\n",
    "def assignAllocationFlow_CFS(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = 0\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"CFS\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = 0\n",
    "    return outList\n",
    "\n",
    "dfpodin['AllocationFlow_CFS'] = dfpodin.apply(lambda row: assignAllocationFlow_CFS(row['ProGrant'], row['Units']), axis=1)\n",
    "dfpodin['AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationVolume_AF - based on reporeted Unit\n",
    "\n",
    "def assignAllocationVolume_AF(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = 0\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"AF\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = 0\n",
    "    return outList\n",
    "\n",
    "dfpodin['AllocationVolume_AF'] = dfpodin.apply(lambda row: assignAllocationVolume_AF(row['ProGrant'], row['Units']), axis=1)\n",
    "dfpodin['AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VariableSpecificCv value\n",
    "def createVariableSpecificCv(unit):\n",
    "    unit = unit.strip()\n",
    "    outString = \"NEwr_V1\"\n",
    "    if unit == \"CFS\":\n",
    "        outString = \"NEwr_V1\"\n",
    "    if unit == \"AF\":\n",
    "        outString = \"NEwr_V2\"\n",
    "\n",
    "    return(outString)\n",
    "\n",
    "dfpodin['in_VariableSpecificUUID'] = dfpodin.apply(lambda row: createVariableSpecificCv(row['Units']), axis=1)\n",
    "dfpodin['in_VariableSpecificUUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the output Dataframe for PODs.\n",
    "\n",
    "dfPOD = pd.DataFrame(index=dfpodin.index)\n",
    "\n",
    "# Data Assessment UUID\n",
    "dfPOD['WaDEUUID'] = dfpodin['WaDEUUID']\n",
    "\n",
    "# Variable\n",
    "dfPOD[\"in_VariableSpecificUUID\"] = dfpodin['in_VariableSpecificUUID']\n",
    "\n",
    "# Water Source\n",
    "dfPOD[\"in_WaterSourceName\"] = dfpodin['SourceName']\n",
    "dfPOD[\"in_WaterSourceTypeCV\"] = \"Surface Water\"\n",
    "\n",
    "# # Site\n",
    "dfPOD[\"in_CoordinateAccuracy\"] = \"WaDE Unspecified\"\n",
    "dfPOD[\"in_CoordinateMethodCV\"] = \"WaDE Unspecified\"\n",
    "dfPOD['in_HUC12'] = dfpodin['HUC12']\n",
    "dfPOD['in_HUC8'] = \"\"\n",
    "dfPOD['in_County'] = dfpodin['CountyName']\n",
    "dfPOD[\"in_Latitude\"] = dfpodin['LatitudeDecimalDegrees.1']\n",
    "dfPOD[\"in_Longitude\"] = dfpodin['LongitudeDecimalDegrees.1']\n",
    "dfPOD[\"in_PODorPOUSite\"] = \"POD\"\n",
    "dfPOD[\"in_SiteName\"] = \"WaDE Unspecified\"\n",
    "dfPOD[\"in_SiteNativeID\"] = \"POD\" + dfpodin['PointOfDiversionID'].astype(str)\n",
    "dfPOD[\"in_SiteTypeCV\"] = \"WaDE Unspecified\"\n",
    "dfPOD[\"in_StateCV\"] = \"NE\"\n",
    "\n",
    "# Allocation\n",
    "dfPOD[\"in_AllocationApplicationDate\"] = \"\"\n",
    "dfPOD[\"in_AllocationExpirationDate\"] = \"\"\n",
    "dfPOD[\"in_AllocationFlow_CFS\"] = dfpodin['AllocationFlow_CFS'].astype(float)\n",
    "dfPOD[\"in_AllocationVolume_AF\"] = dfpodin['AllocationVolume_AF'].astype(float)\n",
    "dfPOD['in_AllocationLegalStatusCV'] = dfpodin['RightStatus'].astype(str)\n",
    "dfPOD[\"in_AllocationNativeID\"] = dfpodin['RightID'].astype(str)\n",
    "dfPOD['in_AllocationOwner'] = dfpodin['in_AllocationOwner']\n",
    "dfPOD['in_AllocationPriorityDate'] = dfpodin['PriorityDate']\n",
    "dfPOD['in_AllocationTimeframeEnd'] = \"\"\n",
    "dfPOD['in_AllocationTimeframeStart'] = \"\"\n",
    "dfPOD['in_AllocationTypeCV'] = \"\"\n",
    "dfPOD[\"in_BeneficialUseCategory\"] = dfpodin['BeneficialUseCategory']\n",
    "dfPOD['in_CommunityWaterSupplySystem'] = \"\"\n",
    "dfPOD['in_ExemptOfVolumeFlowPriority'] = \"0\"\n",
    "dfPOD[\"in_IrrigatedAcreage\"] = \"\"\n",
    "dfPOD[\"in_IrrigationMethodCV\"] = \"\"\n",
    "dfPOD[\"in_WaterAllocationNativeURL\"] = 'https://nednr.nebraska.gov/dynamic/WaterRights/WaterRights/SWRDetailPageForPublic?RightId=' + dfpodin['RightID'].astype(str)\n",
    "\n",
    "dfPOD = dfPOD.drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfPOD))\n",
    "dfPOD.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: NEwr POU data via shapefile\n",
    "- should already be transfomred to WSG format in a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File - dataframeTimeSeries.zip\n",
    "dfpouin = pd.read_csv('BND_SurfaceWaterRights_DNR.zip', compression='zip')\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfpouin:\n",
    "    dfpouin['WaDEUUID'] = \"nePOU\" + dfpouin.index.astype(str)\n",
    "    dfpouin.to_csv('BND_SurfaceWaterRights_DNR.zip', compression=dict(method='zip', archive_name='BND_SurfaceWaterRights_DNR.csv'), index=False)\n",
    "\n",
    "print(len(dfpouin))\n",
    "dfpouin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine some POD data to POU site info\n",
    "dfpouin = pd.merge(dfpouin, dfPOD[['in_AllocationNativeID', 'in_County', 'in_AllocationLegalStatusCV', 'in_AllocationOwner', 'in_BeneficialUseCategory']], left_on=dfpouin['RightID'].astype(str), right_on='in_AllocationNativeID', how='left')\n",
    "print(len(dfpouin))\n",
    "dfpouin.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationFlow_CFS - based on reporeted Unit\n",
    "\n",
    "def assignAllocationFlow_CFS(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = 0\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"CFS\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = 0\n",
    "    return outList\n",
    "\n",
    "dfpouin['AllocationFlow_CFS'] = dfpouin.apply(lambda row: assignAllocationFlow_CFS(row['ProGrant'], row['Units']), axis=1)\n",
    "dfpouin['AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllocationVolume_AF - based on reporeted Unit\n",
    "\n",
    "def assignAllocationVolume_AF(colvA, colvB):\n",
    "    if colvA == '' or pd.isnull(colvA):\n",
    "        outList = 0\n",
    "    else:\n",
    "        colvB = colvB.strip()\n",
    "        if colvB == \"AF\":\n",
    "            outList = colvA\n",
    "        else:\n",
    "            outList = 0\n",
    "    return outList\n",
    "\n",
    "dfpouin['AllocationVolume_AF'] = dfpouin.apply(lambda row: assignAllocationVolume_AF(row['ProGrant'], row['Units']), axis=1)\n",
    "dfpouin['AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VariableSpecificCv value\n",
    "def createVariableSpecificCv(unit):\n",
    "    unit = unit.strip()\n",
    "    outString = \"NEwr_V1\"\n",
    "    if unit == \"CFS\":\n",
    "        outString = \"NEwr_V1\"\n",
    "    if unit == \"AF\":\n",
    "        outString = \"NEwr_V2\"\n",
    "\n",
    "    return(outString)\n",
    "\n",
    "dfpouin['in_VariableSpecificUUID'] = dfpouin.apply(lambda row: createVariableSpecificCv(row['Units']), axis=1)\n",
    "dfpouin['in_VariableSpecificUUID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the output Dataframe for POUs.\n",
    "\n",
    "dfPOU = pd.DataFrame(index=dfpouin.index)\n",
    "\n",
    "# Data Assessment UUID\n",
    "dfPOU['WaDEUUID'] = dfpouin['WaDEUUID']\n",
    "\n",
    "# Variable\n",
    "dfPOU[\"in_VariableSpecificUUID\"] = dfpouin['in_VariableSpecificUUID']\n",
    "\n",
    "# Water Source\n",
    "dfPOU[\"in_WaterSourceName\"] = dfpouin['SourceName']\n",
    "dfPOU[\"in_WaterSourceTypeCV\"] = \"Surface Water\"\n",
    "\n",
    "# Site\n",
    "dfPOU[\"in_CoordinateAccuracy\"] = \"WaDE Unspecified\"\n",
    "dfPOU[\"in_CoordinateMethodCV\"] = \"WaDE Unspecified\"\n",
    "dfPOU['in_HUC12'] = \"\"\n",
    "dfPOU['in_HUC8'] = \"\"\n",
    "dfPOU['in_County'] = dfpouin['in_County']  #from POD data\n",
    "dfPOU[\"in_Latitude\"] = dfpouin['Latitude']\n",
    "dfPOU[\"in_Longitude\"] = dfpouin['Longitude']\n",
    "dfPOU[\"in_PODorPOUSite\"] = \"POU\"\n",
    "dfPOU[\"in_SiteName\"] = \"WaDE Unspecified\"\n",
    "dfPOU[\"in_SiteNativeID\"] = \"POU\" + dfpouin['OBJECTID'].astype(str)\n",
    "dfPOU[\"in_SiteTypeCV\"] = \"WaDE Unspecified\"\n",
    "dfPOU[\"in_StateCV\"] = \"NE\"\n",
    "\n",
    "# # Allocation\n",
    "dfPOU[\"in_AllocationApplicationDate\"] = \"\"\n",
    "dfPOU[\"in_AllocationExpirationDate\"] = \"\"\n",
    "dfPOU[\"in_AllocationFlow_CFS\"] = dfpouin['AllocationFlow_CFS'].astype(float)\n",
    "dfPOU[\"in_AllocationVolume_AF\"] = dfpouin['AllocationVolume_AF'].astype(float)\n",
    "dfPOU['in_AllocationLegalStatusCV'] = dfpouin['in_AllocationLegalStatusCV']  #from POD data\n",
    "dfPOU[\"in_AllocationNativeID\"] = dfpouin['RightID'].astype(str)\n",
    "dfPOU['in_AllocationOwner'] = dfpouin['in_AllocationOwner']  #from POD data\n",
    "dfPOU['in_AllocationPriorityDate'] = dfpouin['PriorityDa']\n",
    "dfPOU['in_AllocationTimeframeEnd'] = \"\"\n",
    "dfPOU['in_AllocationTimeframeStart'] = \"\"\n",
    "dfPOU['in_AllocationTypeCV'] = \"\"\n",
    "dfPOU[\"in_BeneficialUseCategory\"] = dfpouin['in_BeneficialUseCategory']  #from POD data\n",
    "dfPOU['in_CommunityWaterSupplySystem'] = \"\"\n",
    "dfPOU['in_ExemptOfVolumeFlowPriority'] = \"0\"\n",
    "dfPOU[\"in_IrrigatedAcreage\"] = dfpouin['Acres_Orde'].astype(float).fillna(0)\n",
    "dfPOU[\"in_IrrigationMethodCV\"] = \"\"\n",
    "dfPOU[\"in_WaterAllocationNativeURL\"] = 'https://nednr.nebraska.gov/dynamic/WaterRights/WaterRights/SWRDetailPageForPublic?RightId=' + dfpouin['RightID'].astype(str)\n",
    "\n",
    "dfPOU = dfPOU.drop_duplicates().reset_index(drop=True)\n",
    "print(len(dfPOU))\n",
    "dfPOU.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'WaterSourceTypeCV'\n",
    "for x in dfPOU['in_BeneficialUseCategory'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate POD and POU Data.  Clean Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "frames = [dfPOD, dfPOU]\n",
    "dfout = pd.concat(frames)\n",
    "\n",
    "#Removing all NaN Values and replacing with blank\n",
    "dfout = dfout.replace(np.nan, \"\", regex=True).reset_index()\n",
    "\n",
    "print(len(dfout))\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing empty string names\n",
    "\n",
    "def fixEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or pd.isnull(val):\n",
    "        outString = \"WaDE Unspecified\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout['in_WaterSourceName'] = dfout.apply(lambda row: fixEmptyString(row['in_WaterSourceName']), axis=1)\n",
    "dfout['in_WaterSourceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout['in_County'] = dfout.apply(lambda row: fixEmptyString(row['in_County']), axis=1)\n",
    "dfout['in_County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout['in_AllocationLegalStatusCV'] = dfout.apply(lambda row: fixEmptyString(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "dfout['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout['in_BeneficialUseCategory'] = dfout.apply(lambda row: fixEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "dfout['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing null or empty lat and long values\n",
    "dfout['in_Latitude'] = pd.to_numeric(dfout['in_Latitude'], errors='coerce').fillna(0)\n",
    "dfout['in_Longitude'] = pd.to_numeric(dfout['in_Longitude'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype of date fields to fit WaDE.\n",
    "dfout['in_AllocationPriorityDate'] = pd.to_datetime(dfout['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "dfout['in_AllocationPriorityDate'] = pd.to_datetime(dfout[\"in_AllocationPriorityDate\"].dt.strftime('%m/%d/%Y'))\n",
    "dfout['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "dfout['in_AllocationFlow_CFS'] = pd.to_numeric(dfout['in_AllocationFlow_CFS'], errors='coerce').fillna(0)\n",
    "dfout['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "dfout['in_AllocationVolume_AF'] = pd.to_numeric(dfout['in_AllocationVolume_AF'], errors='coerce').fillna(0)\n",
    "dfout['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Sure datatype of HUC12 is int.\n",
    "\n",
    "def assignHUC12(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = ''\n",
    "    else:\n",
    "        outList = int(colrowValue)\n",
    "    return outList\n",
    "\n",
    "dfout['in_HUC12'] = dfout.apply(lambda row: assignHUC12(row['in_HUC12']), axis=1)\n",
    "dfout['in_HUC12'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaDE Custom Elements (due to missing state site info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = dfout['in_WaterSourceName']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "def retrieveWaterSourceNativeID(A):\n",
    "    if (A == '') or (pd.isnull(A)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        ml = dfWaterSourceNativeID.loc[(dfWaterSourceNativeID['in_WaterSourceName'] == A), 'in_WaterSourceNativeID']\n",
    "        if not (ml.empty):  # check if the series is empty\n",
    "            outList = ml.iloc[0]\n",
    "        else:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "dfout['in_WaterSourceNativeID'] = dfout.apply(lambda row: retrieveWaterSourceNativeID(row['in_WaterSourceName']), axis=1)\n",
    "dfout['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching geometry to POU csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "dfPoUshapetemp = gpd.read_file('shapefile/BND_SurfaceWaterRights_DNR.shp')\n",
    "print(len(dfPoUshapetemp))\n",
    "dfPoUshapetemp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp['OBJECTID'].astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "dfPoUshape.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#technique to check datatype of long dataframes.\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dfout.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting output files.\n",
    "dfout.to_csv('Pwr_neWaterRightMain.zip', index=False, compression=\"zip\")  # The output, save as a zip.\n",
    "dfPoUshape.to_csv('Pwr_neGeometry.zip', index=False, compression=\"zip\")  # The output geometry, save as zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
