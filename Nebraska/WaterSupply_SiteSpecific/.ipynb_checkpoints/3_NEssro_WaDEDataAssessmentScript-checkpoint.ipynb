{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f571be",
   "metadata": {},
   "source": [
    "# Data Assessment & Analytics\n",
    "Notes:\n",
    "- change os directory location\n",
    "- be aware of the number of provdied native source data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd # the library that lets us read in shapefiles\n",
    "import geoplot as gplt # for plotting maps\n",
    "import geoplot.crs as gcrs #used to pull in webdata\n",
    "\n",
    "\n",
    "# visulizaiton\n",
    "import missingno as msno # creates a matrix chart to show missing values\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go # for subplot creation\n",
    "from plotly.subplots import make_subplots # for subplot creation\n",
    "import matplotlib.pyplot as mplt # use with gplt to save fig to pdf\n",
    "\n",
    "# Cleanup\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24dccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Nebraska/SS_ReservoirsObservationSites\" # change here\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be custom per state\n",
    "\n",
    "# Input Data\n",
    "#################################################################\n",
    "# Data 1: Stream Gage Data\n",
    "df1 = pd.read_csv(\"RawinputData/P_caStreamObsRecords.zip\", compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data - Processed WaDE Input files\n",
    "#################################################################\n",
    "dfws = pd.read_csv(\"ProcessedInputData/watersources.csv\").replace(np.nan, \"\")\n",
    "dfwspurge = pd.read_csv(\"ProcessedInputData/watersources_missing.csv\").replace(np.nan, \"\")\n",
    "\n",
    "dfs = pd.read_csv(\"ProcessedInputData/sites.csv\").replace(np.nan, \"\")\n",
    "dfspurge = pd.read_csv(\"ProcessedInputData/sites_missing.csv\").replace(np.nan, \"\")\n",
    "\n",
    "dfssro = pd.read_csv(\"ProcessedInputData/sitespecificamounts.csv\").replace(np.nan, \"\")\n",
    "dfssropurge = pd.read_csv(\"ProcessedInputData/sitespecificamounts_missing.csv\").replace(np.nan, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff4e59",
   "metadata": {},
   "source": [
    "# Water Source Info\n",
    "- watersources.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a506fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(dfws))\n",
    "dfws.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.matrix(dfws, figsize=(10,5), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'WaterSourceTypeCV'\n",
    "for x in dfws['WaterSourceTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaterSourceTypeCV: histogram distribution of WaDE values\n",
    "print(dfws.WaterSourceTypeCV.value_counts())\n",
    "\n",
    "fig = px.histogram(dfws, x=\"WaterSourceTypeCV\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of WaterSourceTypeCV Entries in watersource.csv\",\n",
    "                  xaxis_title=\"WaterSourceTypeCV Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('DataAssessment/figures/WaterSourceTypeCV.pdf', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6701f3",
   "metadata": {},
   "source": [
    "# Site Info\n",
    "- sites.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs))\n",
    "dfs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ba2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.matrix(dfs, figsize=(10,5), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'CoordinateMethodCV'\n",
    "for x in dfs['CoordinateMethodCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c269f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'SiteTypeCV'\n",
    "for x in dfs['SiteTypeCV'].sort_values().unique():\n",
    "    print(f'\"' + x + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SiteTypeCV: histogram distribution of WaDE values\n",
    "print(dfs.SiteTypeCV.value_counts())\n",
    "\n",
    "fig = px.histogram(dfs, x=\"SiteTypeCV\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of SiteTypeCV Entries in sites.csv\",\n",
    "                  xaxis_title=\"SiteTypeCV Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('DataAssessment/figures/SiteTypeCV.pdf', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4077ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PODorPOUSite: histogram distribution of WaDE values\n",
    "print(dfs.PODorPOUSite.value_counts())\n",
    "\n",
    "fig = px.histogram(dfs, x=\"PODorPOUSite\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of PODorPOUSite Entries in sites.csv\",\n",
    "                  xaxis_title=\"PODorPOUSite Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('DataAssessment/figures/PODorPOUSite.pdf', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03635fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the site info (this would be lat & long Points only)\n",
    "try:\n",
    "    contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "    ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "    \n",
    "    dfsPoint = dfs.copy()\n",
    "    gdfsPoint = gpd.GeoDataFrame(dfsPoint, geometry=gpd.points_from_xy(dfsPoint.Longitude.astype(float), dfsPoint.Latitude.astype(float)), crs=\"EPSG:4326\")\n",
    "    gplt.pointplot(gdfsPoint, hue='PODorPOUSite', legend=True, legend_var='hue', ax=ax)\n",
    "    mplt.savefig(format=\"pdf\", fname='DataAssessment/figures/PointMap.pdf')\n",
    "    \n",
    "except:\n",
    "    print('No point data to plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map poly info\n",
    "try:\n",
    "    contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "    ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "    \n",
    "    dfsPoly = dfs.copy()\n",
    "    dfsPoly = dfsPoly[dfsPoly['Geometry'] != \"\"].reset_index(drop=True)\n",
    "    dfsPoly['Geometry'] = gpd.GeoSeries.from_wkt(dfsPoly['Geometry'], crs=\"EPSG:4326\")\n",
    "    gdfsPoly = gpd.GeoDataFrame(dfsPoly, geometry=dfsPoly['Geometry'], crs=\"EPSG:4326\") # covert to geodataframe\n",
    "    gdfsPoly['Geometry'] = gdfsPoly.simplify(0.001) # simplify the geometry. Lower the number the larger the exported file.\n",
    "    gplt.polyplot(gdfsPoly, ax=ax)\n",
    "    mplt.savefig(format=\"pdf\", fname='DataAssessment/figures/PolyMap.pdf')\n",
    "except:\n",
    "    print('No geometry data to plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59382d3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfsPoly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68319e",
   "metadata": {},
   "source": [
    "# Site Specific Amount Info\n",
    "- sitespecificamounts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4130bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfssro))\n",
    "dfssro.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a144c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unique values for 'AllocationBasisCV'\n",
    "# for x in dfssro['AllocationBasisCV'].sort_values().unique():\n",
    "#     print(f'\"' + str(x) + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for 'BeneficialUseCategory'\n",
    "uniqueList = list(set([i.strip() for i in ','.join(dfssro['BeneficialUseCategory'].astype(str)).split(',')]))\n",
    "uniqueList.sort()\n",
    "uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns contain missing information.\n",
    "msno.matrix(dfssro, figsize=(10,5), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37758f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Amount: Boxplot distribution of WaDE values\n",
    "# try:\n",
    "#     trace1 = go.Violin(x=dfssro['Amount'], points='outliers', name='Violin Plot')\n",
    "#     trace2 = go.Histogram(x=dfssro['Amount'], name='Historgram')\n",
    "\n",
    "#     fig = make_subplots(rows=2, cols=1)\n",
    "#     fig.add_trace(trace1, row=1, col=1)\n",
    "#     fig.add_trace(trace2, row=2, col=1)\n",
    "\n",
    "#     fig.update_layout(showlegend=False, bargap=0.2, title=\"Amount Distribution in sitespecificamounts.csv\", font=dict(family=\"Arial Bold\", size=12,color=\"Black\"))\n",
    "#     fig.update_xaxes(title_text=\"Amount Value\", row=1, col=1)\n",
    "#     fig.update_xaxes(title_text=\"Amount Value\", row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Num. of Records\", row=2, col=1)\n",
    "#     fig.show()\n",
    "#     fig.write_image('DataAssessment/figures/Amount.pdf', engine=\"kaleido\")\n",
    "\n",
    "# except: print('Could not plot Amount value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcaff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryUseCategory: histogram distribution of WaDE values\n",
    "print(dfssro.PrimaryUseCategory.value_counts())\n",
    "\n",
    "fig = px.histogram(dfssro, x=\"PrimaryUseCategory\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of PrimaryUseCategory Entries in sitespecificamounts.csv\",\n",
    "                  xaxis_title=\"PrimaryUseCategory Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('DataAssessment/figures/PrimaryUseCategory.pdf', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReportYearCV: histogram distribution of WaDE values\n",
    "print(dfssro.ReportYearCV.value_counts())\n",
    "\n",
    "fig = px.histogram(dfssro, x=\"ReportYearCV\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of ReportYearCV Entries in sitespecificamounts.csv\",\n",
    "                  xaxis_title=\"ReportYearCV Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('DataAssessment/figures/ReportYearCV.pdf', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all figure pdfs into single output pdf\n",
    "\n",
    "'''\n",
    "Notes:\n",
    "'merger' is used for merging multiple files into one and merger.append(absfile) will append \n",
    " the files one by one until all pdfs are appended in the result file.\n",
    "'''\n",
    "\n",
    "from PyPDF2 import PdfFileMerger\n",
    "\n",
    "# If files are saved in the folder 'C:\\Users' then Full_Path will be replaced with C:\\Users\n",
    "filePath = str(os.getcwd()) + '/DataAssessment/figures'\n",
    "pdfsList = os.listdir(filePath)\n",
    "print(pdfsList)\n",
    "\n",
    "\n",
    "# os.listdir will create the list of all files in a directory\n",
    "merger = PdfFileMerger(strict=False)\n",
    "\n",
    "for file in pdfsList:\n",
    "    if file.endswith(\".pdf\"):\n",
    "        path_with_file = os.path.join(filePath, file)\n",
    "        print(path_with_file)\n",
    "        merger.append(path_with_file,  import_bookmarks=False )\n",
    "merger.write(\"DataAssessment/Figures Merged Copy.pdf\")\n",
    "\n",
    "merger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc755d8",
   "metadata": {},
   "source": [
    "# Removed Records compared to Source Data\n",
    "- this is working just fine\n",
    "- just want to comment out temporarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79220931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode purge.xlsx files by WaDEUUID, concat together\n",
    "#################################################################\n",
    "\n",
    "# Explode watersources_missing.xlsx records by WaDEUUID\n",
    "dfwspurgeCopy = dfwspurge.assign(WaDEUUID=dfwspurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "dfwspurgeCopy = dfwspurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# Explode sites_missing.xlsx records by WaDEUUID\n",
    "dfspurgeCopy = dfspurge.assign(WaDEUUID=dfspurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "dfspurgeCopy = dfspurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# Explode waterallocations_missing.xlsx records by WaDEUUID\n",
    "dfssropurgeCopy = dfssropurge.assign(WaDEUUID=dfssropurge['WaDEUUID'].str.split(',')).explode('WaDEUUID').reset_index(drop=True)\n",
    "dfssropurgeCopy = dfssropurgeCopy[['WaDEUUID','ReasonRemoved','IncompleteField']]\n",
    "\n",
    "# concat purge dataframes togehter\n",
    "frames = [dfwspurgeCopy, dfspurgeCopy, dfssropurgeCopy] \n",
    "dfWaDEUUID = pd.concat(frames)\n",
    "dfWaDEUUID = dfWaDEUUID.drop_duplicates().reset_index(drop=True).replace(np.nan, \"\")\n",
    "print(len(dfWaDEUUID))\n",
    "dfWaDEUUID.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is custom to the provided data\n",
    "\n",
    "# attach purge dataframe to Native Source Data\n",
    "# Data 1: Stream Gage Data\n",
    "#################################################################\n",
    "\n",
    "if 'ReasonRemoved' in df1:\n",
    "    df1 = df1.drop(['ReasonRemoved', 'IncompleteField'], axis=1)\n",
    "\n",
    "df1Copy = dfWaDEUUID.merge(df1, how='right', on='WaDEUUID')\n",
    "df1Copy = df1Copy.groupby('WaDEUUID').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem!=''])).replace(np.nan, \"\").reset_index()\n",
    "df1Copy.to_csv('RawInputData/P_caStreamObsRecords.zip', compression=dict(method='zip', archive_name='P_caStreamObsRecords.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is custom to the provided data\n",
    "\n",
    "# attach purge dataframe to Native Source Data\n",
    "# Data 2: Reservoir Level Data\n",
    "#################################################################\n",
    "\n",
    "if 'ReasonRemoved' in df2:\n",
    "    df2 = df2.drop(['ReasonRemoved', 'IncompleteField'], axis=1)\n",
    "\n",
    "df2Copy = dfWaDEUUID.merge(df2, how='right', on='WaDEUUID')\n",
    "df2Copy = df2Copy.groupby('WaDEUUID').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem!=''])).replace(np.nan, \"\").reset_index()\n",
    "df2Copy.to_csv('RawInputData/P_caReservoirObsRecords.zip', compression=dict(method='zip', archive_name='P_caReservoirObsRecords.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c080897",
   "metadata": {},
   "source": [
    "# Custom Queries and Analysis for this Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b385767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
