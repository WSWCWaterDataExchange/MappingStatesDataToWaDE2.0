{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Nebraska Reservoir and Observation Site data for WaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Nebraska/SS_ReservoirsObservationSites/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Site Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done already\n",
    "\n",
    "# %%time\n",
    "# # Retrieve list of only NeDNRstream gage stations\n",
    "# #######################################\n",
    "\n",
    "# # API retrieval\n",
    "# url = \"https://nednr.nebraska.gov/IwipApi/api/v1/StreamGage/GetStationList\"\n",
    "# responseD = json.loads(requests.get(url).text)\n",
    "# DtL = responseD['Results']\n",
    "# length = len(DtL)\n",
    "\n",
    "# # create dataframe and store\n",
    "# df = pd.DataFrame()\n",
    "# for i in range(length):\n",
    "#     row = pd.DataFrame([DtL[i]])\n",
    "#     df = pd.concat([df, row])\n",
    "\n",
    "# # Use only NeNDR Active provided sites\n",
    "# df = df[df['SourceName'] == 'NeDNR']\n",
    "\n",
    "# # Exporting output files.\n",
    "# df.to_csv('StreamGageGetStationList.csv', index=False)  # The output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one we want to test out\n",
    "\n",
    "# Input File - StreamGageGetStationList.csv\n",
    "sgInput = \"StreamGageGetStationList.csv\"\n",
    "dfsg = pd.read_csv(sgInput)\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfsg:\n",
    "    dfsg['WaDEUUID'] = \"nebRG\" + dfsg.index.astype(str)\n",
    "    dfsg.to_csv('StreamGageGetStationList.csv', index=False)\n",
    "\n",
    "dfsg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update StationNumber values must have 8 digits, with leading 0s\n",
    "\n",
    "def updateStationNumber(x):\n",
    "    x = str(x).strip()\n",
    "    if len(x) == 4:\n",
    "        x = \"0000\" + x\n",
    "    if len(x) == 5:\n",
    "        x = \"000\" + x\n",
    "    if len(x) == 6:\n",
    "        x = \"00\" + x\n",
    "    if len(x) == 7:\n",
    "        x = \"0\" + x\n",
    "    return x\n",
    "\n",
    "dfsg['StationNumber'] = dfsg.apply(lambda row: updateStationNumber(row['StationNumber']), axis=1)\n",
    "dfsg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of StationNumber\n",
    "streamgageIdList = dfsg['StationNumber'].tolist()   \n",
    "print(len(streamgageIdList))\n",
    "streamgageIdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DailyMeanByYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get timeseires without using the year list\n",
    "\n",
    "# %%time\n",
    "# # get timeseries results\n",
    "# # use StationNumber in url\n",
    "\n",
    "# # create empty dataframe\n",
    "# dfts = pd.DataFrame()\n",
    "\n",
    "# sglength = len(streamgageIdList)\n",
    "# for i in range(sglength):\n",
    "#     serviceStr = \"DailyMeanByYear\" # change here\n",
    "#     url = \"https://nednr.nebraska.gov/IwipApi/api/v1/StreamGage/\" + serviceStr + \"?StationNumber=\" + str(streamgageIdList[i])\n",
    "#     try:\n",
    "#         responseD = json.loads(requests.get(url).text)\n",
    "#         DtL = responseD['Results']\n",
    "\n",
    "#         # store in dataframe\n",
    "#         dftemp = pd.DataFrame()\n",
    "#         length = len(DtL)\n",
    "#         for x in range(length):\n",
    "#             row = pd.DataFrame([DtL[x]])\n",
    "#             row['url'] = url\n",
    "#             row['service'] = serviceStr\n",
    "#             dftemp = pd.concat([dftemp, row])\n",
    "\n",
    "#         dfts = pd.concat([dfts, dftemp])\n",
    "    \n",
    "#     except:\n",
    "#         dftemp = pd.DataFrame()\n",
    "#         dftemp['url'] = url\n",
    "#         dfts = pd.concat([dfts, dftemp])\n",
    "#         print(\"Error, issue with API return.\")\n",
    "\n",
    "# dfts.to_csv('DailyMeanByYear.csv', index=False)  # The output.\n",
    "# print(len(dfts))\n",
    "# dfts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year list\n",
    "yearList = [\"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\",\n",
    "            \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\",\n",
    "            \"2020\", \"2021\", \"2022\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get timeseries results\n",
    "# use StationNumber in url\n",
    "\n",
    "# create empty dataframe\n",
    "dfts = pd.DataFrame()\n",
    "\n",
    "sgLength = len(streamgageIdList)\n",
    "ylLength = len(yearList)\n",
    "\n",
    "for i in range(sgLength):\n",
    "    serviceStr = \"DailyMeanByYear\" # change here\n",
    "    for j in range(ylLength):\n",
    "        url = \"https://nednr.nebraska.gov/IwipApi/api/v1/StreamGage/\" + serviceStr + \"?StationNumber=\" + str(streamgageIdList[i]) + \"&MeanYear=\" + str(yearList[j])\n",
    "        print(url)\n",
    "        try:\n",
    "            responseD = json.loads(requests.get(url).text)\n",
    "            DtL = responseD['Results']\n",
    "\n",
    "            # store in dataframe\n",
    "            dftemp = pd.DataFrame()\n",
    "            length = len(DtL)\n",
    "            for x in range(length):\n",
    "                row = pd.DataFrame([DtL[x]])\n",
    "                row['url'] = url\n",
    "                row['service'] = serviceStr\n",
    "                dftemp = pd.concat([dftemp, row])\n",
    "\n",
    "            dfts = pd.concat([dfts, dftemp])\n",
    "        except:\n",
    "            dftemp = pd.DataFrame()\n",
    "            dftemp['url'] = url\n",
    "            dfts = pd.concat([dfts, dftemp])\n",
    "            print(\"Error, issue with API return.\")\n",
    "\n",
    "print(len(dfts))\n",
    "dfts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update StationNumber values must have 8 digits, with leading 0s\n",
    "\n",
    "def updateStationNumber(x):\n",
    "    x = str(x).strip()\n",
    "    if len(x) == 4:\n",
    "        x = \"0000\" + x\n",
    "    if len(x) == 5:\n",
    "        x = \"000\" + x\n",
    "    if len(x) == 6:\n",
    "        x = \"00\" + x\n",
    "    if len(x) == 7:\n",
    "        x = \"0\" + x\n",
    "    return x\n",
    "\n",
    "dfts['StationNumber'] = dfts.apply(lambda row: updateStationNumber(row['StationNumber']), axis=1)\n",
    "dfts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Merging dataframes into one, using left-join.\n",
    "df = pd.merge(dfts, dfsg, on='StationNumber', how='left')\n",
    "print(len(df))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe\n",
    "dfout = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Site Info\n",
    "dfout['in_Latitude'] = df['Latitude']\n",
    "dfout['in_Longitude'] = df['Longitude']\n",
    "dfout['in_PODorPOUSite'] = \"Observation Site\"\n",
    "dfout['in_SiteName'] = df['StationName']\n",
    "dfout['in_SiteNativeID'] = df['StationNumber']\n",
    "dfout['in_SiteTypeCV'] = df['StationTypeDescription']\n",
    "\n",
    "# Site VariableAmounts Info\n",
    "dfout['in_Amount'] = df['Value']\n",
    "dfout['in_BeneficialUseCategory'] = \"Unspecified\"\n",
    "dfout['in_ReportYearCV'] = df['Date']\n",
    "dfout['in_TimeframeEnd'] = df['Date']\n",
    "dfout['in_TimeframeStart'] = df['Date']\n",
    "\n",
    "print(len(dfout))\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout.info()\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert History Year to YYYY-MM-DD format.\n",
    "dfout['in_TimeframeEnd'] = pd.to_datetime(dfout['in_TimeframeEnd'], utc=True)\n",
    "dfout['in_TimeframeEnd'] = pd.to_datetime(dfout[\"in_TimeframeEnd\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout['in_TimeframeStart'] = pd.to_datetime(dfout['in_TimeframeStart'], utc=True)\n",
    "dfout['in_TimeframeStart'] = pd.to_datetime(dfout[\"in_TimeframeStart\"].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year out\n",
    "dfout['in_ReportYearCV'] = pd.to_datetime(dfout['in_ReportYearCV'], utc=True)\n",
    "dfout['in_ReportYearCV'] = pd.to_datetime(dfout[\"in_ReportYearCV\"].dt.strftime('%m/%d/%Y'))\n",
    "dfout['in_ReportYearCV'] = dfout['in_ReportYearCV'].dt.year\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude & in_Longitude\n",
    "dfout['in_Latitude'] = pd.to_numeric(dfout['in_Latitude'], errors='coerce').fillna(0)\n",
    "dfout['in_Longitude'] = pd.to_numeric(dfout['in_Longitude'], errors='coerce').fillna(0)\n",
    "dfout.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dfout.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to Finished File\n",
    "dfout.to_csv('P_neSSRGMain.csv', index=False)  # The output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
