{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Oklahoma Allocation data for WaDEQA upload.\n",
    "Date Updated: 04/07/2020\n",
    "Purpose:  To pre-process the Oklahoma data into one master file for simple DataFrame creation and extraction.  To validate datatypes and other data related informattion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "\n",
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visulizaiton\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# API retrieval\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Cleanup\n",
    "import re\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory and Input File\n",
    "workingDir = \"G:/Shared drives/WaDE Data/Oklahoma/WaterAllocation/RawInputData\"\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POD Division Data\n",
    "- groundwater wells\n",
    "- surface water divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundwater\n",
    "# Input File\n",
    "PGW_Input = \"Permitted_Groundwater_Wells_input.zip\"\n",
    "df_PGW = pd.read_csv(PGW_Input).replace(np.nan, \"\").replace (\"nan,nan\", \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in df_PGW:\n",
    "    df_PGW['WaDEUUID'] = \"okGD\" + df_PGW.index.astype(str)\n",
    "    df_PGW.to_csv('Permitted_Groundwater_Wells_input.zip', compression=dict(method='zip', archive_name='Permitted_Groundwater_Wells_input.csv'), index=False)\n",
    "\n",
    "print(len(df_PGW))\n",
    "df_PGW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface Water\n",
    "# Input File\n",
    "PSWDP_Input = \"Permitted_Surface_Water_Diversion_Points_input.csv\"\n",
    "df_PSWDP = pd.read_csv(PSWDP_Input).replace(np.nan, \"\").replace (\"nan,nan\", \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in df_PSWDP:\n",
    "    df_PSWDP['WaDEUUID'] = \"okSD\" + df_PSWDP.index.astype(str)\n",
    "    df_PSWDP.to_csv('Permitted_Surface_Water_Diversion_Points_input.zip', compression=dict(method='zip', archive_name='Permitted_Surface_Water_Diversion_Points_input.csv'), index=False)\n",
    "\n",
    "print(len(df_PSWDP))\n",
    "df_PSWDP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate - Both datasets share the same columns.\n",
    "dfPOD = pd.concat([df_PGW, df_PSWDP], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "print(len(dfPOD))\n",
    "dfPOD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing datatype of used date fields. \n",
    "dfPOD['DATE_FILED'] = pd.to_datetime(dfPOD['DATE_FILED'], errors = 'coerce')\n",
    "dfPOD['DATE_FILED'] = pd.to_datetime(dfPOD['DATE_FILED'].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfPOD['DATE_ISSUED'] = pd.to_datetime(dfPOD['DATE_ISSUED'], errors = 'coerce')\n",
    "dfPOD['DATE_ISSUED'] = pd.to_datetime(dfPOD['DATE_ISSUED'].dt.strftime('%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating WaDE Custom site native ID for easy site identificaiion\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Create temp SiteNativeID dataframe of unique site.\n",
    "# def assignSiteUUID(colrowValue):\n",
    "#     string1 = str(colrowValue)\n",
    "#     outstring = \"wadeID\" + string1\n",
    "#     return outstring\n",
    "\n",
    "# dfSiteNativeID = pd.DataFrame()\n",
    "# dfSiteNativeID['in_Latitude'] = dfPOD['LATITUDE']\n",
    "# dfSiteNativeID['in_Longitude'] = dfPOD['LONGITUDE']\n",
    "# dfSiteNativeID = dfSiteNativeID.drop_duplicates()\n",
    "\n",
    "# dftemp = pd.DataFrame(index=dfSiteNativeID.index)\n",
    "# dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "# dfSiteNativeID['in_SiteNativeID'] = dftemp.apply(lambda row: assignSiteUUID(row['Count']), axis=1)\n",
    "# dfSiteNativeID['linkKey'] = dfSiteNativeID['in_Latitude'].astype(str) + dfSiteNativeID['in_Longitude'].astype(str)\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Retreive WaDE Custom site native ID\n",
    "# SiteNativeIDdict = pd.Series(dfSiteNativeID.in_SiteNativeID.values, index=dfSiteNativeID.linkKey.astype(str)).to_dict()\n",
    "# def retrieveSiteNativeID(A, B):\n",
    "#     if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "#         outList = ''\n",
    "#     else:\n",
    "#         colrowValue = str(A).strip() + str(B).strip()\n",
    "#         try:\n",
    "#             outList = SiteNativeIDdict[colrowValue]\n",
    "#         except:\n",
    "#             outList = ''\n",
    "#     return outList\n",
    "\n",
    "# dfPOD['in_SiteNativeID'] = dfPOD.apply(lambda row: retrieveSiteNativeID( row['LATITUDE'], row['LONGITUDE']), axis=1)\n",
    "# dfPOD['in_SiteNativeID'] = \"POD\" + dfPOD['in_SiteNativeID'].astype(str)\n",
    "# dfPOD.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOD['in_PODorPOUSite'] = \"POD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOD['in_SiteNativeID'] = \"POD\" + dfPOD['RECORD_ID'].astype(str).str.strip()\n",
    "dfPOD['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place of Use Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input File\n",
    "AOU_Input = \"OK_AreasofUse_input.zip\"\n",
    "dfPOU = pd.read_csv(AOU_Input).replace(np.nan, \"\").replace (\"nan,nan\", \"\")\n",
    "\n",
    "# WaDE UUID tracker for data assessment\n",
    "if 'WaDEUUID' not in dfPOU:\n",
    "    dfPOU['WaDEUUID'] = \"okU\" + dfPOU.index.astype(str)\n",
    "    dfPOU.to_csv('OK_AreasofUse_input.zip', compression=dict(method='zip', archive_name='OK_AreasofUse_input.csv'), index=False)\n",
    "\n",
    "print(len(dfPOU))\n",
    "dfPOU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing datatype of used date fields. \n",
    "dfPOU['DATE_FILED'] = pd.to_datetime(dfPOU['DATE_FILED'], errors = 'coerce')\n",
    "dfPOU['DATE_FILED'] = pd.to_datetime(dfPOU['DATE_FILED'].dt.strftime('%m/%d/%Y'))\n",
    "\n",
    "dfPOU['DATE_ISSUED'] = pd.to_datetime(dfPOU['DATE_ISSUED'], errors = 'coerce')\n",
    "dfPOU['DATE_ISSUED'] = pd.to_datetime(dfPOU['DATE_ISSUED'].dt.strftime('%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating WaDE Custom site native ID for easy site identificaiion\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Create temp SiteNativeID dataframe of unique site.\n",
    "# def assignSiteUUID(colrowValue):\n",
    "#     string1 = str(colrowValue)\n",
    "#     outstring = \"wadeID\" + string1\n",
    "#     return outstring\n",
    "\n",
    "# dfSiteNativeID = pd.DataFrame()\n",
    "# dfSiteNativeID['in_Latitude'] = dfPOU['LATITUDE']\n",
    "# dfSiteNativeID['in_Longitude'] = dfPOU['LONGITUDE']\n",
    "# dfSiteNativeID = dfSiteNativeID.drop_duplicates()\n",
    "\n",
    "# dftemp = pd.DataFrame(index=dfSiteNativeID.index)\n",
    "# dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "# dfSiteNativeID['in_SiteNativeID'] = dftemp.apply(lambda row: assignSiteUUID(row['Count']), axis=1)\n",
    "# dfSiteNativeID['linkKey'] = dfSiteNativeID['in_Latitude'].astype(str) + dfSiteNativeID['in_Longitude'].astype(str)\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Retreive WaDE Custom site native ID\n",
    "# SiteNativeIDdict = pd.Series(dfSiteNativeID.in_SiteNativeID.values, index=dfSiteNativeID.linkKey.astype(str)).to_dict()\n",
    "# def retrieveSiteNativeID(A, B):\n",
    "#     if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "#         outList = ''\n",
    "#     else:\n",
    "#         colrowValue = str(A).strip() + str(B).strip()\n",
    "#         try:\n",
    "#             outList = SiteNativeIDdict[colrowValue]\n",
    "#         except:\n",
    "#             outList = ''\n",
    "#     return outList\n",
    "\n",
    "# dfPOU['in_SiteNativeID'] = dfPOU.apply(lambda row: retrieveSiteNativeID( row['LATITUDE'], row['LONGITUDE']), axis=1)\n",
    "# dfPOU['in_SiteNativeID'] = \"POU\" + dfPOU['in_SiteNativeID'].astype(str)\n",
    "# dfPOU.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOU['in_PODorPOUSite'] = \"POU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOU['in_SiteNativeID'] = \"POU\" + dfPOU['RECORD_ID'].astype(str).str.strip()\n",
    "dfPOU['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concaenate POD and POU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "# Both datasets share the same columns.\n",
    "dfin = pd.concat([dfPOD, dfPOU], ignore_index=True).reset_index(drop=True).replace(np.nan, '')\n",
    "\n",
    "print(len(dfin))\n",
    "dfin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing Beneficial Uses PRIMARY_PURPOSE\n",
    "def fixRecFishWild(colrowValue):\n",
    "    colrowValue = str(colrowValue).strip()\n",
    "    if colrowValue == 'Recreation, Fish, Wildlife':\n",
    "        outList = 'Recreation Fish Wildlife'\n",
    "    else:\n",
    "        outList = colrowValue\n",
    "    return outList\n",
    "\n",
    "dfin['PRIMARY_PURPOSE'] = dfin.apply(lambda row: fixRecFishWild(row['PRIMARY_PURPOSE']), axis=1)\n",
    "dfin['PRIMARY_PURPOSE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output POD dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data Assessment UUID\n",
    "df['WaDEUUID'] = dfin['WaDEUUID']\n",
    "\n",
    "# Method Info\n",
    "df['in_MethodUUID'] = \"OKwr_M1\"\n",
    "\n",
    "# Variable Info\n",
    "df['in_VariableSpecificUUID'] = \"OKwr_V1\"\n",
    "\n",
    "# Organization Info\n",
    "df['in_OrganizationUUID'] = \"OKwr_O1\"\n",
    "\n",
    "# WaterSource Info\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISFeatureNameCV'] = \"\"\n",
    "df['in_WaterQualityIndicatorCV'] = \"\"\n",
    "df['in_WaterSourceName'] = \"\"\n",
    "df['in_WaterSourceNativeID'] = \"\"\n",
    "df['in_WaterSourceTypeCV'] = dfin['WATER']\n",
    "\n",
    "# Site Info\n",
    "df['in_CoordinateAccuracy'] = \"\"\n",
    "df['in_CoordinateMethodCV'] = \"\"\n",
    "df['in_County'] = dfin['COUNTY']\n",
    "df['in_EPSGCodeCV'] = 4326\n",
    "df['in_Geometry'] = \"\"\n",
    "df['in_GNISCodeCV'] = \"\"\n",
    "df['in_HUC12'] = \"\"\n",
    "df['in_HUC8'] = dfin['HYDRO_UNIT'].replace(\"\", 0).replace(\" \", 0).fillna(0).astype(float).astype(int).astype(str).replace(\"0\", \"\") # see above\n",
    "df['in_Latitude'] = dfin['LATITUDE']\n",
    "df['in_Longitude'] = dfin['LONGITUDE']\n",
    "df['in_NHDNetworkStatusCV'] = \"\"\n",
    "df['in_NHDProductCV'] = \"\"\n",
    "df['in_PODorPOUSite'] = dfin['in_PODorPOUSite'] # see above\n",
    "df['in_SiteName'] = \"\"\n",
    "df['in_SiteNativeID'] = dfin['in_SiteNativeID'].replace(\"\", 0).fillna(0).astype(str) # see above\n",
    "df['in_SitePoint'] = \"\"\n",
    "df['in_SiteTypeCV'] = \"\"\n",
    "df['in_StateCV'] = \"OK\"\n",
    "df['in_USGSSiteID'] = \"\"\n",
    "\n",
    "# AllocationAmount Info\n",
    "df['in_AllocationApplicationDate'] = dfin['DATE_FILED']\n",
    "df['in_AllocationAssociatedConsumptiveUseSiteIDs'] = \"\"\n",
    "df['in_AllocationAssociatedWithdrawalSiteIDs'] = \"\"\n",
    "df['in_AllocationBasisCV'] = \"\"\n",
    "df['in_AllocationChangeApplicationIndicator'] = \"\"\n",
    "df['in_AllocationCommunityWaterSupplySystem'] = \"\"\n",
    "df['in_AllocationCropDutyAmount'] = \"\"\n",
    "df['in_AllocationExpirationDate'] = \"\"\n",
    "df['in_AllocationFlow_CFS'] = \"\"\n",
    "df['in_AllocationLegalStatusCV'] = dfin['STATUS']\n",
    "df['in_AllocationNativeID'] =  dfin['PERMIT_NUMBER'].replace(\"\", 0).fillna(0).astype(str)\n",
    "df['in_AllocationOwner'] = dfin['ENTITY_NAME']\n",
    "df['in_AllocationPriorityDate'] = dfin['DATE_ISSUED']\n",
    "df['in_AllocationSDWISIdentifierCV'] = \"\"\n",
    "df['in_AllocationTimeframeEnd'] = \"\"\n",
    "df['in_AllocationTimeframeStart'] = \"\"\n",
    "df['in_AllocationTypeCV'] = \"\"\n",
    "df['in_AllocationVolume_AF'] = dfin['TOTAL_PERMITTED_ACRE_FEET']\n",
    "df['in_BeneficialUseCategory'] = dfin['PRIMARY_PURPOSE']\n",
    "df['in_CommunityWaterSupplySystem'] = \"\"\n",
    "df['in_CropTypeCV'] = \"\"\n",
    "df['in_CustomerTypeCV'] = \"\"\n",
    "df['in_DataPublicationDate'] = \"\"\n",
    "df['in_DataPublicationDOI'] = \"\"\n",
    "df['in_ExemptOfVolumeFlowPriority'] = 0\n",
    "df['in_GeneratedPowerCapacityMW'] = \"\"\n",
    "df['in_IrrigatedAcreage'] = \"\"\n",
    "df['in_IrrigationMethodCV'] = \"\"\n",
    "df['in_LegacyAllocationIDs'] = \"\"\n",
    "df['in_OwnerClassificationCV'] = \"\"\n",
    "df['in_PopulationServed'] = \"\"\n",
    "df['in_PowerType'] = \"\"\n",
    "df['in_PrimaryBeneficialUseCategory'] = \"\"\n",
    "df['in_SDWISIdentifierCV'] = \"\"\n",
    "df['in_WaterAllocationNativeURL'] = \"\"\n",
    "\n",
    "outdf = df.copy()\n",
    "outdf = outdf.drop_duplicates().reset_index(drop=True).replace(np.nan, '')\n",
    "print(len(outdf))\n",
    "outdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean owner name up\n",
    "def cleanOwnerDataFunc(Val):\n",
    "    Val = str(Val)\n",
    "    Val = re.sub(\"[$@&.;,/\\)(-]\", \"\", Val).title().replace(\"  \", \" \").strip()\n",
    "    return Val\n",
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: cleanOwnerDataFunc(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Empty String\n",
    "\n",
    "def ensureEmptyString(val):\n",
    "    val = str(val).strip()\n",
    "    if val == \"\" or val == \" \" or val == \"nan\" or pd.isnull(val):\n",
    "        outString = \"\"\n",
    "    else:\n",
    "        outString = val\n",
    "    return outString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationLegalStatusCV'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationLegalStatusCV']), axis=1)\n",
    "outdf['in_AllocationLegalStatusCV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_AllocationOwner'] = outdf.apply(lambda row: ensureEmptyString(row['in_AllocationOwner']), axis=1)\n",
    "outdf['in_AllocationOwner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf['in_BeneficialUseCategory'] = outdf.apply(lambda row: ensureEmptyString(row['in_BeneficialUseCategory']), axis=1)\n",
    "outdf['in_BeneficialUseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Latitude\n",
    "outdf['in_Latitude'] = pd.to_numeric(outdf['in_Latitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_Longitude\n",
    "outdf['in_Longitude'] = pd.to_numeric(outdf['in_Longitude'], errors='coerce').fillna(\"\")\n",
    "outdf['in_Longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update datatype of Priority Date to fit WaDE 2.0 structure\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'], errors = 'coerce')\n",
    "outdf['in_AllocationPriorityDate'] = pd.to_datetime(outdf['in_AllocationPriorityDate'].dt.strftime('%m/%d/%Y'))\n",
    "outdf['in_AllocationPriorityDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationFlow_CFS datatype\n",
    "outdf['in_AllocationFlow_CFS'] = pd.to_numeric(outdf['in_AllocationFlow_CFS'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationFlow_CFS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing in_AllocationVolume_AF datatype\n",
    "outdf['in_AllocationVolume_AF'] = pd.to_numeric(outdf['in_AllocationVolume_AF'], errors='coerce').replace(0,\"\").fillna(\"\")\n",
    "outdf['in_AllocationVolume_AF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating WaDE Custom water source native ID for easy water source identification\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create temp WaterSourceNativeID dataframe of unique water source.\n",
    "def assignWaterSourceNativeID(colrowValue):\n",
    "    string1 = str(colrowValue)\n",
    "    outstring = \"wadeID\" + string1\n",
    "    return outstring\n",
    "\n",
    "dfWaterSourceNativeID = pd.DataFrame()\n",
    "dfWaterSourceNativeID['in_WaterSourceName'] = outdf['in_WaterSourceName']\n",
    "dfWaterSourceNativeID['in_WaterSourceTypeCV'] = outdf['in_WaterSourceTypeCV']\n",
    "dfWaterSourceNativeID = dfWaterSourceNativeID.drop_duplicates()\n",
    "\n",
    "dftemp = pd.DataFrame(index=dfWaterSourceNativeID.index)\n",
    "dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "dfWaterSourceNativeID['in_WaterSourceNativeID'] = dftemp.apply(lambda row: assignWaterSourceNativeID(row['Count']), axis=1)\n",
    "dfWaterSourceNativeID['linkKey'] = dfWaterSourceNativeID['in_WaterSourceName'].astype(str) + dfWaterSourceNativeID['in_WaterSourceTypeCV'].astype(str)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Retreive WaDE Custom water source native ID\n",
    "WaterSourceNativeIDdict = pd.Series(dfWaterSourceNativeID.in_WaterSourceNativeID.values, index=dfWaterSourceNativeID.linkKey.astype(str)).to_dict()\n",
    "def retrieveWaterSourceNativeID(A, B):\n",
    "    if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "        outList = ''\n",
    "    else:\n",
    "        colrowValue = str(A).strip() + str(B).strip()\n",
    "        try:\n",
    "            outList = WaterSourceNativeIDdict[colrowValue]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "\n",
    "outdf['in_WaterSourceNativeID'] = outdf.apply(lambda row: retrieveWaterSourceNativeID( row['in_WaterSourceName'], row['in_WaterSourceTypeCV']), axis=1)\n",
    "outdf['in_WaterSourceNativeID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile Data\n",
    "- For attaching gemetry to csv inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoU Shapefile Data\n",
    "# Shapefile input\n",
    "dfPoUshapetemp = gpd.read_file('shapefile/OK_PoU2.shp')\n",
    "dfPoUshapetemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating WaDE Custom site native ID for easy site identificaiion\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Create temp SiteNativeID dataframe of unique site.\n",
    "# def assignSiteUUID(colrowValue):\n",
    "#     string1 = str(colrowValue)\n",
    "#     outstring = \"wadeID\" + string1\n",
    "#     return outstring\n",
    "\n",
    "# dfSiteNativeID = pd.DataFrame()\n",
    "# dfSiteNativeID['in_Latitude'] = dfPoUshapetemp['Lattitude']\n",
    "# dfSiteNativeID['in_Longitude'] = dfPoUshapetemp['Longitude']\n",
    "# dfSiteNativeID = dfSiteNativeID.drop_duplicates()\n",
    "\n",
    "# dftemp = pd.DataFrame(index=dfSiteNativeID.index)\n",
    "# dftemp[\"Count\"] = range(1, len(dftemp.index) + 1)\n",
    "# dfSiteNativeID['in_SiteNativeID'] = dftemp.apply(lambda row: assignSiteUUID(row['Count']), axis=1)\n",
    "# dfSiteNativeID['linkKey'] = dfSiteNativeID['in_Latitude'].astype(str) + dfSiteNativeID['in_Longitude'].astype(str)\n",
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Retreive WaDE Custom site native ID\n",
    "# SiteNativeIDdict = pd.Series(dfSiteNativeID.in_SiteNativeID.values, index=dfSiteNativeID.linkKey.astype(str)).to_dict()\n",
    "# def retrieveSiteNativeID(A, B):\n",
    "#     if (A == '' and B == '') or (pd.isnull(A) and pd.isnull(B)):\n",
    "#         outList = ''\n",
    "#     else:\n",
    "#         colrowValue = str(A).strip() + str(B).strip()\n",
    "#         try:\n",
    "#             outList = SiteNativeIDdict[colrowValue]\n",
    "#         except:\n",
    "#             outList = ''\n",
    "#     return outList\n",
    "\n",
    "# dfPoUshapetemp['in_SiteNativeID'] = dfPoUshapetemp.apply(lambda row: retrieveSiteNativeID( row['Lattitude'], row['Longitude']), axis=1)\n",
    "# dfPoUshapetemp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOU['in_SiteNativeID'] = \"POU\" + dfPOU['RECORD_ID'].astype(str).str.strip()\n",
    "dfPOU['in_SiteNativeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList = ['in_SiteNativeID', 'geometry']\n",
    "dfPoUshape = pd.DataFrame(columns=columnsList)\n",
    "dfPoUshape['in_SiteNativeID'] = \"POU\" + dfPoUshapetemp['RECORD_ID'].replace(\"\", 0).fillna(0).astype(str)\n",
    "dfPoUshape['geometry'] = dfPoUshapetemp['geometry']\n",
    "dfPoUshape = dfPoUshape.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "print(len(dfPoUshape))\n",
    "dfPoUshape.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output dataframe\n",
    "outdf.to_csv('Pwr_okMain.zip', compression=dict(method='zip', archive_name='Pwr_okMain.csv'), index=False)  # The output, save as a zip\n",
    "dfPoUshape.to_csv('P_Geometry.zip', compression=dict(method='zip', archive_name='P_Geometry.csv'), index=False)  # The output geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
