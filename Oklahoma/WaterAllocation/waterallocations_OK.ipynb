{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from waterallocationsFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "working_dir = \"C:/tseg/OKTest\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "fileInput1 = \"Permitted_Groundwater_Wells.csv\" \n",
    "FileInput2 = \"Permitted_Surface_Water_Diversion_Points.csv\" # Points of diversion\n",
    "FileInput3 = \"Areas_of_Use.csv\"  # \n",
    "# water sources look up\n",
    "inp_wtrsrs=\"watersources.csv\"\n",
    "# sites look up\n",
    "inp_sitdim = 'sites.csv'\n",
    "\n",
    "#output: water allocation\n",
    "out_alloc = \"waterallocations.csv\"    #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## WaDE columns\n",
    "\n",
    "#the followwing fields have difference between the table here (edited by DPL) and that on the schema website\n",
    "#http://schema.westernstateswater.org/tables/Input_AllocationAmounts_fact.html\n",
    "\"\"\"\n",
    "BeneficialUseCategory, PrimaryUseCategory, AllocationTimeframeStart, AllocationTimeframeEnd, \" \"\n",
    "BeneficialUseCategoryCV, PrimaryUseCategoryCV, TimeframeStartDate,\tTimeframeEndDate,\tGeometry\t\n",
    "\"\"\"\n",
    "# UUIDs: Add UUIDs for all dim tables\n",
    "# OrganizationUUID, SiteUUID, VariableSpecificUUID, WaterSourceUUID, MethodUUID\n",
    "columns = [\"OrganizationUUID\", \"SiteUUID\", \"VariableSpecificUUID\", \"WaterSourceUUID\", \"MethodUUID\", \"PrimaryUseCategory\",\n",
    "           \"BeneficialUseCategory\", \"AllocationNativeID\", \"AllocationTypeCV\", \"AllocationOwner\",\n",
    "           \"AllocationApplicationDate\", \"AllocationPriorityDate\", \"AllocationLegalStatusCV\", \"AllocationCropDutyAmount\",\n",
    "           \"AllocationExpirationDate\",\n",
    "           \"AllocationChangeApplicationIndicator\", \"LegacyAllocationIDs\", \"AllocationBasisCV\", \"AllocationTimeframeStart\",\n",
    "           \"AllocationTimeframeEnd\", \"AllocationAmount\", \"AllocationMaximum\", \"PopulationServed\", \"PowerGeneratedGWh\",\n",
    "           \"IrrigatedAcreage\", \"AllocationCommunityWaterSupplySystem\", \"AllocationSDWISIdentifierCV\",\n",
    "           \"AllocationAssociatedWithdrawalSiteIDs\", \"AllocationAssociatedConsumptiveUseSiteIDs\", \"WaterAllocationNativeURL\",\n",
    "           \"CustomerTypeCV\", \"IrrigationMethodCV\", \"CropTypeCV\", \"CommunityWaterSupplySystem\", \"DataPublicationDate\",\n",
    "           \"DataPublicationDOI\"]\n",
    "\n",
    "dtypesx = [''] #here we could theoretically specify data types for each column name, but we didn't need to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### target dataFrame\n",
    "\n",
    "# TODO: assumes dtypes inferred from CO file\n",
    "outdf100=pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading inputs...\")\n",
    "\n",
    "# Read Inputs and merge tables\n",
    "# ToDO: We are joining 'on-left': keep all rows of mater table (check if need to be refined)\n",
    "\n",
    "# ground water\n",
    "df100_l = pd.read_csv(fileInput1,encoding = \"ISO-8859-1\") #, or alternatively encoding = \"utf-8\"\n",
    "print (len(df100_l.index))\n",
    "\n",
    "#### Join tables\n",
    "\n",
    "# surface water \n",
    "df200 = pd.read_csv(FileInput2,encoding = \"ISO-8859-1\")  \n",
    "print (len(df200.index))\n",
    "\n",
    "df100=pd.merge(df100_l, df200, left_on='OBJECTID', right_on='OBJECTID', how='left') #joined Points of diversiont table into Master_Table\n",
    "#df100\n",
    "print (len(df100.index))\n",
    "\n",
    "#df100 = df100.head(10000) #only runs first 100 lines for testing.\n",
    "\n",
    "#df100 = df100.replace('', np.nan)\n",
    "df100.head(5)\n",
    "\n",
    "# water sources look up\n",
    "df400 = pd.read_csv(inp_wtrsrs,encoding = \"ISO-8859-1\")\n",
    "#drop duplicate rows ---this one is not necessary once the water sources table is refined to remove duplicates\n",
    "df400 = df400.drop_duplicates(subset=['WaterSourceName'])\n",
    "#df400\n",
    "\n",
    "# sites look up\n",
    "df500 = pd.read_csv(inp_sitdim,encoding = \"ISO-8859-1\")\n",
    "#df500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only unique water rights based on permit number \n",
    "print(\"Dropping duplicates...\")\n",
    "\n",
    "outdf100 = outdf100.drop_duplicates(subset = ['Permit Number'], inplace=True)   #\n",
    "outdf100 = outdf100.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding SiteUUID...\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding SiteUUID...\")\n",
    "\n",
    "df100 = df100.assign(SiteUUID='')  #add new column and make is nan\n",
    "\n",
    "#Permit Number\n",
    "df100['SiteUUID'] = df100.apply(lambda row: assignSiteID(row['Permit Number'], df500), axis=1)\n",
    "#df100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Water sources...\")\n",
    "df100 = df100.assign(WaterSourceUUID='')\n",
    "\n",
    "df100['WaterSourceUUID'] = df100.apply(lambda row: \n",
    "                                       'OK_1' if row['Water Type'].strip() == 'Groundwater'\n",
    "                                              else 'UT_2', axis=1)\n",
    "#df100['WaterSourceUUID'] = df100['Water Type'].apply(lambda cv: \n",
    "#                                                     'OK_1' if cv.strip() == 'Groundwater'\n",
    "#                                                            else 'UT_2', axis=1)\n",
    "\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Copying all columns...\")\n",
    "#\n",
    "destCols=[\"SiteUUID\", \"WaterSourceUUID\", \n",
    "          \"AllocationNativeID\", \"AllocationTypeCV\", \"AllocationLegalStatusCV\", \n",
    "          \"BeneficialUseCategory\", \n",
    "          \"AllocationOwner\", \n",
    "          \"AllocationApplicationDate\", \"AllocationPriorityDate\",\n",
    "          #\"AllocationAmount\", \n",
    "          \"AllocationMaximum\", \n",
    "          #\"IrrigatedAcreage\",\n",
    "          #\"AllocationCropDutyAmount\", \"AllocationExpirationDate\", \n",
    "          #\"AllocationTimeframeStart\", \"AllocationTimeframeEnd\"\n",
    "         ]\n",
    "#\n",
    "sourCols=[\"SiteUUID\", \"WaterSourceUUID\", \n",
    "          \"Permit Number\", \"Permit Type\", \"Status\",\n",
    "          \"Primary Purpose\", \n",
    "          \"Entity Name\",\n",
    "          \"Date Filed\", \"Date Issued\",\n",
    "          #\"\",\n",
    "          \"Total Amount (AFY)\",\n",
    "          #\"Areas_of_Use.SHAPE.AREA\",\n",
    "          #\"IRRIGATION_DEPLETION\", \"DATE_TERMINATED\",\n",
    "          #\"USE_BEG_DATE\", \"USE_END_DATE\"\n",
    "         ]\n",
    "\n",
    "outdf100[destCols] = df100[sourCols]\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded\n",
    "print(\"Hard coded...\")\n",
    "#hard coded\n",
    "outdf100.OrganizationUUID = \"OWRB\"\n",
    "outdf100.VariableSpecificUUID = \"OWRB Allocation All\"\n",
    "outdf100.MethodUUID = \"OK_WaterAllocation\"\n",
    "outdf100.AllocationBasisCV = \"Unknown\"\n",
    "# check this later\n",
    "outdf100.PrimaryUseCategory = \"Irrigation\"\n",
    "outdf100.TimeframeStart = \"01/01\"\n",
    "outdf100.TimeframeEnd = \"12/31\"\n",
    "#\n",
    "outdf100.DataPublicationDate = datetime.now().strftime('%m/%d/%Y')    #\"10/31/2019\" # edit this to the code run date\n",
    "\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null allocations...\")\n",
    "# if both Allocation amount and Allocation maximum are empty drop row and save it to a Allocations_missing.csv\n",
    "#outdf100 = outdf100.replace('', np.nan) #replace blank strings by NaN,\n",
    "outdf100purge = outdf100.loc[(outdf100[\"AllocationAmount\"] == '') & (outdf100[\"AllocationMaximum\"] == '')]\n",
    "if len(outdf100purge.index) > 0:\n",
    "    outdf100purge.to_csv('waterallocations_missing.csv')    #index=False,\n",
    "    dropIndex = outdf100.loc[(outdf100[\"AllocationAmount\"] == '') & (outdf100[\"AllocationMaximum\"] == '')].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null SiteUUIDs...\")\n",
    "outdf100nullID = outdf100.loc[outdf100[\"SiteUUID\"] == '']\n",
    "if len(outdf100nullID.index) > 0:\n",
    "    dropIndex = outdf100.loc[outdf100[\"SiteUUID\"] == ''].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null Priority date...\")\n",
    "outdf100nullPR = outdf100.loc[outdf100[\"AllocationPriorityDate\"] == '']\n",
    "if len(outdf100nullPR.index) > 0:\n",
    "    dropIndex = outdf100.loc[outdf100[\"AllocationPriorityDate\"] == ''].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping null WaterSourceUUID ...\")\n",
    "outdf100nullPR = outdf100.loc[outdf100[\"WaterSourceUUID\"] == '']\n",
    "if len(outdf100nullPR.index) > 0:\n",
    "    dropIndex = outdf100.loc[outdf100[\"WaterSourceUUID\"] == ''].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Droping duplicates...\")\n",
    "#drop duplicate rows; just make sure\n",
    "outdf100Duplicated=outdf100.loc[outdf100.duplicated()]\n",
    "if len(outdf100Duplicated.index) > 0:\n",
    "    outdf100Duplicated.to_csv(\"waterallocations_duplicaterows.csv\")  # index=False,\n",
    "    outdf100.drop_duplicates(inplace=True)   #\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking required is not null...\")\n",
    "# check if any cell of these columns is null\n",
    "requiredCols = [\"OrganizationUUID\", \"VariableSpecificUUID\", \"WaterSourceUUID\", \n",
    "                \"MethodUUID\", \"AllocationPriorityDate\"] #SiteUUID\n",
    "# outdf100_nullMand = outdf100.loc[outdf100.isnull().any(axis=1)] --for all cols\n",
    "# outdf100_nullMand = outdf100.loc[outdf100[requiredCols].isnull().any(axis=1)]\n",
    "#(outdf100[\"SiteUUID\"].isnull()) |\n",
    "outdf100_nullMand = outdf100.loc[(outdf100[\"OrganizationUUID\"] == '') |\n",
    "                                (outdf100[\"VariableSpecificUUID\"] == '') |\n",
    "                                (outdf100[\"WaterSourceUUID\"] == '') |\n",
    "                                (outdf100[\"MethodUUID\"] == '') |\n",
    "                                (outdf100[\"AllocationPriorityDate\"] == '')]\n",
    "#outdf100_nullMand = outdf100.loc[[False | (outdf100[varName].isnull()) for varName in requiredCols]]\n",
    "if(len(outdf100_nullMand.index) > 0):\n",
    "    outdf100_nullMand.to_csv('waterallocations_mandatoryFieldMissing.csv')  # index=False,\n",
    "#ToDO: purge these cells if there is any missing? #For now left to be inspected\n",
    "#outdf100_nullMand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing outputs...\")\n",
    "#write out\n",
    "outdf100.to_csv(out_alloc, index=False, encoding = \"utf-8\")\n",
    "\n",
    "print(\"Done Water Allocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
