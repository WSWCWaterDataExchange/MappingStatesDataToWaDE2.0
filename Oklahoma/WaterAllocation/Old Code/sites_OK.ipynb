{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sites_dim\n",
    "Code to generate sites.csv as input to the WaDE db for OK water rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from waterallocationsFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "working_dir = \"C:/tseg/OKTest\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the following cell, make sure the input csv file is in the working directory. To obtain the data, go to the following link and download the tables: \n",
    "\n",
    "Permitted Surface Water Diversion Points\n",
    "http://home-owrb.opendata.arcgis.com/datasets/permitted-surface-water-diversion-points?geometry=-119.379%2C31.373%2C-77.565%2C37.701  \n",
    "\n",
    "Permitted Groundwater Wells (Point coverage)\n",
    "http://home-owrb.opendata.arcgis.com/datasets/permitted-groundwater-wells  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "fileInput1 = \"Permitted_Groundwater_Wells.csv\" \n",
    "FileInput2 = \"Permitted_Surface_Water_Diversion_Points.csv\" # Points of diversion\n",
    "FileInput3 = \"Areas_of_Use.csv\"  # \n",
    "\n",
    "# output sites\n",
    "out_sitdim = 'sites.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column names\n",
    "#10.24.19 rename 'WaDESiteUUID' to 'SiteUUID'\n",
    "columns=['SiteUUID', 'SiteNativeID', 'SiteName', 'USGSSiteID', 'SiteTypeCV', 'Longitude', 'Latitude',\n",
    "          'SitePoint', 'SiteNativeURL', 'Geometry', 'CoordinateMethodCV', 'CoordinateAccuracy', 'GNISCodeCV',\n",
    "          'EPSGCodeCV', 'NHDNetworkStatusCV', 'NHDProductCV', 'NHDUpdateDate', 'NHDReachCode', 'NHDMeasureNumber',\n",
    "          'StateCV']\n",
    "\n",
    "# These are not used currently. Data types inferred from the inputs\n",
    "dtypesx = ['NVarChar(55)\tNVarChar(50)\tNVarChar(500)\tNVarChar(250)\tNVarChar(100)\tDouble\tDouble\tGeometry',\n",
    "           'NVarChar(250)\tGeometry\tNVarChar(100)\tNVarChar(255)\tNVarChar(50)\tNVarChar(50)\tNVarChar(50)',\n",
    "           'NVarChar(50)\tDate\tNVarChar(50)\tNVarChar(50)\tNChar(5)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target dataframe\n",
    "\n",
    "#assumes dtypes inferred from CO file\n",
    "outdf100=pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading inputs...\n",
      "20859\n",
      "3422\n",
      "24281\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>RECORD_ID</th>\n",
       "      <th>PERMIT_NUMBER</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>RECORD_TYPE</th>\n",
       "      <th>WATER</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>PERMIT_TYPE</th>\n",
       "      <th>TOTAL_PERMITTED_ACRE_FEET</th>\n",
       "      <th>PRIMARY_PURPOSE</th>\n",
       "      <th>DATE_FILED</th>\n",
       "      <th>DATE_ISSUED</th>\n",
       "      <th>HYDRO_UNIT</th>\n",
       "      <th>STREAM_SYSTEM</th>\n",
       "      <th>RECORD_ID2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-101.896349</td>\n",
       "      <td>36.574734</td>\n",
       "      <td>561</td>\n",
       "      <td>9753</td>\n",
       "      <td>19980623</td>\n",
       "      <td>36.574728</td>\n",
       "      <td>-101.896340</td>\n",
       "      <td>Permit</td>\n",
       "      <td>Groundwater</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>11EC</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Regular</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>1998-11-20T00:00:00.000Z</td>\n",
       "      <td>1999-09-14T00:00:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-101.575120</td>\n",
       "      <td>36.516345</td>\n",
       "      <td>752</td>\n",
       "      <td>50052</td>\n",
       "      <td>20020591</td>\n",
       "      <td>36.516338</td>\n",
       "      <td>-101.575112</td>\n",
       "      <td>Permit</td>\n",
       "      <td>Groundwater</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>14EC</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>Irrigation</td>\n",
       "      <td>2002-09-20T00:00:00.000Z</td>\n",
       "      <td>2003-05-03T00:00:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-99.052511</td>\n",
       "      <td>34.582855</td>\n",
       "      <td>944</td>\n",
       "      <td>53324</td>\n",
       "      <td>20040578</td>\n",
       "      <td>34.582849</td>\n",
       "      <td>-99.052503</td>\n",
       "      <td>Permit</td>\n",
       "      <td>Groundwater</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>18WI</td>\n",
       "      <td>Tillman</td>\n",
       "      <td>Regular</td>\n",
       "      <td>314.0</td>\n",
       "      <td>Irrigation</td>\n",
       "      <td>2004-09-07T00:00:00.000Z</td>\n",
       "      <td>2005-05-10T00:00:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99.050317</td>\n",
       "      <td>34.590121</td>\n",
       "      <td>954</td>\n",
       "      <td>53325</td>\n",
       "      <td>20040578</td>\n",
       "      <td>34.590116</td>\n",
       "      <td>-99.050308</td>\n",
       "      <td>Permit</td>\n",
       "      <td>Groundwater</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>18WI</td>\n",
       "      <td>Tillman</td>\n",
       "      <td>Regular</td>\n",
       "      <td>314.0</td>\n",
       "      <td>Irrigation</td>\n",
       "      <td>2004-09-07T00:00:00.000Z</td>\n",
       "      <td>2005-05-10T00:00:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99.050317</td>\n",
       "      <td>34.586494</td>\n",
       "      <td>945</td>\n",
       "      <td>53326</td>\n",
       "      <td>20040578</td>\n",
       "      <td>34.586489</td>\n",
       "      <td>-99.050308</td>\n",
       "      <td>Permit</td>\n",
       "      <td>Groundwater</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>18WI</td>\n",
       "      <td>Tillman</td>\n",
       "      <td>Regular</td>\n",
       "      <td>314.0</td>\n",
       "      <td>Irrigation</td>\n",
       "      <td>2004-09-07T00:00:00.000Z</td>\n",
       "      <td>2005-05-10T00:00:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X          Y  OBJECTID  RECORD_ID PERMIT_NUMBER   LATITUDE  \\\n",
       "0 -101.896349  36.574734       561       9753      19980623  36.574728   \n",
       "1 -101.575120  36.516345       752      50052      20020591  36.516338   \n",
       "2  -99.052511  34.582855       944      53324      20040578  34.582849   \n",
       "3  -99.050317  34.590121       954      53325      20040578  34.590116   \n",
       "4  -99.050317  34.586494       945      53326      20040578  34.586489   \n",
       "\n",
       "    LONGITUDE RECORD_TYPE        WATER  STATUS  ... RANGE   COUNTY  \\\n",
       "0 -101.896340      Permit  Groundwater  Active  ...  11EC    Texas   \n",
       "1 -101.575112      Permit  Groundwater  Active  ...  14EC    Texas   \n",
       "2  -99.052503      Permit  Groundwater  Active  ...  18WI  Tillman   \n",
       "3  -99.050308      Permit  Groundwater  Active  ...  18WI  Tillman   \n",
       "4  -99.050308      Permit  Groundwater  Active  ...  18WI  Tillman   \n",
       "\n",
       "  PERMIT_TYPE TOTAL_PERMITTED_ACRE_FEET  PRIMARY_PURPOSE  \\\n",
       "0     Regular                      10.0      Agriculture   \n",
       "1     Regular                    1280.0       Irrigation   \n",
       "2     Regular                     314.0       Irrigation   \n",
       "3     Regular                     314.0       Irrigation   \n",
       "4     Regular                     314.0       Irrigation   \n",
       "\n",
       "                 DATE_FILED               DATE_ISSUED HYDRO_UNIT  \\\n",
       "0  1998-11-20T00:00:00.000Z  1999-09-14T00:00:00.000Z        NaN   \n",
       "1  2002-09-20T00:00:00.000Z  2003-05-03T00:00:00.000Z        NaN   \n",
       "2  2004-09-07T00:00:00.000Z  2005-05-10T00:00:00.000Z        NaN   \n",
       "3  2004-09-07T00:00:00.000Z  2005-05-10T00:00:00.000Z        NaN   \n",
       "4  2004-09-07T00:00:00.000Z  2005-05-10T00:00:00.000Z        NaN   \n",
       "\n",
       "  STREAM_SYSTEM  RECORD_ID2  \n",
       "0           NaN        9753  \n",
       "1           NaN       50052  \n",
       "2           NaN       53324  \n",
       "3           NaN       53325  \n",
       "4           NaN       53326  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Reading inputs...\")\n",
    "\n",
    "# Read Inputs and merge tables\n",
    "# ToDO: We are joining 'on-left': keep all rows of mater table (check if need to be refined)\n",
    "\n",
    "# ground water\n",
    "df100_l = pd.read_csv(fileInput1,encoding = \"ISO-8859-1\") #, or alternatively encoding = \"utf-8\"\n",
    "print (len(df100_l.index))\n",
    "\n",
    "#### Join tables\n",
    "\n",
    "# surface water \n",
    "df200 = pd.read_csv(FileInput2,encoding = \"ISO-8859-1\")  \n",
    "print (len(df200.index))\n",
    "\n",
    "# in this case we concatenate the two water right data\n",
    "df100=pd.concat([df100_l, df200], ignore_index=True)\n",
    "#df100\n",
    "print (len(df100.index))\n",
    "\n",
    "#df100 = df100.head(10000) #only runs first 100 lines for testing.\n",
    "\n",
    "#df100 = df100.replace('', np.nan)\n",
    "df100.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " 'Y',\n",
       " 'OBJECTID',\n",
       " 'RECORD_ID',\n",
       " 'PERMIT_NUMBER',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'RECORD_TYPE',\n",
       " 'WATER',\n",
       " 'STATUS',\n",
       " 'ENTITY_NAME',\n",
       " 'QUARTER3',\n",
       " 'QUARTER2',\n",
       " 'QUARTER1',\n",
       " 'SECTION',\n",
       " 'TOWNSHIP',\n",
       " 'RANGE',\n",
       " 'COUNTY',\n",
       " 'PERMIT_TYPE',\n",
       " 'TOTAL_PERMITTED_ACRE_FEET',\n",
       " 'PRIMARY_PURPOSE',\n",
       " 'DATE_FILED',\n",
       " 'DATE_ISSUED',\n",
       " 'HYDRO_UNIT',\n",
       " 'STREAM_SYSTEM',\n",
       " 'RECORD_ID2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df100.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct mapping columns...\n"
     ]
    }
   ],
   "source": [
    "print(\"Direct mapping columns...\")\n",
    "#\n",
    "# Utah directly mapped cells\n",
    "destCols=['SiteNativeID', 'SiteTypeCV', 'Longitude', 'Latitude']\n",
    "srsCols=['OBJECTID', 'WATER', 'LONGITUDE', 'LATITUDE']\n",
    "\n",
    "outdf100[destCols] = df100[srsCols]\n",
    "\n",
    "# replace NaN with blank cells\n",
    "outdf100 = outdf100.replace(np.nan, '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping empty lat/lon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping empty lat/lon\")\n",
    "#drop the sites with no long and lat.\n",
    "outdf100purge = outdf100.loc[(outdf100['Longitude'].isnull()) | (outdf100['Longitude'] == '') |\n",
    "                             (outdf100['Latitude'].isnull()) | (outdf100['Latitude'] == '')]\n",
    "if len(outdf100purge.index) > 0:\n",
    "    outdf100purge.to_csv('sites_missing.csv')    #index=False,\n",
    "    dropIndex = outdf100.loc[(outdf100['Longitude'].isnull()) | (outdf100['Longitude'] == '') |\n",
    "                             (outdf100['Latitude'].isnull()) | (outdf100['Latitude'] == '')].index\n",
    "    outdf100 = outdf100.drop(dropIndex)\n",
    "    outdf100 = outdf100.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicates...\n",
      "24281\n",
      "24281\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping duplicates...\")\n",
    "#filter the whole table based on a unique combination of site ID, SiteName, SiteType\n",
    "#10.24.19 added lat lon to list\n",
    "print(len(outdf100.index))\n",
    "outdf100 = outdf100.drop_duplicates(subset=['SiteNativeID', 'SiteName', 'SiteTypeCV', 'Longitude', 'Latitude'])   #\n",
    "outdf100 = outdf100.reset_index(drop=True)\n",
    "print(len(outdf100.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard coded\n"
     ]
    }
   ],
   "source": [
    "# hardcoded columns\n",
    "print(\"Hard coded\")\n",
    "outdf100.EPSGCodeCV = 'EPSG:4326'\n",
    "outdf100.SiteName = 'Not Provided'    # site name doesn't exist so use Not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix empty coordinatemethodCV\n"
     ]
    }
   ],
   "source": [
    "print(\"Fix empty coordinatemethodCV\")\n",
    "\n",
    "# in this case all rows for CoordinateMethod are empty so hard code it\n",
    "outdf100.CoordinateMethodCV = 'Unspecified'\n",
    "#outdf100.loc[outdf100[\"CoordinateMethodCV\"] == '', \"CoordinateMethodCV\"] = 'Unspecified'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Site Native IDs are duplicated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteUUID</th>\n",
       "      <th>SiteNativeID</th>\n",
       "      <th>SiteName</th>\n",
       "      <th>USGSSiteID</th>\n",
       "      <th>SiteTypeCV</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>SitePoint</th>\n",
       "      <th>SiteNativeURL</th>\n",
       "      <th>Geometry</th>\n",
       "      <th>CoordinateMethodCV</th>\n",
       "      <th>CoordinateAccuracy</th>\n",
       "      <th>GNISCodeCV</th>\n",
       "      <th>EPSGCodeCV</th>\n",
       "      <th>NHDNetworkStatusCV</th>\n",
       "      <th>NHDProductCV</th>\n",
       "      <th>NHDUpdateDate</th>\n",
       "      <th>NHDReachCode</th>\n",
       "      <th>NHDMeasureNumber</th>\n",
       "      <th>StateCV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SiteUUID, SiteNativeID, SiteName, USGSSiteID, SiteTypeCV, Longitude, Latitude, SitePoint, SiteNativeURL, Geometry, CoordinateMethodCV, CoordinateAccuracy, GNISCodeCV, EPSGCodeCV, NHDNetworkStatusCV, NHDProductCV, NHDUpdateDate, NHDReachCode, NHDMeasureNumber, StateCV]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Check Site Native IDs are duplicated\")\n",
    "\n",
    "siteNativeIDdup=outdf100.loc[outdf100.duplicated(subset=['SiteNativeID'])]\n",
    "siteNIdDup = False\n",
    "if len(siteNativeIDdup.index) > 0:\n",
    "    print(\"Site Native IDs are duplicated\")\n",
    "    siteNIdDup = True\n",
    "#outdf100\n",
    "\n",
    "siteNativeIDdup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding SiteUUID...\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding SiteUUID...\")\n",
    "\n",
    "if siteNIdDup:    \n",
    "    # 10.24.19 create unique site uuid\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "    outdf100['TempUUID'] = range(1, len(outdf100.index) + 1)\n",
    "    #append 'OK'\n",
    "    outdf100['SiteUUID'] = outdf100.apply(lambda row: \"_\".join([\"OK\", str(row['TempUUID'])]) , axis=1)\n",
    "    #drop temp uuid\n",
    "    outdf100 = outdf100.drop('TempUUID', axis=1)\n",
    "else:\n",
    "    #append 'OK'\n",
    "    outdf100['SiteUUID'] = outdf100.apply(lambda row: '' if str(row['SiteNativeID']) == '' \n",
    "                                        else \"_\".join([\"OK\", str(row['SiteNativeID'])]), axis=1)\n",
    "\n",
    "#df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droping duplicates...\n"
     ]
    }
   ],
   "source": [
    "print(\"Droping duplicates...\")\n",
    "# replace NaN with blank cells\n",
    "outdf100 = outdf100.replace(np.nan, '')\n",
    "#drop duplicate rows; just make sure\n",
    "outdf100Duplicated=outdf100.loc[outdf100.duplicated()]\n",
    "if len(outdf100Duplicated.index) > 0:\n",
    "    outdf100Duplicated.to_csv(\"sites_duplicaterows.csv\")  # index=False,\n",
    "    outdf100.drop_duplicates(inplace=True)   #\n",
    "    outdf100 = outdf100.reset_index(drop=True)\n",
    "#outdf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking required isnot null...\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking required isnot null...\")\n",
    "# check if any cell of these columns is null\n",
    "requiredCols = ['SiteUUID', 'SiteName', 'CoordinateMethodCV', 'GNISCodeCV', 'EPSGCodeCV']\n",
    "\n",
    "# replace NaN with blank cells\n",
    "outdf100 = outdf100.replace(np.nan, '')\n",
    "\n",
    "outdf100_nullMand = outdf100.loc[(outdf100[\"SiteUUID\"] == '') |\n",
    "                                 (outdf100[\"SiteName\"] == '') | \n",
    "                                 (outdf100[\"CoordinateMethodCV\"] == '') |\n",
    "                                 (outdf100[\"GNISCodeCV\"] == '') | \n",
    "                                 (outdf100[\"EPSGCodeCV\"] == '')]\n",
    "\n",
    "if (len(outdf100_nullMand.index) > 0):\n",
    "    outdf100_nullMand.to_csv('sites_mandatoryFieldMissing.csv')  # index=False,\n",
    "\n",
    "# ToDO: purge these cells if there is any missing? #For now left to be inspected and reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing out...\n",
      "Done sites\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing out...\")\n",
    "\n",
    "#write out\n",
    "outdf100.to_csv(out_sitdim, index=False, encoding = \"utf-8\")\n",
    "\n",
    "print(\"Done sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
